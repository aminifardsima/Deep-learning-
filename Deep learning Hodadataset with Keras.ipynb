{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,  Activation\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = io.loadmat('Data_hoda_full.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orginal = np.squeeze(dataset['Data'][:1000])\n",
    "y_train = np.squeeze(dataset['labels'][:1000])\n",
    "X_test_original = np.squeeze(dataset['Data'][1000:1200])\n",
    "y_test = np.squeeze(dataset['labels'][1000:1200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train_orginal[65], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_5by5 = [resize(img, (5, 5)) for img in X_train_orginal]\n",
    "X_test_5by_5 = [resize(img, (5, 5)) for img in X_test_original]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [x.reshape(25) for x in X_train_5by5]\n",
    "X_test = [x.reshape(25) for x in X_test_5by_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tx_train.shape: (1000, 25)\n"
     ]
    }
   ],
   "source": [
    "print (\"\\tx_train.shape: {}\".format(np.shape(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess input data for Keras. \n",
    "x_train = np.array(X_train)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "x_test = np.array(X_test)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tx_train.shape: (1000, 25)\n"
     ]
    }
   ],
   "source": [
    "print (\"\\tx_train.shape: {}\".format(np.shape(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tx_train.shape: (1000, 25)\n"
     ]
    }
   ],
   "source": [
    "print (\"\\tx_train.shape: {}\".format(np.shape(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=25))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                1664      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 2,314\n",
      "Trainable params: 2,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/3000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 1.2509 - accuracy: 0.6875 - val_loss: 1.2246 - val_accuracy: 0.6500\n",
      "Epoch 2/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.1787 - accuracy: 0.62 - 0s 58us/step - loss: 1.2487 - accuracy: 0.6900 - val_loss: 1.2267 - val_accuracy: 0.6550\n",
      "Epoch 3/3000\n",
      "800/800 [==============================] - 0s 61us/step - loss: 1.2460 - accuracy: 0.6862 - val_loss: 1.2191 - val_accuracy: 0.6500\n",
      "Epoch 4/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 1.2434 - accuracy: 0.6825 - val_loss: 1.2167 - val_accuracy: 0.6550\n",
      "Epoch 5/3000\n",
      "800/800 [==============================] - 0s 58us/step - loss: 1.2411 - accuracy: 0.6963 - val_loss: 1.2202 - val_accuracy: 0.6550\n",
      "Epoch 6/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 1.2389 - accuracy: 0.6875 - val_loss: 1.2128 - val_accuracy: 0.6600\n",
      "Epoch 7/3000\n",
      "800/800 [==============================] - 0s 59us/step - loss: 1.2364 - accuracy: 0.6900 - val_loss: 1.2108 - val_accuracy: 0.6600\n",
      "Epoch 8/3000\n",
      "800/800 [==============================] - 0s 56us/step - loss: 1.2345 - accuracy: 0.6913 - val_loss: 1.2091 - val_accuracy: 0.6600\n",
      "Epoch 9/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 1.2323 - accuracy: 0.6975 - val_loss: 1.2072 - val_accuracy: 0.6600\n",
      "Epoch 10/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 1.2301 - accuracy: 0.6875 - val_loss: 1.2076 - val_accuracy: 0.6550\n",
      "Epoch 11/3000\n",
      "800/800 [==============================] - 0s 60us/step - loss: 1.2268 - accuracy: 0.6900 - val_loss: 1.2026 - val_accuracy: 0.6550\n",
      "Epoch 12/3000\n",
      "800/800 [==============================] - 0s 56us/step - loss: 1.2245 - accuracy: 0.6913 - val_loss: 1.1991 - val_accuracy: 0.6550\n",
      "Epoch 13/3000\n",
      "800/800 [==============================] - 0s 56us/step - loss: 1.2228 - accuracy: 0.6875 - val_loss: 1.2002 - val_accuracy: 0.6600\n",
      "Epoch 14/3000\n",
      "800/800 [==============================] - 0s 59us/step - loss: 1.2207 - accuracy: 0.6925 - val_loss: 1.1968 - val_accuracy: 0.6650\n",
      "Epoch 15/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 1.2180 - accuracy: 0.6975 - val_loss: 1.1915 - val_accuracy: 0.6650\n",
      "Epoch 16/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 1.2159 - accuracy: 0.7013 - val_loss: 1.1921 - val_accuracy: 0.6550\n",
      "Epoch 17/3000\n",
      "800/800 [==============================] - 0s 53us/step - loss: 1.2133 - accuracy: 0.6988 - val_loss: 1.1891 - val_accuracy: 0.6550\n",
      "Epoch 18/3000\n",
      "800/800 [==============================] - 0s 60us/step - loss: 1.2112 - accuracy: 0.6988 - val_loss: 1.1919 - val_accuracy: 0.6650\n",
      "Epoch 19/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 1.2089 - accuracy: 0.6975 - val_loss: 1.1841 - val_accuracy: 0.6600\n",
      "Epoch 20/3000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 1.2066 - accuracy: 0.6938 - val_loss: 1.1815 - val_accuracy: 0.6600\n",
      "Epoch 21/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.2050 - accuracy: 0.7063 - val_loss: 1.1819 - val_accuracy: 0.6600\n",
      "Epoch 22/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 1.2023 - accuracy: 0.7013 - val_loss: 1.1772 - val_accuracy: 0.6600\n",
      "Epoch 23/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 1.1996 - accuracy: 0.6950 - val_loss: 1.1742 - val_accuracy: 0.6750\n",
      "Epoch 24/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.3060 - accuracy: 0.64 - 0s 63us/step - loss: 1.1980 - accuracy: 0.7075 - val_loss: 1.1759 - val_accuracy: 0.6650\n",
      "Epoch 25/3000\n",
      "800/800 [==============================] - 0s 61us/step - loss: 1.1951 - accuracy: 0.7125 - val_loss: 1.1721 - val_accuracy: 0.6750\n",
      "Epoch 26/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 1.1927 - accuracy: 0.7075 - val_loss: 1.1723 - val_accuracy: 0.6600\n",
      "Epoch 27/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 1.1914 - accuracy: 0.7025 - val_loss: 1.1661 - val_accuracy: 0.6750\n",
      "Epoch 28/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 1.1884 - accuracy: 0.7050 - val_loss: 1.1692 - val_accuracy: 0.6650\n",
      "Epoch 29/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 1.1866 - accuracy: 0.7050 - val_loss: 1.1646 - val_accuracy: 0.6750\n",
      "Epoch 30/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 1.1846 - accuracy: 0.7050 - val_loss: 1.1627 - val_accuracy: 0.6800\n",
      "Epoch 31/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 1.1826 - accuracy: 0.7100 - val_loss: 1.1614 - val_accuracy: 0.6850\n",
      "Epoch 32/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 1.1804 - accuracy: 0.7100 - val_loss: 1.1575 - val_accuracy: 0.6800\n",
      "Epoch 33/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.2120 - accuracy: 0.71 - 0s 70us/step - loss: 1.1776 - accuracy: 0.7100 - val_loss: 1.1545 - val_accuracy: 0.6850\n",
      "Epoch 34/3000\n",
      "800/800 [==============================] - 0s 54us/step - loss: 1.1761 - accuracy: 0.7063 - val_loss: 1.1551 - val_accuracy: 0.6700\n",
      "Epoch 35/3000\n",
      "800/800 [==============================] - 0s 58us/step - loss: 1.1735 - accuracy: 0.7075 - val_loss: 1.1515 - val_accuracy: 0.6850\n",
      "Epoch 36/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 1.1718 - accuracy: 0.7225 - val_loss: 1.1486 - val_accuracy: 0.6850\n",
      "Epoch 37/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 1.1691 - accuracy: 0.7100 - val_loss: 1.1490 - val_accuracy: 0.6800\n",
      "Epoch 38/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.1671 - accuracy: 0.7150 - val_loss: 1.1465 - val_accuracy: 0.6800\n",
      "Epoch 39/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 1.1654 - accuracy: 0.7150 - val_loss: 1.1451 - val_accuracy: 0.6900\n",
      "Epoch 40/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 1.1628 - accuracy: 0.7075 - val_loss: 1.1400 - val_accuracy: 0.6900\n",
      "Epoch 41/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 1.1612 - accuracy: 0.7113 - val_loss: 1.1391 - val_accuracy: 0.6850\n",
      "Epoch 42/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 1.1590 - accuracy: 0.7100 - val_loss: 1.1396 - val_accuracy: 0.6950\n",
      "Epoch 43/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 1.1564 - accuracy: 0.7212 - val_loss: 1.1355 - val_accuracy: 0.6900\n",
      "Epoch 44/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 1.1554 - accuracy: 0.7200 - val_loss: 1.1355 - val_accuracy: 0.6900\n",
      "Epoch 45/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 1.1523 - accuracy: 0.7088 - val_loss: 1.1313 - val_accuracy: 0.6900\n",
      "Epoch 46/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 1.1501 - accuracy: 0.7125 - val_loss: 1.1315 - val_accuracy: 0.6900\n",
      "Epoch 47/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.1483 - accuracy: 0.7175 - val_loss: 1.1297 - val_accuracy: 0.7000\n",
      "Epoch 48/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 1.1464 - accuracy: 0.7188 - val_loss: 1.1280 - val_accuracy: 0.6900\n",
      "Epoch 49/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 1.1445 - accuracy: 0.7113 - val_loss: 1.1273 - val_accuracy: 0.6950\n",
      "Epoch 50/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 1.1424 - accuracy: 0.7212 - val_loss: 1.1244 - val_accuracy: 0.6900\n",
      "Epoch 51/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 1.1397 - accuracy: 0.7150 - val_loss: 1.1226 - val_accuracy: 0.6800\n",
      "Epoch 52/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 1.1381 - accuracy: 0.7225 - val_loss: 1.1185 - val_accuracy: 0.6900\n",
      "Epoch 53/3000\n",
      "800/800 [==============================] - 0s 60us/step - loss: 1.1358 - accuracy: 0.7200 - val_loss: 1.1205 - val_accuracy: 0.6900\n",
      "Epoch 54/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 1.1342 - accuracy: 0.7225 - val_loss: 1.1169 - val_accuracy: 0.6900\n",
      "Epoch 55/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.1770 - accuracy: 0.73 - 0s 81us/step - loss: 1.1313 - accuracy: 0.7150 - val_loss: 1.1161 - val_accuracy: 0.6850\n",
      "Epoch 56/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 1.1296 - accuracy: 0.7250 - val_loss: 1.1140 - val_accuracy: 0.6900\n",
      "Epoch 57/3000\n",
      "800/800 [==============================] - 0s 58us/step - loss: 1.1272 - accuracy: 0.7163 - val_loss: 1.1126 - val_accuracy: 0.6950\n",
      "Epoch 58/3000\n",
      "800/800 [==============================] - 0s 56us/step - loss: 1.1249 - accuracy: 0.7175 - val_loss: 1.1090 - val_accuracy: 0.7000\n",
      "Epoch 59/3000\n",
      "800/800 [==============================] - 0s 56us/step - loss: 1.1232 - accuracy: 0.7237 - val_loss: 1.1049 - val_accuracy: 0.6950\n",
      "Epoch 60/3000\n",
      "800/800 [==============================] - 0s 55us/step - loss: 1.1208 - accuracy: 0.7225 - val_loss: 1.1055 - val_accuracy: 0.6900\n",
      "Epoch 61/3000\n",
      "800/800 [==============================] - 0s 59us/step - loss: 1.1189 - accuracy: 0.7287 - val_loss: 1.1016 - val_accuracy: 0.6900\n",
      "Epoch 62/3000\n",
      "800/800 [==============================] - 0s 55us/step - loss: 1.1169 - accuracy: 0.7250 - val_loss: 1.1026 - val_accuracy: 0.6850\n",
      "Epoch 63/3000\n",
      "800/800 [==============================] - 0s 55us/step - loss: 1.1154 - accuracy: 0.7150 - val_loss: 1.0978 - val_accuracy: 0.6900\n",
      "Epoch 64/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 1.1129 - accuracy: 0.7150 - val_loss: 1.0968 - val_accuracy: 0.6900\n",
      "Epoch 65/3000\n",
      "800/800 [==============================] - 0s 60us/step - loss: 1.1111 - accuracy: 0.7300 - val_loss: 1.0943 - val_accuracy: 0.6900\n",
      "Epoch 66/3000\n",
      "800/800 [==============================] - 0s 59us/step - loss: 1.1091 - accuracy: 0.7250 - val_loss: 1.0931 - val_accuracy: 0.6950\n",
      "Epoch 67/3000\n",
      "800/800 [==============================] - 0s 56us/step - loss: 1.1066 - accuracy: 0.7225 - val_loss: 1.0939 - val_accuracy: 0.6950\n",
      "Epoch 68/3000\n",
      "800/800 [==============================] - 0s 61us/step - loss: 1.1052 - accuracy: 0.7262 - val_loss: 1.0891 - val_accuracy: 0.6900\n",
      "Epoch 69/3000\n",
      "800/800 [==============================] - 0s 60us/step - loss: 1.1032 - accuracy: 0.7362 - val_loss: 1.0894 - val_accuracy: 0.6950\n",
      "Epoch 70/3000\n",
      "800/800 [==============================] - 0s 58us/step - loss: 1.1008 - accuracy: 0.7250 - val_loss: 1.0861 - val_accuracy: 0.6950\n",
      "Epoch 71/3000\n",
      "800/800 [==============================] - 0s 60us/step - loss: 1.0996 - accuracy: 0.7300 - val_loss: 1.0848 - val_accuracy: 0.7000\n",
      "Epoch 72/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 1.0974 - accuracy: 0.7262 - val_loss: 1.0823 - val_accuracy: 0.6950\n",
      "Epoch 73/3000\n",
      "800/800 [==============================] - 0s 61us/step - loss: 1.0953 - accuracy: 0.7188 - val_loss: 1.0823 - val_accuracy: 0.6900\n",
      "Epoch 74/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.0931 - accuracy: 0.7362 - val_loss: 1.0811 - val_accuracy: 0.6950\n",
      "Epoch 75/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 1.0913 - accuracy: 0.7237 - val_loss: 1.0770 - val_accuracy: 0.6900\n",
      "Epoch 76/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 1.0891 - accuracy: 0.7212 - val_loss: 1.0761 - val_accuracy: 0.6950\n",
      "Epoch 77/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 1.0871 - accuracy: 0.7262 - val_loss: 1.0740 - val_accuracy: 0.6900\n",
      "Epoch 78/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 1.0856 - accuracy: 0.7325 - val_loss: 1.0707 - val_accuracy: 0.6950\n",
      "Epoch 79/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 1.0837 - accuracy: 0.7337 - val_loss: 1.0719 - val_accuracy: 0.6950\n",
      "Epoch 80/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.1238 - accuracy: 0.64 - 0s 69us/step - loss: 1.0816 - accuracy: 0.7275 - val_loss: 1.0688 - val_accuracy: 0.6950\n",
      "Epoch 81/3000\n",
      "800/800 [==============================] - 0s 148us/step - loss: 1.0806 - accuracy: 0.7325 - val_loss: 1.0672 - val_accuracy: 0.6950\n",
      "Epoch 82/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 1.0778 - accuracy: 0.7300 - val_loss: 1.0626 - val_accuracy: 0.6950\n",
      "Epoch 83/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.1223 - accuracy: 0.67 - 0s 135us/step - loss: 1.0765 - accuracy: 0.7300 - val_loss: 1.0643 - val_accuracy: 0.6950\n",
      "Epoch 84/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.0736 - accuracy: 0.7312 - val_loss: 1.0629 - val_accuracy: 0.6950\n",
      "Epoch 85/3000\n",
      "800/800 [==============================] - 0s 126us/step - loss: 1.0723 - accuracy: 0.7287 - val_loss: 1.0591 - val_accuracy: 0.6950\n",
      "Epoch 86/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.9881 - accuracy: 0.79 - 0s 89us/step - loss: 1.0701 - accuracy: 0.7337 - val_loss: 1.0570 - val_accuracy: 0.6950\n",
      "Epoch 87/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 1.0679 - accuracy: 0.7400 - val_loss: 1.0554 - val_accuracy: 0.6900\n",
      "Epoch 88/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 1.0661 - accuracy: 0.7287 - val_loss: 1.0584 - val_accuracy: 0.7000\n",
      "Epoch 89/3000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 1.0645 - accuracy: 0.7350 - val_loss: 1.0559 - val_accuracy: 0.6950\n",
      "Epoch 90/3000\n",
      "800/800 [==============================] - 0s 151us/step - loss: 1.0624 - accuracy: 0.7337 - val_loss: 1.0524 - val_accuracy: 0.7000\n",
      "Epoch 91/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.0655 - accuracy: 0.72 - 0s 151us/step - loss: 1.0606 - accuracy: 0.7250 - val_loss: 1.0519 - val_accuracy: 0.7000\n",
      "Epoch 92/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 1.0586 - accuracy: 0.7287 - val_loss: 1.0471 - val_accuracy: 0.6900\n",
      "Epoch 93/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 1.0571 - accuracy: 0.7312 - val_loss: 1.0452 - val_accuracy: 0.6950\n",
      "Epoch 94/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 1.0554 - accuracy: 0.7350 - val_loss: 1.0473 - val_accuracy: 0.6950\n",
      "Epoch 95/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 1.0528 - accuracy: 0.7375 - val_loss: 1.0444 - val_accuracy: 0.7000\n",
      "Epoch 96/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 1.0512 - accuracy: 0.7325 - val_loss: 1.0429 - val_accuracy: 0.7000\n",
      "Epoch 97/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 1.0490 - accuracy: 0.7375 - val_loss: 1.0421 - val_accuracy: 0.7000\n",
      "Epoch 98/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 1.0473 - accuracy: 0.7300 - val_loss: 1.0375 - val_accuracy: 0.7100\n",
      "Epoch 99/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 1.0465 - accuracy: 0.7425 - val_loss: 1.0362 - val_accuracy: 0.6950\n",
      "Epoch 100/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 1.0435 - accuracy: 0.7375 - val_loss: 1.0338 - val_accuracy: 0.7100\n",
      "Epoch 101/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 1.0415 - accuracy: 0.7387 - val_loss: 1.0320 - val_accuracy: 0.7000\n",
      "Epoch 102/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.9041 - accuracy: 0.79 - 0s 74us/step - loss: 1.0407 - accuracy: 0.7300 - val_loss: 1.0305 - val_accuracy: 0.6950\n",
      "Epoch 103/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 1.0386 - accuracy: 0.7387 - val_loss: 1.0299 - val_accuracy: 0.6950\n",
      "Epoch 104/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 1.0362 - accuracy: 0.7400 - val_loss: 1.0283 - val_accuracy: 0.7000\n",
      "Epoch 105/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 1.0350 - accuracy: 0.7362 - val_loss: 1.0270 - val_accuracy: 0.7000\n",
      "Epoch 106/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 1.0332 - accuracy: 0.7375 - val_loss: 1.0256 - val_accuracy: 0.7000\n",
      "Epoch 107/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 1.0313 - accuracy: 0.7400 - val_loss: 1.0242 - val_accuracy: 0.7000\n",
      "Epoch 108/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 1.0295 - accuracy: 0.7375 - val_loss: 1.0219 - val_accuracy: 0.7100\n",
      "Epoch 109/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 1.0279 - accuracy: 0.7387 - val_loss: 1.0202 - val_accuracy: 0.6950\n",
      "Epoch 110/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 1.0258 - accuracy: 0.7400 - val_loss: 1.0191 - val_accuracy: 0.7000\n",
      "Epoch 111/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 1.0238 - accuracy: 0.7412 - val_loss: 1.0178 - val_accuracy: 0.7100\n",
      "Epoch 112/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 1.0230 - accuracy: 0.7387 - val_loss: 1.0149 - val_accuracy: 0.7050\n",
      "Epoch 113/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 1.0210 - accuracy: 0.7412 - val_loss: 1.0131 - val_accuracy: 0.7050\n",
      "Epoch 114/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 1.0185 - accuracy: 0.7437 - val_loss: 1.0110 - val_accuracy: 0.7050\n",
      "Epoch 115/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 1.0171 - accuracy: 0.7362 - val_loss: 1.0084 - val_accuracy: 0.7050\n",
      "Epoch 116/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 1.0155 - accuracy: 0.7375 - val_loss: 1.0110 - val_accuracy: 0.7050\n",
      "Epoch 117/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 1.0141 - accuracy: 0.7450 - val_loss: 1.0099 - val_accuracy: 0.7000\n",
      "Epoch 118/3000\n",
      "800/800 [==============================] - 0s 59us/step - loss: 1.0116 - accuracy: 0.7462 - val_loss: 1.0044 - val_accuracy: 0.7050\n",
      "Epoch 119/3000\n",
      "800/800 [==============================] - 0s 61us/step - loss: 1.0104 - accuracy: 0.7412 - val_loss: 1.0045 - val_accuracy: 0.7100\n",
      "Epoch 120/3000\n",
      "800/800 [==============================] - 0s 61us/step - loss: 1.0083 - accuracy: 0.7437 - val_loss: 1.0008 - val_accuracy: 0.7150\n",
      "Epoch 121/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 1.0072 - accuracy: 0.7500 - val_loss: 1.0042 - val_accuracy: 0.7100\n",
      "Epoch 122/3000\n",
      "800/800 [==============================] - 0s 61us/step - loss: 1.0048 - accuracy: 0.7450 - val_loss: 0.9991 - val_accuracy: 0.7150\n",
      "Epoch 123/3000\n",
      "800/800 [==============================] - 0s 58us/step - loss: 1.0032 - accuracy: 0.7563 - val_loss: 0.9988 - val_accuracy: 0.7050\n",
      "Epoch 124/3000\n",
      "800/800 [==============================] - 0s 58us/step - loss: 1.0019 - accuracy: 0.7387 - val_loss: 0.9986 - val_accuracy: 0.7100\n",
      "Epoch 125/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 1.0004 - accuracy: 0.7475 - val_loss: 0.9973 - val_accuracy: 0.7150\n",
      "Epoch 126/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.9984 - accuracy: 0.7437 - val_loss: 0.9967 - val_accuracy: 0.7150\n",
      "Epoch 127/3000\n",
      "800/800 [==============================] - 0s 60us/step - loss: 0.9971 - accuracy: 0.7462 - val_loss: 0.9923 - val_accuracy: 0.7050\n",
      "Epoch 128/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.9951 - accuracy: 0.7513 - val_loss: 0.9912 - val_accuracy: 0.7100\n",
      "Epoch 129/3000\n",
      "800/800 [==============================] - 0s 60us/step - loss: 0.9935 - accuracy: 0.7462 - val_loss: 0.9914 - val_accuracy: 0.7150\n",
      "Epoch 130/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.9925 - accuracy: 0.7487 - val_loss: 0.9879 - val_accuracy: 0.7100\n",
      "Epoch 131/3000\n",
      "800/800 [==============================] - 0s 58us/step - loss: 0.9893 - accuracy: 0.7425 - val_loss: 0.9875 - val_accuracy: 0.7100\n",
      "Epoch 132/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.9888 - accuracy: 0.7550 - val_loss: 0.9870 - val_accuracy: 0.7050\n",
      "Epoch 133/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.9870 - accuracy: 0.7487 - val_loss: 0.9824 - val_accuracy: 0.7050\n",
      "Epoch 134/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.9848 - accuracy: 0.7500 - val_loss: 0.9840 - val_accuracy: 0.7150\n",
      "Epoch 135/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.9831 - accuracy: 0.7450 - val_loss: 0.9808 - val_accuracy: 0.7150\n",
      "Epoch 136/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.9820 - accuracy: 0.7525 - val_loss: 0.9779 - val_accuracy: 0.7100\n",
      "Epoch 137/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.9807 - accuracy: 0.7475 - val_loss: 0.9800 - val_accuracy: 0.7150\n",
      "Epoch 138/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.9787 - accuracy: 0.7437 - val_loss: 0.9762 - val_accuracy: 0.7150\n",
      "Epoch 139/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.9762 - accuracy: 0.7600 - val_loss: 0.9735 - val_accuracy: 0.7050\n",
      "Epoch 140/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.9758 - accuracy: 0.7450 - val_loss: 0.9732 - val_accuracy: 0.7200\n",
      "Epoch 141/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.9735 - accuracy: 0.7487 - val_loss: 0.9725 - val_accuracy: 0.7150\n",
      "Epoch 142/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.9724 - accuracy: 0.7550 - val_loss: 0.9731 - val_accuracy: 0.7150\n",
      "Epoch 143/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.9703 - accuracy: 0.7563 - val_loss: 0.9712 - val_accuracy: 0.7250\n",
      "Epoch 144/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.9687 - accuracy: 0.7538 - val_loss: 0.9690 - val_accuracy: 0.7150\n",
      "Epoch 145/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.9674 - accuracy: 0.7563 - val_loss: 0.9668 - val_accuracy: 0.7150\n",
      "Epoch 146/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.9538 - accuracy: 0.79 - 0s 64us/step - loss: 0.9647 - accuracy: 0.7475 - val_loss: 0.9635 - val_accuracy: 0.7150\n",
      "Epoch 147/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.9635 - accuracy: 0.7650 - val_loss: 0.9651 - val_accuracy: 0.7200\n",
      "Epoch 148/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.9622 - accuracy: 0.7538 - val_loss: 0.9626 - val_accuracy: 0.7100\n",
      "Epoch 149/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.9600 - accuracy: 0.7550 - val_loss: 0.9649 - val_accuracy: 0.7200\n",
      "Epoch 150/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.9589 - accuracy: 0.7625 - val_loss: 0.9595 - val_accuracy: 0.7250\n",
      "Epoch 151/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.9569 - accuracy: 0.7588 - val_loss: 0.9565 - val_accuracy: 0.7250\n",
      "Epoch 152/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.9557 - accuracy: 0.7550 - val_loss: 0.9571 - val_accuracy: 0.7200\n",
      "Epoch 153/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.9531 - accuracy: 0.7600 - val_loss: 0.9531 - val_accuracy: 0.7250\n",
      "Epoch 154/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.9520 - accuracy: 0.7613 - val_loss: 0.9545 - val_accuracy: 0.7250\n",
      "Epoch 155/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.9508 - accuracy: 0.7625 - val_loss: 0.9520 - val_accuracy: 0.7200\n",
      "Epoch 156/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.9490 - accuracy: 0.7550 - val_loss: 0.9495 - val_accuracy: 0.7200\n",
      "Epoch 157/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.9472 - accuracy: 0.7638 - val_loss: 0.9472 - val_accuracy: 0.7200\n",
      "Epoch 158/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.9456 - accuracy: 0.7638 - val_loss: 0.9463 - val_accuracy: 0.7200\n",
      "Epoch 159/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.9439 - accuracy: 0.7613 - val_loss: 0.9447 - val_accuracy: 0.7200\n",
      "Epoch 160/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.9427 - accuracy: 0.7500 - val_loss: 0.9460 - val_accuracy: 0.7250\n",
      "Epoch 161/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.9403 - accuracy: 0.7550 - val_loss: 0.9432 - val_accuracy: 0.7300\n",
      "Epoch 162/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.9396 - accuracy: 0.7625 - val_loss: 0.9439 - val_accuracy: 0.7200\n",
      "Epoch 163/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.9378 - accuracy: 0.7613 - val_loss: 0.9401 - val_accuracy: 0.7250\n",
      "Epoch 164/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.9357 - accuracy: 0.7625 - val_loss: 0.9404 - val_accuracy: 0.7200\n",
      "Epoch 165/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.9350 - accuracy: 0.7663 - val_loss: 0.9388 - val_accuracy: 0.7350\n",
      "Epoch 166/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.9329 - accuracy: 0.7625 - val_loss: 0.9354 - val_accuracy: 0.7300\n",
      "Epoch 167/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.9313 - accuracy: 0.7650 - val_loss: 0.9343 - val_accuracy: 0.7250\n",
      "Epoch 168/3000\n",
      "800/800 [==============================] - 0s 60us/step - loss: 0.9295 - accuracy: 0.7638 - val_loss: 0.9340 - val_accuracy: 0.7250\n",
      "Epoch 169/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.9280 - accuracy: 0.7638 - val_loss: 0.9334 - val_accuracy: 0.7200\n",
      "Epoch 170/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.9273 - accuracy: 0.7775 - val_loss: 0.9312 - val_accuracy: 0.7300\n",
      "Epoch 171/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.9255 - accuracy: 0.7713 - val_loss: 0.9285 - val_accuracy: 0.7250\n",
      "Epoch 172/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.9237 - accuracy: 0.7688 - val_loss: 0.9272 - val_accuracy: 0.7300\n",
      "Epoch 173/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.9215 - accuracy: 0.7613 - val_loss: 0.9268 - val_accuracy: 0.7300\n",
      "Epoch 174/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.9207 - accuracy: 0.7725 - val_loss: 0.9265 - val_accuracy: 0.7250\n",
      "Epoch 175/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.9189 - accuracy: 0.7738 - val_loss: 0.9261 - val_accuracy: 0.7300\n",
      "Epoch 176/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.9175 - accuracy: 0.7663 - val_loss: 0.9246 - val_accuracy: 0.7300\n",
      "Epoch 177/3000\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.9158 - accuracy: 0.7663 - val_loss: 0.9210 - val_accuracy: 0.7300\n",
      "Epoch 178/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.9142 - accuracy: 0.7663 - val_loss: 0.9207 - val_accuracy: 0.7300\n",
      "Epoch 179/3000\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.9133 - accuracy: 0.7725 - val_loss: 0.9202 - val_accuracy: 0.7350\n",
      "Epoch 180/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.9111 - accuracy: 0.7725 - val_loss: 0.9173 - val_accuracy: 0.7250\n",
      "Epoch 181/3000\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.9098 - accuracy: 0.7700 - val_loss: 0.9179 - val_accuracy: 0.7300\n",
      "Epoch 182/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.9079 - accuracy: 0.7725 - val_loss: 0.9154 - val_accuracy: 0.7250\n",
      "Epoch 183/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.9067 - accuracy: 0.7688 - val_loss: 0.9133 - val_accuracy: 0.7350\n",
      "Epoch 184/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.9048 - accuracy: 0.7750 - val_loss: 0.9139 - val_accuracy: 0.7250\n",
      "Epoch 185/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.9042 - accuracy: 0.7675 - val_loss: 0.9118 - val_accuracy: 0.7300\n",
      "Epoch 186/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.9026 - accuracy: 0.7750 - val_loss: 0.9084 - val_accuracy: 0.7300\n",
      "Epoch 187/3000\n",
      "800/800 [==============================] - 0s 60us/step - loss: 0.9000 - accuracy: 0.7750 - val_loss: 0.9084 - val_accuracy: 0.7400\n",
      "Epoch 188/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.8988 - accuracy: 0.7713 - val_loss: 0.9073 - val_accuracy: 0.7400\n",
      "Epoch 189/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.8975 - accuracy: 0.7738 - val_loss: 0.9045 - val_accuracy: 0.7400\n",
      "Epoch 190/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.8963 - accuracy: 0.7700 - val_loss: 0.9035 - val_accuracy: 0.7400\n",
      "Epoch 191/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.8947 - accuracy: 0.7688 - val_loss: 0.9037 - val_accuracy: 0.7400\n",
      "Epoch 192/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.8931 - accuracy: 0.7763 - val_loss: 0.9036 - val_accuracy: 0.7350\n",
      "Epoch 193/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.8917 - accuracy: 0.7700 - val_loss: 0.8992 - val_accuracy: 0.7350\n",
      "Epoch 194/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.8896 - accuracy: 0.7775 - val_loss: 0.8993 - val_accuracy: 0.7350\n",
      "Epoch 195/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.8886 - accuracy: 0.7688 - val_loss: 0.8991 - val_accuracy: 0.7350\n",
      "Epoch 196/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.8872 - accuracy: 0.7763 - val_loss: 0.8970 - val_accuracy: 0.7400\n",
      "Epoch 197/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.8859 - accuracy: 0.7800 - val_loss: 0.8962 - val_accuracy: 0.7350\n",
      "Epoch 198/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.8842 - accuracy: 0.7763 - val_loss: 0.8938 - val_accuracy: 0.7300\n",
      "Epoch 199/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.9196 - accuracy: 0.73 - 0s 70us/step - loss: 0.8832 - accuracy: 0.7825 - val_loss: 0.8928 - val_accuracy: 0.7300\n",
      "Epoch 200/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.8816 - accuracy: 0.7812 - val_loss: 0.8940 - val_accuracy: 0.7350\n",
      "Epoch 201/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.8525 - accuracy: 0.81 - 0s 74us/step - loss: 0.8804 - accuracy: 0.7738 - val_loss: 0.8899 - val_accuracy: 0.7300\n",
      "Epoch 202/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.9456 - accuracy: 0.70 - 0s 80us/step - loss: 0.8785 - accuracy: 0.7700 - val_loss: 0.8896 - val_accuracy: 0.7350\n",
      "Epoch 203/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.8770 - accuracy: 0.7763 - val_loss: 0.8897 - val_accuracy: 0.7400\n",
      "Epoch 204/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.8762 - accuracy: 0.7788 - val_loss: 0.8873 - val_accuracy: 0.7300\n",
      "Epoch 205/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.8744 - accuracy: 0.7825 - val_loss: 0.8836 - val_accuracy: 0.7350\n",
      "Epoch 206/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.8733 - accuracy: 0.7775 - val_loss: 0.8839 - val_accuracy: 0.7300\n",
      "Epoch 207/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.8709 - accuracy: 0.7738 - val_loss: 0.8816 - val_accuracy: 0.7350\n",
      "Epoch 208/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.8700 - accuracy: 0.7775 - val_loss: 0.8841 - val_accuracy: 0.7300\n",
      "Epoch 209/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.9041 - accuracy: 0.79 - 0s 71us/step - loss: 0.8686 - accuracy: 0.7788 - val_loss: 0.8821 - val_accuracy: 0.7350\n",
      "Epoch 210/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.8669 - accuracy: 0.7700 - val_loss: 0.8793 - val_accuracy: 0.7400\n",
      "Epoch 211/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.8660 - accuracy: 0.7825 - val_loss: 0.8775 - val_accuracy: 0.7350\n",
      "Epoch 212/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.8644 - accuracy: 0.7788 - val_loss: 0.8775 - val_accuracy: 0.7400\n",
      "Epoch 213/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.8634 - accuracy: 0.7837 - val_loss: 0.8742 - val_accuracy: 0.7400\n",
      "Epoch 214/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.8616 - accuracy: 0.7775 - val_loss: 0.8746 - val_accuracy: 0.7350\n",
      "Epoch 215/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.8606 - accuracy: 0.7850 - val_loss: 0.8738 - val_accuracy: 0.7400\n",
      "Epoch 216/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.8594 - accuracy: 0.7837 - val_loss: 0.8735 - val_accuracy: 0.7400\n",
      "Epoch 217/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.8575 - accuracy: 0.7825 - val_loss: 0.8724 - val_accuracy: 0.7450\n",
      "Epoch 218/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.8559 - accuracy: 0.7812 - val_loss: 0.8692 - val_accuracy: 0.7400\n",
      "Epoch 219/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.8551 - accuracy: 0.7800 - val_loss: 0.8673 - val_accuracy: 0.7350\n",
      "Epoch 220/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.8532 - accuracy: 0.7812 - val_loss: 0.8659 - val_accuracy: 0.7450\n",
      "Epoch 221/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.8518 - accuracy: 0.7800 - val_loss: 0.8656 - val_accuracy: 0.7350\n",
      "Epoch 222/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.8504 - accuracy: 0.7812 - val_loss: 0.8658 - val_accuracy: 0.7400\n",
      "Epoch 223/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.8498 - accuracy: 0.7825 - val_loss: 0.8637 - val_accuracy: 0.7400\n",
      "Epoch 224/3000\n",
      "800/800 [==============================] - 0s 60us/step - loss: 0.8480 - accuracy: 0.7887 - val_loss: 0.8610 - val_accuracy: 0.7450\n",
      "Epoch 225/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.8463 - accuracy: 0.7875 - val_loss: 0.8619 - val_accuracy: 0.7350\n",
      "Epoch 226/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.8448 - accuracy: 0.7850 - val_loss: 0.8594 - val_accuracy: 0.7350\n",
      "Epoch 227/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.8436 - accuracy: 0.7837 - val_loss: 0.8620 - val_accuracy: 0.7400\n",
      "Epoch 228/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.8435 - accuracy: 0.7900 - val_loss: 0.8578 - val_accuracy: 0.7400\n",
      "Epoch 229/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.8408 - accuracy: 0.7912 - val_loss: 0.8557 - val_accuracy: 0.7400\n",
      "Epoch 230/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.8391 - accuracy: 0.7837 - val_loss: 0.8566 - val_accuracy: 0.7500\n",
      "Epoch 231/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.8380 - accuracy: 0.7825 - val_loss: 0.8553 - val_accuracy: 0.7500\n",
      "Epoch 232/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.8368 - accuracy: 0.7850 - val_loss: 0.8544 - val_accuracy: 0.7550\n",
      "Epoch 233/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.8360 - accuracy: 0.7887 - val_loss: 0.8522 - val_accuracy: 0.7450\n",
      "Epoch 234/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.8338 - accuracy: 0.7825 - val_loss: 0.8495 - val_accuracy: 0.7500\n",
      "Epoch 235/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.8330 - accuracy: 0.7875 - val_loss: 0.8488 - val_accuracy: 0.7400\n",
      "Epoch 236/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.8314 - accuracy: 0.7875 - val_loss: 0.8470 - val_accuracy: 0.7500\n",
      "Epoch 237/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.8309 - accuracy: 0.7887 - val_loss: 0.8463 - val_accuracy: 0.7400\n",
      "Epoch 238/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.8289 - accuracy: 0.7900 - val_loss: 0.8463 - val_accuracy: 0.7350\n",
      "Epoch 239/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.7183 - accuracy: 0.82 - 0s 74us/step - loss: 0.8272 - accuracy: 0.7837 - val_loss: 0.8458 - val_accuracy: 0.7400\n",
      "Epoch 240/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.8268 - accuracy: 0.7887 - val_loss: 0.8453 - val_accuracy: 0.7500\n",
      "Epoch 241/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.8246 - accuracy: 0.7900 - val_loss: 0.8428 - val_accuracy: 0.7600\n",
      "Epoch 242/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.8243 - accuracy: 0.7887 - val_loss: 0.8430 - val_accuracy: 0.7450\n",
      "Epoch 243/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.8224 - accuracy: 0.7925 - val_loss: 0.8405 - val_accuracy: 0.7550\n",
      "Epoch 244/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.8206 - accuracy: 0.7900 - val_loss: 0.8380 - val_accuracy: 0.7500\n",
      "Epoch 245/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.8200 - accuracy: 0.7875 - val_loss: 0.8373 - val_accuracy: 0.7400\n",
      "Epoch 246/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.8182 - accuracy: 0.7937 - val_loss: 0.8377 - val_accuracy: 0.7400\n",
      "Epoch 247/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.8170 - accuracy: 0.7887 - val_loss: 0.8360 - val_accuracy: 0.7550\n",
      "Epoch 248/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.8158 - accuracy: 0.7925 - val_loss: 0.8348 - val_accuracy: 0.7500\n",
      "Epoch 249/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.8146 - accuracy: 0.7925 - val_loss: 0.8334 - val_accuracy: 0.7450\n",
      "Epoch 250/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.8126 - accuracy: 0.7912 - val_loss: 0.8315 - val_accuracy: 0.7400\n",
      "Epoch 251/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.8121 - accuracy: 0.7900 - val_loss: 0.8316 - val_accuracy: 0.7500\n",
      "Epoch 252/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.8106 - accuracy: 0.7925 - val_loss: 0.8293 - val_accuracy: 0.7400\n",
      "Epoch 253/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.8092 - accuracy: 0.7900 - val_loss: 0.8284 - val_accuracy: 0.7550\n",
      "Epoch 254/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.8070 - accuracy: 0.7937 - val_loss: 0.8314 - val_accuracy: 0.7450\n",
      "Epoch 255/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.8069 - accuracy: 0.7925 - val_loss: 0.8270 - val_accuracy: 0.7400\n",
      "Epoch 256/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.8045 - accuracy: 0.7950 - val_loss: 0.8246 - val_accuracy: 0.7600\n",
      "Epoch 257/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.8040 - accuracy: 0.7987 - val_loss: 0.8241 - val_accuracy: 0.7550\n",
      "Epoch 258/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.8030 - accuracy: 0.7875 - val_loss: 0.8244 - val_accuracy: 0.7550\n",
      "Epoch 259/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.8008 - accuracy: 0.7937 - val_loss: 0.8247 - val_accuracy: 0.7600\n",
      "Epoch 260/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.8007 - accuracy: 0.7925 - val_loss: 0.8222 - val_accuracy: 0.7550\n",
      "Epoch 261/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.7982 - accuracy: 0.7912 - val_loss: 0.8211 - val_accuracy: 0.7550\n",
      "Epoch 262/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.7978 - accuracy: 0.7937 - val_loss: 0.8197 - val_accuracy: 0.7500\n",
      "Epoch 263/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.7961 - accuracy: 0.7962 - val_loss: 0.8199 - val_accuracy: 0.7600\n",
      "Epoch 264/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.7823 - accuracy: 0.82 - 0s 83us/step - loss: 0.7953 - accuracy: 0.7950 - val_loss: 0.8175 - val_accuracy: 0.7550\n",
      "Epoch 265/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.7931 - accuracy: 0.7937 - val_loss: 0.8185 - val_accuracy: 0.7500\n",
      "Epoch 266/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.7922 - accuracy: 0.7962 - val_loss: 0.8153 - val_accuracy: 0.7600\n",
      "Epoch 267/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.7893 - accuracy: 0.81 - 0s 79us/step - loss: 0.7916 - accuracy: 0.7975 - val_loss: 0.8134 - val_accuracy: 0.7550\n",
      "Epoch 268/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.7903 - accuracy: 0.7950 - val_loss: 0.8137 - val_accuracy: 0.7600\n",
      "Epoch 269/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.7889 - accuracy: 0.7975 - val_loss: 0.8130 - val_accuracy: 0.7600\n",
      "Epoch 270/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.7878 - accuracy: 0.8025 - val_loss: 0.8100 - val_accuracy: 0.7550\n",
      "Epoch 271/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.7860 - accuracy: 0.7937 - val_loss: 0.8086 - val_accuracy: 0.7450\n",
      "Epoch 272/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.7850 - accuracy: 0.7962 - val_loss: 0.8087 - val_accuracy: 0.7600\n",
      "Epoch 273/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.7836 - accuracy: 0.7975 - val_loss: 0.8116 - val_accuracy: 0.7750\n",
      "Epoch 274/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.7827 - accuracy: 0.7950 - val_loss: 0.8073 - val_accuracy: 0.7800\n",
      "Epoch 275/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.7819 - accuracy: 0.7950 - val_loss: 0.8043 - val_accuracy: 0.7650\n",
      "Epoch 276/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.7797 - accuracy: 0.8012 - val_loss: 0.8042 - val_accuracy: 0.7600\n",
      "Epoch 277/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.7789 - accuracy: 0.7937 - val_loss: 0.8036 - val_accuracy: 0.7600\n",
      "Epoch 278/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.7774 - accuracy: 0.7950 - val_loss: 0.8035 - val_accuracy: 0.7600\n",
      "Epoch 279/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.7764 - accuracy: 0.7975 - val_loss: 0.8034 - val_accuracy: 0.7650\n",
      "Epoch 280/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.7753 - accuracy: 0.7987 - val_loss: 0.7996 - val_accuracy: 0.7600\n",
      "Epoch 281/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.7737 - accuracy: 0.7987 - val_loss: 0.7993 - val_accuracy: 0.7550\n",
      "Epoch 282/3000\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.7737 - accuracy: 0.7950 - val_loss: 0.7976 - val_accuracy: 0.7550\n",
      "Epoch 283/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.7712 - accuracy: 0.7975 - val_loss: 0.7989 - val_accuracy: 0.7650\n",
      "Epoch 284/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.7706 - accuracy: 0.8012 - val_loss: 0.7965 - val_accuracy: 0.7600\n",
      "Epoch 285/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.7696 - accuracy: 0.8000 - val_loss: 0.7950 - val_accuracy: 0.7600\n",
      "Epoch 286/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.7679 - accuracy: 0.7962 - val_loss: 0.7944 - val_accuracy: 0.7550\n",
      "Epoch 287/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.7673 - accuracy: 0.7975 - val_loss: 0.7929 - val_accuracy: 0.7600\n",
      "Epoch 288/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.7652 - accuracy: 0.7987 - val_loss: 0.7922 - val_accuracy: 0.7600\n",
      "Epoch 289/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.7643 - accuracy: 0.8012 - val_loss: 0.7925 - val_accuracy: 0.7650\n",
      "Epoch 290/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.7638 - accuracy: 0.8050 - val_loss: 0.7887 - val_accuracy: 0.7650\n",
      "Epoch 291/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.7620 - accuracy: 0.7975 - val_loss: 0.7914 - val_accuracy: 0.7900\n",
      "Epoch 292/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.7616 - accuracy: 0.8037 - val_loss: 0.7886 - val_accuracy: 0.7650\n",
      "Epoch 293/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.7603 - accuracy: 0.7975 - val_loss: 0.7880 - val_accuracy: 0.7700\n",
      "Epoch 294/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.7583 - accuracy: 0.7987 - val_loss: 0.7894 - val_accuracy: 0.7800\n",
      "Epoch 295/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.7581 - accuracy: 0.8012 - val_loss: 0.7882 - val_accuracy: 0.7650\n",
      "Epoch 296/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.7558 - accuracy: 0.8050 - val_loss: 0.7833 - val_accuracy: 0.7550\n",
      "Epoch 297/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.7552 - accuracy: 0.8025 - val_loss: 0.7816 - val_accuracy: 0.7600\n",
      "Epoch 298/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.7539 - accuracy: 0.7987 - val_loss: 0.7806 - val_accuracy: 0.7600\n",
      "Epoch 299/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.7532 - accuracy: 0.7975 - val_loss: 0.7827 - val_accuracy: 0.7650\n",
      "Epoch 300/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.7513 - accuracy: 0.8025 - val_loss: 0.7797 - val_accuracy: 0.7600\n",
      "Epoch 301/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.7501 - accuracy: 0.8025 - val_loss: 0.7808 - val_accuracy: 0.7650\n",
      "Epoch 302/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.7491 - accuracy: 0.8050 - val_loss: 0.7774 - val_accuracy: 0.7650\n",
      "Epoch 303/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.7488 - accuracy: 0.8000 - val_loss: 0.7765 - val_accuracy: 0.7650\n",
      "Epoch 304/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.7473 - accuracy: 0.8012 - val_loss: 0.7761 - val_accuracy: 0.7600\n",
      "Epoch 305/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.7462 - accuracy: 0.8012 - val_loss: 0.7755 - val_accuracy: 0.7700\n",
      "Epoch 306/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.7440 - accuracy: 0.8000 - val_loss: 0.7747 - val_accuracy: 0.7650\n",
      "Epoch 307/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.7438 - accuracy: 0.8062 - val_loss: 0.7725 - val_accuracy: 0.7650\n",
      "Epoch 308/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.7433 - accuracy: 0.8037 - val_loss: 0.7720 - val_accuracy: 0.7700\n",
      "Epoch 309/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.7345 - accuracy: 0.78 - 0s 78us/step - loss: 0.7412 - accuracy: 0.8025 - val_loss: 0.7711 - val_accuracy: 0.7750\n",
      "Epoch 310/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.7399 - accuracy: 0.8037 - val_loss: 0.7706 - val_accuracy: 0.7700\n",
      "Epoch 311/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.7394 - accuracy: 0.8075 - val_loss: 0.7707 - val_accuracy: 0.7850\n",
      "Epoch 312/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.7378 - accuracy: 0.8112 - val_loss: 0.7666 - val_accuracy: 0.7750\n",
      "Epoch 313/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.7371 - accuracy: 0.8050 - val_loss: 0.7690 - val_accuracy: 0.7800\n",
      "Epoch 314/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.7359 - accuracy: 0.8037 - val_loss: 0.7668 - val_accuracy: 0.7850\n",
      "Epoch 315/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.7342 - accuracy: 0.8087 - val_loss: 0.7672 - val_accuracy: 0.7800\n",
      "Epoch 316/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.7310 - accuracy: 0.84 - 0s 74us/step - loss: 0.7337 - accuracy: 0.8037 - val_loss: 0.7665 - val_accuracy: 0.7750\n",
      "Epoch 317/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.7324 - accuracy: 0.8062 - val_loss: 0.7651 - val_accuracy: 0.7800\n",
      "Epoch 318/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.7311 - accuracy: 0.8025 - val_loss: 0.7653 - val_accuracy: 0.7750\n",
      "Epoch 319/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.7300 - accuracy: 0.8025 - val_loss: 0.7633 - val_accuracy: 0.7700\n",
      "Epoch 320/3000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.7291 - accuracy: 0.8075 - val_loss: 0.7589 - val_accuracy: 0.7650\n",
      "Epoch 321/3000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 0.7287 - accuracy: 0.8025 - val_loss: 0.7579 - val_accuracy: 0.7650\n",
      "Epoch 322/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.7271 - accuracy: 0.8062 - val_loss: 0.7589 - val_accuracy: 0.7850\n",
      "Epoch 323/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.7257 - accuracy: 0.8062 - val_loss: 0.7577 - val_accuracy: 0.7700\n",
      "Epoch 324/3000\n",
      "800/800 [==============================] - 0s 158us/step - loss: 0.7245 - accuracy: 0.8000 - val_loss: 0.7586 - val_accuracy: 0.7750\n",
      "Epoch 325/3000\n",
      "800/800 [==============================] - 0s 135us/step - loss: 0.7240 - accuracy: 0.8075 - val_loss: 0.7594 - val_accuracy: 0.7800\n",
      "Epoch 326/3000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 0.7229 - accuracy: 0.8087 - val_loss: 0.7566 - val_accuracy: 0.7750\n",
      "Epoch 327/3000\n",
      "800/800 [==============================] - 0s 223us/step - loss: 0.7227 - accuracy: 0.8050 - val_loss: 0.7550 - val_accuracy: 0.7750\n",
      "Epoch 328/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.7170 - accuracy: 0.81 - 0s 225us/step - loss: 0.7195 - accuracy: 0.8075 - val_loss: 0.7542 - val_accuracy: 0.7850\n",
      "Epoch 329/3000\n",
      "800/800 [==============================] - 0s 169us/step - loss: 0.7197 - accuracy: 0.8075 - val_loss: 0.7519 - val_accuracy: 0.7750\n",
      "Epoch 330/3000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 0.7185 - accuracy: 0.8062 - val_loss: 0.7522 - val_accuracy: 0.7850\n",
      "Epoch 331/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.7163 - accuracy: 0.8112 - val_loss: 0.7513 - val_accuracy: 0.7750\n",
      "Epoch 332/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.7164 - accuracy: 0.8050 - val_loss: 0.7500 - val_accuracy: 0.7700\n",
      "Epoch 333/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.7338 - accuracy: 0.80 - 0s 114us/step - loss: 0.7153 - accuracy: 0.8050 - val_loss: 0.7501 - val_accuracy: 0.7850\n",
      "Epoch 334/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.7143 - accuracy: 0.8075 - val_loss: 0.7487 - val_accuracy: 0.7750\n",
      "Epoch 335/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.7122 - accuracy: 0.8087 - val_loss: 0.7481 - val_accuracy: 0.7850\n",
      "Epoch 336/3000\n",
      "800/800 [==============================] - 0s 141us/step - loss: 0.7120 - accuracy: 0.8062 - val_loss: 0.7477 - val_accuracy: 0.7750\n",
      "Epoch 337/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.7107 - accuracy: 0.8075 - val_loss: 0.7442 - val_accuracy: 0.7750\n",
      "Epoch 338/3000\n",
      "800/800 [==============================] - 0s 135us/step - loss: 0.7093 - accuracy: 0.8138 - val_loss: 0.7436 - val_accuracy: 0.7750\n",
      "Epoch 339/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.7084 - accuracy: 0.8062 - val_loss: 0.7425 - val_accuracy: 0.7750\n",
      "Epoch 340/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.7079 - accuracy: 0.8075 - val_loss: 0.7407 - val_accuracy: 0.7800\n",
      "Epoch 341/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.7065 - accuracy: 0.8150 - val_loss: 0.7414 - val_accuracy: 0.7800\n",
      "Epoch 342/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.7055 - accuracy: 0.8062 - val_loss: 0.7432 - val_accuracy: 0.7700\n",
      "Epoch 343/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.7046 - accuracy: 0.8100 - val_loss: 0.7404 - val_accuracy: 0.7800\n",
      "Epoch 344/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.7035 - accuracy: 0.8125 - val_loss: 0.7404 - val_accuracy: 0.7800\n",
      "Epoch 345/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.7018 - accuracy: 0.8138 - val_loss: 0.7366 - val_accuracy: 0.7750\n",
      "Epoch 346/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.7323 - accuracy: 0.78 - 0s 71us/step - loss: 0.7012 - accuracy: 0.8138 - val_loss: 0.7349 - val_accuracy: 0.7700\n",
      "Epoch 347/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.7003 - accuracy: 0.8037 - val_loss: 0.7353 - val_accuracy: 0.7800\n",
      "Epoch 348/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.6990 - accuracy: 0.8112 - val_loss: 0.7345 - val_accuracy: 0.7800\n",
      "Epoch 349/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.6978 - accuracy: 0.8125 - val_loss: 0.7344 - val_accuracy: 0.7800\n",
      "Epoch 350/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.6968 - accuracy: 0.8125 - val_loss: 0.7330 - val_accuracy: 0.7800\n",
      "Epoch 351/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.6956 - accuracy: 0.8138 - val_loss: 0.7337 - val_accuracy: 0.7900\n",
      "Epoch 352/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.6950 - accuracy: 0.8150 - val_loss: 0.7330 - val_accuracy: 0.7900\n",
      "Epoch 353/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.6942 - accuracy: 0.8175 - val_loss: 0.7308 - val_accuracy: 0.7850\n",
      "Epoch 354/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.6931 - accuracy: 0.8188 - val_loss: 0.7294 - val_accuracy: 0.7750\n",
      "Epoch 355/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.6219 - accuracy: 0.81 - 0s 78us/step - loss: 0.6923 - accuracy: 0.8188 - val_loss: 0.7298 - val_accuracy: 0.7800\n",
      "Epoch 356/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.6464 - accuracy: 0.85 - 0s 78us/step - loss: 0.6912 - accuracy: 0.8150 - val_loss: 0.7298 - val_accuracy: 0.7800\n",
      "Epoch 357/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.7119 - accuracy: 0.81 - 0s 71us/step - loss: 0.6896 - accuracy: 0.8100 - val_loss: 0.7304 - val_accuracy: 0.7900\n",
      "Epoch 358/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.6887 - accuracy: 0.8175 - val_loss: 0.7272 - val_accuracy: 0.7850\n",
      "Epoch 359/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.6878 - accuracy: 0.8125 - val_loss: 0.7260 - val_accuracy: 0.7850\n",
      "Epoch 360/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.6865 - accuracy: 0.8100 - val_loss: 0.7263 - val_accuracy: 0.7850\n",
      "Epoch 361/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.6858 - accuracy: 0.8175 - val_loss: 0.7244 - val_accuracy: 0.7800\n",
      "Epoch 362/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.6850 - accuracy: 0.8150 - val_loss: 0.7230 - val_accuracy: 0.7900\n",
      "Epoch 363/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.6837 - accuracy: 0.8163 - val_loss: 0.7210 - val_accuracy: 0.7800\n",
      "Epoch 364/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.6826 - accuracy: 0.8075 - val_loss: 0.7218 - val_accuracy: 0.7750\n",
      "Epoch 365/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.6818 - accuracy: 0.8112 - val_loss: 0.7207 - val_accuracy: 0.7800\n",
      "Epoch 366/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.6747 - accuracy: 0.81 - 0s 78us/step - loss: 0.6806 - accuracy: 0.8175 - val_loss: 0.7207 - val_accuracy: 0.7900\n",
      "Epoch 367/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.6798 - accuracy: 0.8112 - val_loss: 0.7182 - val_accuracy: 0.7800\n",
      "Epoch 368/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.6787 - accuracy: 0.8175 - val_loss: 0.7190 - val_accuracy: 0.7750\n",
      "Epoch 369/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.6776 - accuracy: 0.8150 - val_loss: 0.7158 - val_accuracy: 0.7850\n",
      "Epoch 370/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.6769 - accuracy: 0.8100 - val_loss: 0.7164 - val_accuracy: 0.7750\n",
      "Epoch 371/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.6752 - accuracy: 0.8175 - val_loss: 0.7174 - val_accuracy: 0.7900\n",
      "Epoch 372/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.6749 - accuracy: 0.8250 - val_loss: 0.7146 - val_accuracy: 0.7750\n",
      "Epoch 373/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.6741 - accuracy: 0.8225 - val_loss: 0.7139 - val_accuracy: 0.7750\n",
      "Epoch 374/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.6738 - accuracy: 0.8163 - val_loss: 0.7134 - val_accuracy: 0.7900\n",
      "Epoch 375/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.6719 - accuracy: 0.8200 - val_loss: 0.7129 - val_accuracy: 0.7950\n",
      "Epoch 376/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.6707 - accuracy: 0.8150 - val_loss: 0.7120 - val_accuracy: 0.7800\n",
      "Epoch 377/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.6691 - accuracy: 0.8238 - val_loss: 0.7100 - val_accuracy: 0.7900\n",
      "Epoch 378/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.6692 - accuracy: 0.8087 - val_loss: 0.7105 - val_accuracy: 0.7850\n",
      "Epoch 379/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.6686 - accuracy: 0.8200 - val_loss: 0.7084 - val_accuracy: 0.7750\n",
      "Epoch 380/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.6674 - accuracy: 0.8225 - val_loss: 0.7075 - val_accuracy: 0.7950\n",
      "Epoch 381/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.6663 - accuracy: 0.8163 - val_loss: 0.7077 - val_accuracy: 0.7850\n",
      "Epoch 382/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.6657 - accuracy: 0.8225 - val_loss: 0.7061 - val_accuracy: 0.8000\n",
      "Epoch 383/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.6648 - accuracy: 0.8200 - val_loss: 0.7068 - val_accuracy: 0.7950\n",
      "Epoch 384/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.6640 - accuracy: 0.8163 - val_loss: 0.7056 - val_accuracy: 0.7800\n",
      "Epoch 385/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.6627 - accuracy: 0.8225 - val_loss: 0.7040 - val_accuracy: 0.7800\n",
      "Epoch 386/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.6612 - accuracy: 0.8250 - val_loss: 0.7028 - val_accuracy: 0.7950\n",
      "Epoch 387/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.6606 - accuracy: 0.8200 - val_loss: 0.7015 - val_accuracy: 0.7850\n",
      "Epoch 388/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.6599 - accuracy: 0.8175 - val_loss: 0.7022 - val_accuracy: 0.7950\n",
      "Epoch 389/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.6588 - accuracy: 0.8213 - val_loss: 0.7030 - val_accuracy: 0.7950\n",
      "Epoch 390/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.6582 - accuracy: 0.8238 - val_loss: 0.6990 - val_accuracy: 0.7900\n",
      "Epoch 391/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.6573 - accuracy: 0.8238 - val_loss: 0.7000 - val_accuracy: 0.7950\n",
      "Epoch 392/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.6555 - accuracy: 0.8225 - val_loss: 0.6999 - val_accuracy: 0.7950\n",
      "Epoch 393/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.6545 - accuracy: 0.8238 - val_loss: 0.6968 - val_accuracy: 0.8050\n",
      "Epoch 394/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.6547 - accuracy: 0.8213 - val_loss: 0.6971 - val_accuracy: 0.8000\n",
      "Epoch 395/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.6530 - accuracy: 0.8225 - val_loss: 0.6967 - val_accuracy: 0.7950\n",
      "Epoch 396/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.6522 - accuracy: 0.8250 - val_loss: 0.6950 - val_accuracy: 0.7900\n",
      "Epoch 397/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.6520 - accuracy: 0.8238 - val_loss: 0.6952 - val_accuracy: 0.7850\n",
      "Epoch 398/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.6498 - accuracy: 0.8238 - val_loss: 0.6942 - val_accuracy: 0.7900\n",
      "Epoch 399/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.6497 - accuracy: 0.8263 - val_loss: 0.6932 - val_accuracy: 0.7800\n",
      "Epoch 400/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.6482 - accuracy: 0.8238 - val_loss: 0.6957 - val_accuracy: 0.7900\n",
      "Epoch 401/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.6481 - accuracy: 0.8238 - val_loss: 0.6930 - val_accuracy: 0.7950\n",
      "Epoch 402/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.6469 - accuracy: 0.8238 - val_loss: 0.6900 - val_accuracy: 0.7950\n",
      "Epoch 403/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.6460 - accuracy: 0.8238 - val_loss: 0.6903 - val_accuracy: 0.7900\n",
      "Epoch 404/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.6585 - accuracy: 0.85 - 0s 78us/step - loss: 0.6452 - accuracy: 0.8200 - val_loss: 0.6889 - val_accuracy: 0.8000\n",
      "Epoch 405/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.6439 - accuracy: 0.8313 - val_loss: 0.6891 - val_accuracy: 0.7900\n",
      "Epoch 406/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.6430 - accuracy: 0.8238 - val_loss: 0.6885 - val_accuracy: 0.7950\n",
      "Epoch 407/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.6424 - accuracy: 0.8213 - val_loss: 0.6864 - val_accuracy: 0.7850\n",
      "Epoch 408/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.6419 - accuracy: 0.8225 - val_loss: 0.6858 - val_accuracy: 0.7900\n",
      "Epoch 409/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.6403 - accuracy: 0.8263 - val_loss: 0.6853 - val_accuracy: 0.8000\n",
      "Epoch 410/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.6400 - accuracy: 0.8250 - val_loss: 0.6864 - val_accuracy: 0.7850\n",
      "Epoch 411/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.6399 - accuracy: 0.8188 - val_loss: 0.6834 - val_accuracy: 0.8000\n",
      "Epoch 412/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.6381 - accuracy: 0.8263 - val_loss: 0.6831 - val_accuracy: 0.8000\n",
      "Epoch 413/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.6372 - accuracy: 0.8250 - val_loss: 0.6828 - val_accuracy: 0.8000\n",
      "Epoch 414/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.6373 - accuracy: 0.8263 - val_loss: 0.6814 - val_accuracy: 0.7950\n",
      "Epoch 415/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.6356 - accuracy: 0.8313 - val_loss: 0.6812 - val_accuracy: 0.7900\n",
      "Epoch 416/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.6353 - accuracy: 0.8263 - val_loss: 0.6811 - val_accuracy: 0.7900\n",
      "Epoch 417/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.6336 - accuracy: 0.8288 - val_loss: 0.6802 - val_accuracy: 0.8000\n",
      "Epoch 418/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.6333 - accuracy: 0.8300 - val_loss: 0.6789 - val_accuracy: 0.7900\n",
      "Epoch 419/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.6316 - accuracy: 0.8288 - val_loss: 0.6790 - val_accuracy: 0.8000\n",
      "Epoch 420/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.6315 - accuracy: 0.8300 - val_loss: 0.6773 - val_accuracy: 0.8100\n",
      "Epoch 421/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.6304 - accuracy: 0.8263 - val_loss: 0.6758 - val_accuracy: 0.8000\n",
      "Epoch 422/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.6301 - accuracy: 0.8288 - val_loss: 0.6762 - val_accuracy: 0.8050\n",
      "Epoch 423/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.6297 - accuracy: 0.8275 - val_loss: 0.6758 - val_accuracy: 0.8000\n",
      "Epoch 424/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.6271 - accuracy: 0.8288 - val_loss: 0.6732 - val_accuracy: 0.7950\n",
      "Epoch 425/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.6272 - accuracy: 0.8250 - val_loss: 0.6723 - val_accuracy: 0.7950\n",
      "Epoch 426/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.6267 - accuracy: 0.8313 - val_loss: 0.6720 - val_accuracy: 0.8100\n",
      "Epoch 427/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.6261 - accuracy: 0.8263 - val_loss: 0.6713 - val_accuracy: 0.8100\n",
      "Epoch 428/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.6245 - accuracy: 0.8288 - val_loss: 0.6701 - val_accuracy: 0.8050\n",
      "Epoch 429/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.6244 - accuracy: 0.8250 - val_loss: 0.6709 - val_accuracy: 0.8000\n",
      "Epoch 430/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.6226 - accuracy: 0.8250 - val_loss: 0.6699 - val_accuracy: 0.7950\n",
      "Epoch 431/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.6221 - accuracy: 0.8300 - val_loss: 0.6691 - val_accuracy: 0.7950\n",
      "Epoch 432/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.6207 - accuracy: 0.8275 - val_loss: 0.6704 - val_accuracy: 0.7900\n",
      "Epoch 433/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.6200 - accuracy: 0.8338 - val_loss: 0.6678 - val_accuracy: 0.8000\n",
      "Epoch 434/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.6194 - accuracy: 0.8313 - val_loss: 0.6666 - val_accuracy: 0.8100\n",
      "Epoch 435/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.6190 - accuracy: 0.8275 - val_loss: 0.6662 - val_accuracy: 0.8050\n",
      "Epoch 436/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.6177 - accuracy: 0.8300 - val_loss: 0.6652 - val_accuracy: 0.8100\n",
      "Epoch 437/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.6165 - accuracy: 0.8288 - val_loss: 0.6644 - val_accuracy: 0.7950\n",
      "Epoch 438/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.6163 - accuracy: 0.8338 - val_loss: 0.6638 - val_accuracy: 0.7950\n",
      "Epoch 439/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.6155 - accuracy: 0.8275 - val_loss: 0.6634 - val_accuracy: 0.8100\n",
      "Epoch 440/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.6150 - accuracy: 0.8325 - val_loss: 0.6627 - val_accuracy: 0.8050\n",
      "Epoch 441/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.6131 - accuracy: 0.8325 - val_loss: 0.6631 - val_accuracy: 0.7950\n",
      "Epoch 442/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.6128 - accuracy: 0.8288 - val_loss: 0.6606 - val_accuracy: 0.8000\n",
      "Epoch 443/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.6124 - accuracy: 0.8275 - val_loss: 0.6618 - val_accuracy: 0.8000\n",
      "Epoch 444/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.6110 - accuracy: 0.8313 - val_loss: 0.6626 - val_accuracy: 0.8000\n",
      "Epoch 445/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.6103 - accuracy: 0.8275 - val_loss: 0.6589 - val_accuracy: 0.8000\n",
      "Epoch 446/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.6101 - accuracy: 0.8300 - val_loss: 0.6584 - val_accuracy: 0.8050\n",
      "Epoch 447/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.6089 - accuracy: 0.8288 - val_loss: 0.6580 - val_accuracy: 0.8000\n",
      "Epoch 448/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.6077 - accuracy: 0.8300 - val_loss: 0.6585 - val_accuracy: 0.8100\n",
      "Epoch 449/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.6076 - accuracy: 0.8288 - val_loss: 0.6573 - val_accuracy: 0.8100\n",
      "Epoch 450/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.6060 - accuracy: 0.8325 - val_loss: 0.6540 - val_accuracy: 0.8050\n",
      "Epoch 451/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.6054 - accuracy: 0.8338 - val_loss: 0.6550 - val_accuracy: 0.8000\n",
      "Epoch 452/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.6052 - accuracy: 0.8313 - val_loss: 0.6538 - val_accuracy: 0.8050\n",
      "Epoch 453/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.6037 - accuracy: 0.8300 - val_loss: 0.6530 - val_accuracy: 0.8100\n",
      "Epoch 454/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.6040 - accuracy: 0.8325 - val_loss: 0.6528 - val_accuracy: 0.8100\n",
      "Epoch 455/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.6034 - accuracy: 0.8288 - val_loss: 0.6519 - val_accuracy: 0.8100\n",
      "Epoch 456/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.6017 - accuracy: 0.8313 - val_loss: 0.6524 - val_accuracy: 0.8050\n",
      "Epoch 457/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.6010 - accuracy: 0.8338 - val_loss: 0.6507 - val_accuracy: 0.8100\n",
      "Epoch 458/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.6006 - accuracy: 0.8350 - val_loss: 0.6499 - val_accuracy: 0.8100\n",
      "Epoch 459/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.5989 - accuracy: 0.8338 - val_loss: 0.6498 - val_accuracy: 0.8100\n",
      "Epoch 460/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.5987 - accuracy: 0.8275 - val_loss: 0.6485 - val_accuracy: 0.8100\n",
      "Epoch 461/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.5976 - accuracy: 0.8338 - val_loss: 0.6500 - val_accuracy: 0.8050\n",
      "Epoch 462/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.5981 - accuracy: 0.8325 - val_loss: 0.6479 - val_accuracy: 0.8100\n",
      "Epoch 463/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.5964 - accuracy: 0.8363 - val_loss: 0.6464 - val_accuracy: 0.8100\n",
      "Epoch 464/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.5952 - accuracy: 0.8350 - val_loss: 0.6494 - val_accuracy: 0.8100\n",
      "Epoch 465/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.5959 - accuracy: 0.8363 - val_loss: 0.6483 - val_accuracy: 0.8150\n",
      "Epoch 466/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.5942 - accuracy: 0.8338 - val_loss: 0.6478 - val_accuracy: 0.8150\n",
      "Epoch 467/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.5934 - accuracy: 0.8350 - val_loss: 0.6460 - val_accuracy: 0.8050\n",
      "Epoch 468/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.5926 - accuracy: 0.8350 - val_loss: 0.6441 - val_accuracy: 0.8100\n",
      "Epoch 469/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.5918 - accuracy: 0.8350 - val_loss: 0.6431 - val_accuracy: 0.8100\n",
      "Epoch 470/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.5905 - accuracy: 0.8338 - val_loss: 0.6443 - val_accuracy: 0.8100\n",
      "Epoch 471/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.5905 - accuracy: 0.8388 - val_loss: 0.6408 - val_accuracy: 0.8100\n",
      "Epoch 472/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.5897 - accuracy: 0.8350 - val_loss: 0.6403 - val_accuracy: 0.8100\n",
      "Epoch 473/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.5883 - accuracy: 0.8325 - val_loss: 0.6412 - val_accuracy: 0.8100\n",
      "Epoch 474/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.5880 - accuracy: 0.8338 - val_loss: 0.6393 - val_accuracy: 0.8050\n",
      "Epoch 475/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.5868 - accuracy: 0.8363 - val_loss: 0.6385 - val_accuracy: 0.8150\n",
      "Epoch 476/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.5869 - accuracy: 0.8363 - val_loss: 0.6415 - val_accuracy: 0.8250\n",
      "Epoch 477/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.5855 - accuracy: 0.8400 - val_loss: 0.6392 - val_accuracy: 0.8000\n",
      "Epoch 478/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.5847 - accuracy: 0.8375 - val_loss: 0.6372 - val_accuracy: 0.8050\n",
      "Epoch 479/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.5844 - accuracy: 0.8375 - val_loss: 0.6366 - val_accuracy: 0.8050\n",
      "Epoch 480/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.5838 - accuracy: 0.8388 - val_loss: 0.6355 - val_accuracy: 0.8150\n",
      "Epoch 481/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.5821 - accuracy: 0.8388 - val_loss: 0.6353 - val_accuracy: 0.8100\n",
      "Epoch 482/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.5429 - accuracy: 0.87 - 0s 79us/step - loss: 0.5822 - accuracy: 0.8400 - val_loss: 0.6358 - val_accuracy: 0.8150\n",
      "Epoch 483/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.5810 - accuracy: 0.8425 - val_loss: 0.6329 - val_accuracy: 0.8150\n",
      "Epoch 484/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.5801 - accuracy: 0.8375 - val_loss: 0.6323 - val_accuracy: 0.8200\n",
      "Epoch 485/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.6975 - accuracy: 0.81 - 0s 78us/step - loss: 0.5801 - accuracy: 0.8400 - val_loss: 0.6323 - val_accuracy: 0.8150\n",
      "Epoch 486/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.5789 - accuracy: 0.8388 - val_loss: 0.6304 - val_accuracy: 0.8050\n",
      "Epoch 487/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.5775 - accuracy: 0.8375 - val_loss: 0.6321 - val_accuracy: 0.8150\n",
      "Epoch 488/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.5777 - accuracy: 0.8388 - val_loss: 0.6300 - val_accuracy: 0.8150\n",
      "Epoch 489/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.5768 - accuracy: 0.8413 - val_loss: 0.6288 - val_accuracy: 0.8100\n",
      "Epoch 490/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.5757 - accuracy: 0.8363 - val_loss: 0.6316 - val_accuracy: 0.8100\n",
      "Epoch 491/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.5750 - accuracy: 0.8375 - val_loss: 0.6304 - val_accuracy: 0.8100\n",
      "Epoch 492/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.5748 - accuracy: 0.8400 - val_loss: 0.6286 - val_accuracy: 0.8150\n",
      "Epoch 493/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.5739 - accuracy: 0.8413 - val_loss: 0.6264 - val_accuracy: 0.8150\n",
      "Epoch 494/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.5729 - accuracy: 0.8375 - val_loss: 0.6279 - val_accuracy: 0.8150\n",
      "Epoch 495/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.5729 - accuracy: 0.8438 - val_loss: 0.6258 - val_accuracy: 0.8100\n",
      "Epoch 496/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.5718 - accuracy: 0.8413 - val_loss: 0.6251 - val_accuracy: 0.8150\n",
      "Epoch 497/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.5712 - accuracy: 0.8413 - val_loss: 0.6257 - val_accuracy: 0.8150\n",
      "Epoch 498/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.5698 - accuracy: 0.8400 - val_loss: 0.6241 - val_accuracy: 0.8100\n",
      "Epoch 499/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.5700 - accuracy: 0.8438 - val_loss: 0.6242 - val_accuracy: 0.8200\n",
      "Epoch 500/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.5697 - accuracy: 0.8350 - val_loss: 0.6249 - val_accuracy: 0.8150\n",
      "Epoch 501/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.5686 - accuracy: 0.8400 - val_loss: 0.6235 - val_accuracy: 0.8150\n",
      "Epoch 502/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.5678 - accuracy: 0.8438 - val_loss: 0.6236 - val_accuracy: 0.8200\n",
      "Epoch 503/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.5665 - accuracy: 0.8450 - val_loss: 0.6227 - val_accuracy: 0.8200\n",
      "Epoch 504/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.5658 - accuracy: 0.8388 - val_loss: 0.6206 - val_accuracy: 0.8200\n",
      "Epoch 505/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.5656 - accuracy: 0.8425 - val_loss: 0.6207 - val_accuracy: 0.8150\n",
      "Epoch 506/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.5645 - accuracy: 0.8462 - val_loss: 0.6213 - val_accuracy: 0.8150\n",
      "Epoch 507/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.5642 - accuracy: 0.8400 - val_loss: 0.6195 - val_accuracy: 0.8150\n",
      "Epoch 508/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.5632 - accuracy: 0.8475 - val_loss: 0.6195 - val_accuracy: 0.8200\n",
      "Epoch 509/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.5636 - accuracy: 0.8438 - val_loss: 0.6212 - val_accuracy: 0.8250\n",
      "Epoch 510/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.5618 - accuracy: 0.8512 - val_loss: 0.6173 - val_accuracy: 0.8200\n",
      "Epoch 511/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.5613 - accuracy: 0.8475 - val_loss: 0.6181 - val_accuracy: 0.8200\n",
      "Epoch 512/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.5606 - accuracy: 0.8438 - val_loss: 0.6168 - val_accuracy: 0.8200\n",
      "Epoch 513/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.5599 - accuracy: 0.8438 - val_loss: 0.6140 - val_accuracy: 0.8150\n",
      "Epoch 514/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.5602 - accuracy: 0.84 - 0s 90us/step - loss: 0.5596 - accuracy: 0.8462 - val_loss: 0.6143 - val_accuracy: 0.8200\n",
      "Epoch 515/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.5594 - accuracy: 0.8462 - val_loss: 0.6150 - val_accuracy: 0.8150\n",
      "Epoch 516/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.5581 - accuracy: 0.8475 - val_loss: 0.6150 - val_accuracy: 0.8150\n",
      "Epoch 517/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.5466 - accuracy: 0.85 - 0s 105us/step - loss: 0.5574 - accuracy: 0.8475 - val_loss: 0.6149 - val_accuracy: 0.8200\n",
      "Epoch 518/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.5564 - accuracy: 0.8500 - val_loss: 0.6136 - val_accuracy: 0.8200\n",
      "Epoch 519/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.5565 - accuracy: 0.8487 - val_loss: 0.6125 - val_accuracy: 0.8200\n",
      "Epoch 520/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.5546 - accuracy: 0.8425 - val_loss: 0.6109 - val_accuracy: 0.8250\n",
      "Epoch 521/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.5546 - accuracy: 0.8487 - val_loss: 0.6100 - val_accuracy: 0.8150\n",
      "Epoch 522/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.5539 - accuracy: 0.8475 - val_loss: 0.6116 - val_accuracy: 0.8200\n",
      "Epoch 523/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.5528 - accuracy: 0.8450 - val_loss: 0.6089 - val_accuracy: 0.8200\n",
      "Epoch 524/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.5526 - accuracy: 0.8450 - val_loss: 0.6105 - val_accuracy: 0.8200\n",
      "Epoch 525/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.5514 - accuracy: 0.8450 - val_loss: 0.6098 - val_accuracy: 0.8150\n",
      "Epoch 526/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.5518 - accuracy: 0.8462 - val_loss: 0.6100 - val_accuracy: 0.8150\n",
      "Epoch 527/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.5504 - accuracy: 0.8500 - val_loss: 0.6086 - val_accuracy: 0.8200\n",
      "Epoch 528/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.5496 - accuracy: 0.8475 - val_loss: 0.6062 - val_accuracy: 0.8100\n",
      "Epoch 529/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.5483 - accuracy: 0.8450 - val_loss: 0.6065 - val_accuracy: 0.8200\n",
      "Epoch 530/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.5487 - accuracy: 0.8500 - val_loss: 0.6046 - val_accuracy: 0.8250\n",
      "Epoch 531/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.5480 - accuracy: 0.8512 - val_loss: 0.6043 - val_accuracy: 0.8200\n",
      "Epoch 532/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.5467 - accuracy: 0.8512 - val_loss: 0.6047 - val_accuracy: 0.8200\n",
      "Epoch 533/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.5472 - accuracy: 0.8487 - val_loss: 0.6035 - val_accuracy: 0.8250\n",
      "Epoch 534/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.5458 - accuracy: 0.8487 - val_loss: 0.6029 - val_accuracy: 0.8200\n",
      "Epoch 535/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.5452 - accuracy: 0.8512 - val_loss: 0.6038 - val_accuracy: 0.8150\n",
      "Epoch 536/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.5451 - accuracy: 0.8512 - val_loss: 0.6018 - val_accuracy: 0.8200\n",
      "Epoch 537/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.5437 - accuracy: 0.8487 - val_loss: 0.6016 - val_accuracy: 0.8200\n",
      "Epoch 538/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.5434 - accuracy: 0.8462 - val_loss: 0.6007 - val_accuracy: 0.8200\n",
      "Epoch 539/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.5430 - accuracy: 0.8462 - val_loss: 0.6002 - val_accuracy: 0.8200\n",
      "Epoch 540/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.5576 - accuracy: 0.84 - 0s 169us/step - loss: 0.5430 - accuracy: 0.8487 - val_loss: 0.6009 - val_accuracy: 0.8200\n",
      "Epoch 541/3000\n",
      "800/800 [==============================] - 0s 136us/step - loss: 0.5412 - accuracy: 0.8525 - val_loss: 0.5998 - val_accuracy: 0.8200\n",
      "Epoch 542/3000\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.5409 - accuracy: 0.8537 - val_loss: 0.6009 - val_accuracy: 0.8250\n",
      "Epoch 543/3000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 0.5407 - accuracy: 0.8487 - val_loss: 0.5993 - val_accuracy: 0.8250\n",
      "Epoch 544/3000\n",
      "800/800 [==============================] - 0s 219us/step - loss: 0.5391 - accuracy: 0.8525 - val_loss: 0.5979 - val_accuracy: 0.8200\n",
      "Epoch 545/3000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 0.5385 - accuracy: 0.8512 - val_loss: 0.5970 - val_accuracy: 0.8150\n",
      "Epoch 546/3000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 0.5376 - accuracy: 0.8512 - val_loss: 0.5958 - val_accuracy: 0.8300\n",
      "Epoch 547/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.5629 - accuracy: 0.85 - 0s 218us/step - loss: 0.5372 - accuracy: 0.8512 - val_loss: 0.5986 - val_accuracy: 0.8250\n",
      "Epoch 548/3000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 0.5367 - accuracy: 0.8512 - val_loss: 0.5947 - val_accuracy: 0.8200\n",
      "Epoch 549/3000\n",
      "800/800 [==============================] - 0s 133us/step - loss: 0.5364 - accuracy: 0.8500 - val_loss: 0.5953 - val_accuracy: 0.8300\n",
      "Epoch 550/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.5356 - accuracy: 0.8512 - val_loss: 0.5944 - val_accuracy: 0.8200\n",
      "Epoch 551/3000\n",
      "800/800 [==============================] - 0s 131us/step - loss: 0.5356 - accuracy: 0.8525 - val_loss: 0.5940 - val_accuracy: 0.8300\n",
      "Epoch 552/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.5346 - accuracy: 0.8500 - val_loss: 0.5925 - val_accuracy: 0.8250\n",
      "Epoch 553/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4499 - accuracy: 0.87 - 0s 80us/step - loss: 0.5332 - accuracy: 0.8512 - val_loss: 0.5941 - val_accuracy: 0.8200\n",
      "Epoch 554/3000\n",
      "800/800 [==============================] - 0s 126us/step - loss: 0.5327 - accuracy: 0.8550 - val_loss: 0.5914 - val_accuracy: 0.8300\n",
      "Epoch 555/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.5326 - accuracy: 0.8550 - val_loss: 0.5914 - val_accuracy: 0.8250\n",
      "Epoch 556/3000\n",
      "800/800 [==============================] - 0s 141us/step - loss: 0.5321 - accuracy: 0.8537 - val_loss: 0.5912 - val_accuracy: 0.8200\n",
      "Epoch 557/3000\n",
      "800/800 [==============================] - 0s 139us/step - loss: 0.5316 - accuracy: 0.8550 - val_loss: 0.5908 - val_accuracy: 0.8250\n",
      "Epoch 558/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.5304 - accuracy: 0.8525 - val_loss: 0.5899 - val_accuracy: 0.8200\n",
      "Epoch 559/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.5303 - accuracy: 0.8475 - val_loss: 0.5895 - val_accuracy: 0.8250\n",
      "Epoch 560/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.5291 - accuracy: 0.8525 - val_loss: 0.5887 - val_accuracy: 0.8200\n",
      "Epoch 561/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.5291 - accuracy: 0.8525 - val_loss: 0.5884 - val_accuracy: 0.8200\n",
      "Epoch 562/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.5286 - accuracy: 0.8487 - val_loss: 0.5871 - val_accuracy: 0.8200\n",
      "Epoch 563/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.5276 - accuracy: 0.8562 - val_loss: 0.5876 - val_accuracy: 0.8250\n",
      "Epoch 564/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.5277 - accuracy: 0.8512 - val_loss: 0.5877 - val_accuracy: 0.8250\n",
      "Epoch 565/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.5262 - accuracy: 0.8537 - val_loss: 0.5885 - val_accuracy: 0.8250\n",
      "Epoch 566/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.5248 - accuracy: 0.8550 - val_loss: 0.5849 - val_accuracy: 0.8200\n",
      "Epoch 567/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.5260 - accuracy: 0.8537 - val_loss: 0.5846 - val_accuracy: 0.8300\n",
      "Epoch 568/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.5244 - accuracy: 0.8562 - val_loss: 0.5861 - val_accuracy: 0.8250\n",
      "Epoch 569/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.5244 - accuracy: 0.8537 - val_loss: 0.5853 - val_accuracy: 0.8250\n",
      "Epoch 570/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.5253 - accuracy: 0.85 - 0s 93us/step - loss: 0.5228 - accuracy: 0.8537 - val_loss: 0.5843 - val_accuracy: 0.8250\n",
      "Epoch 571/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.5228 - accuracy: 0.8575 - val_loss: 0.5848 - val_accuracy: 0.8300\n",
      "Epoch 572/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.5220 - accuracy: 0.8550 - val_loss: 0.5837 - val_accuracy: 0.8250\n",
      "Epoch 573/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.5217 - accuracy: 0.8562 - val_loss: 0.5817 - val_accuracy: 0.8200\n",
      "Epoch 574/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.5213 - accuracy: 0.8537 - val_loss: 0.5833 - val_accuracy: 0.8250\n",
      "Epoch 575/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.5205 - accuracy: 0.8600 - val_loss: 0.5814 - val_accuracy: 0.8200\n",
      "Epoch 576/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.5206 - accuracy: 0.8512 - val_loss: 0.5823 - val_accuracy: 0.8200\n",
      "Epoch 577/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.5190 - accuracy: 0.8550 - val_loss: 0.5792 - val_accuracy: 0.8300\n",
      "Epoch 578/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.5190 - accuracy: 0.8550 - val_loss: 0.5794 - val_accuracy: 0.8300\n",
      "Epoch 579/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.5184 - accuracy: 0.8587 - val_loss: 0.5805 - val_accuracy: 0.8250\n",
      "Epoch 580/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.5174 - accuracy: 0.8575 - val_loss: 0.5804 - val_accuracy: 0.8250\n",
      "Epoch 581/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.5167 - accuracy: 0.8525 - val_loss: 0.5808 - val_accuracy: 0.8250\n",
      "Epoch 582/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.5173 - accuracy: 0.8550 - val_loss: 0.5775 - val_accuracy: 0.8250\n",
      "Epoch 583/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.5162 - accuracy: 0.8600 - val_loss: 0.5767 - val_accuracy: 0.8300\n",
      "Epoch 584/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.5153 - accuracy: 0.8537 - val_loss: 0.5764 - val_accuracy: 0.8300\n",
      "Epoch 585/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.5146 - accuracy: 0.8575 - val_loss: 0.5762 - val_accuracy: 0.8250\n",
      "Epoch 586/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.5142 - accuracy: 0.8587 - val_loss: 0.5773 - val_accuracy: 0.8250\n",
      "Epoch 587/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.5132 - accuracy: 0.8587 - val_loss: 0.5760 - val_accuracy: 0.8250\n",
      "Epoch 588/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.5125 - accuracy: 0.8600 - val_loss: 0.5776 - val_accuracy: 0.8250\n",
      "Epoch 589/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.5130 - accuracy: 0.8587 - val_loss: 0.5773 - val_accuracy: 0.8250\n",
      "Epoch 590/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.5121 - accuracy: 0.8537 - val_loss: 0.5745 - val_accuracy: 0.8250\n",
      "Epoch 591/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.5109 - accuracy: 0.8575 - val_loss: 0.5730 - val_accuracy: 0.8350\n",
      "Epoch 592/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.5108 - accuracy: 0.8537 - val_loss: 0.5739 - val_accuracy: 0.8300\n",
      "Epoch 593/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.5105 - accuracy: 0.8575 - val_loss: 0.5712 - val_accuracy: 0.8250\n",
      "Epoch 594/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.5094 - accuracy: 0.8575 - val_loss: 0.5712 - val_accuracy: 0.8200\n",
      "Epoch 595/3000\n",
      "800/800 [==============================] - 0s 124us/step - loss: 0.5086 - accuracy: 0.8537 - val_loss: 0.5711 - val_accuracy: 0.8250\n",
      "Epoch 596/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4865 - accuracy: 0.89 - 0s 84us/step - loss: 0.5082 - accuracy: 0.8575 - val_loss: 0.5717 - val_accuracy: 0.8300\n",
      "Epoch 597/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.5079 - accuracy: 0.8575 - val_loss: 0.5692 - val_accuracy: 0.8250\n",
      "Epoch 598/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.5076 - accuracy: 0.8575 - val_loss: 0.5686 - val_accuracy: 0.8300\n",
      "Epoch 599/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.5070 - accuracy: 0.8587 - val_loss: 0.5696 - val_accuracy: 0.8250\n",
      "Epoch 600/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.5064 - accuracy: 0.8575 - val_loss: 0.5690 - val_accuracy: 0.8250\n",
      "Epoch 601/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.5059 - accuracy: 0.8562 - val_loss: 0.5689 - val_accuracy: 0.8300\n",
      "Epoch 602/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.5045 - accuracy: 0.8575 - val_loss: 0.5680 - val_accuracy: 0.8250\n",
      "Epoch 603/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.5049 - accuracy: 0.8575 - val_loss: 0.5663 - val_accuracy: 0.8300\n",
      "Epoch 604/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.5030 - accuracy: 0.8587 - val_loss: 0.5680 - val_accuracy: 0.8250\n",
      "Epoch 605/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.5038 - accuracy: 0.8612 - val_loss: 0.5666 - val_accuracy: 0.8250\n",
      "Epoch 606/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.5032 - accuracy: 0.8587 - val_loss: 0.5667 - val_accuracy: 0.8250\n",
      "Epoch 607/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.5022 - accuracy: 0.8587 - val_loss: 0.5654 - val_accuracy: 0.8300\n",
      "Epoch 608/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.5016 - accuracy: 0.8575 - val_loss: 0.5649 - val_accuracy: 0.8300\n",
      "Epoch 609/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.5009 - accuracy: 0.8587 - val_loss: 0.5644 - val_accuracy: 0.8300\n",
      "Epoch 610/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.5005 - accuracy: 0.8562 - val_loss: 0.5660 - val_accuracy: 0.8250\n",
      "Epoch 611/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.4999 - accuracy: 0.8562 - val_loss: 0.5634 - val_accuracy: 0.8300\n",
      "Epoch 612/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.4992 - accuracy: 0.8587 - val_loss: 0.5635 - val_accuracy: 0.8300\n",
      "Epoch 613/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.4991 - accuracy: 0.8625 - val_loss: 0.5636 - val_accuracy: 0.8250\n",
      "Epoch 614/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.4975 - accuracy: 0.8587 - val_loss: 0.5600 - val_accuracy: 0.8300\n",
      "Epoch 615/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.4983 - accuracy: 0.8600 - val_loss: 0.5604 - val_accuracy: 0.8300\n",
      "Epoch 616/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.4974 - accuracy: 0.8587 - val_loss: 0.5615 - val_accuracy: 0.8300\n",
      "Epoch 617/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.4963 - accuracy: 0.8600 - val_loss: 0.5598 - val_accuracy: 0.8300\n",
      "Epoch 618/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.4959 - accuracy: 0.8612 - val_loss: 0.5593 - val_accuracy: 0.8300\n",
      "Epoch 619/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.4955 - accuracy: 0.8625 - val_loss: 0.5593 - val_accuracy: 0.8350\n",
      "Epoch 620/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.4957 - accuracy: 0.8600 - val_loss: 0.5590 - val_accuracy: 0.8250\n",
      "Epoch 621/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.4943 - accuracy: 0.8562 - val_loss: 0.5589 - val_accuracy: 0.8300\n",
      "Epoch 622/3000\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.4953 - accuracy: 0.8600 - val_loss: 0.5589 - val_accuracy: 0.8250\n",
      "Epoch 623/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4923 - accuracy: 0.85 - 0s 253us/step - loss: 0.4930 - accuracy: 0.8587 - val_loss: 0.5567 - val_accuracy: 0.8350\n",
      "Epoch 624/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.4921 - accuracy: 0.8600 - val_loss: 0.5570 - val_accuracy: 0.8250\n",
      "Epoch 625/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.4931 - accuracy: 0.8612 - val_loss: 0.5571 - val_accuracy: 0.8250\n",
      "Epoch 626/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.5178 - accuracy: 0.85 - 0s 111us/step - loss: 0.4920 - accuracy: 0.8600 - val_loss: 0.5560 - val_accuracy: 0.8300\n",
      "Epoch 627/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.4914 - accuracy: 0.8612 - val_loss: 0.5542 - val_accuracy: 0.8250\n",
      "Epoch 628/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.4904 - accuracy: 0.8625 - val_loss: 0.5542 - val_accuracy: 0.8250\n",
      "Epoch 629/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.4901 - accuracy: 0.8575 - val_loss: 0.5551 - val_accuracy: 0.8350\n",
      "Epoch 630/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.4903 - accuracy: 0.8612 - val_loss: 0.5546 - val_accuracy: 0.8300\n",
      "Epoch 631/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.4897 - accuracy: 0.8625 - val_loss: 0.5549 - val_accuracy: 0.8300\n",
      "Epoch 632/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.4886 - accuracy: 0.8662 - val_loss: 0.5529 - val_accuracy: 0.8350\n",
      "Epoch 633/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.4877 - accuracy: 0.8600 - val_loss: 0.5526 - val_accuracy: 0.8300\n",
      "Epoch 634/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.4872 - accuracy: 0.8612 - val_loss: 0.5528 - val_accuracy: 0.8300\n",
      "Epoch 635/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.4880 - accuracy: 0.8637 - val_loss: 0.5528 - val_accuracy: 0.8300\n",
      "Epoch 636/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.4861 - accuracy: 0.8637 - val_loss: 0.5502 - val_accuracy: 0.8350\n",
      "Epoch 637/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.4862 - accuracy: 0.8600 - val_loss: 0.5518 - val_accuracy: 0.8300\n",
      "Epoch 638/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.4862 - accuracy: 0.8587 - val_loss: 0.5507 - val_accuracy: 0.8300\n",
      "Epoch 639/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.4848 - accuracy: 0.8587 - val_loss: 0.5512 - val_accuracy: 0.8250\n",
      "Epoch 640/3000\n",
      "800/800 [==============================] - 0s 124us/step - loss: 0.4849 - accuracy: 0.8650 - val_loss: 0.5505 - val_accuracy: 0.8300\n",
      "Epoch 641/3000\n",
      "800/800 [==============================] - 0s 130us/step - loss: 0.4834 - accuracy: 0.8650 - val_loss: 0.5504 - val_accuracy: 0.8300\n",
      "Epoch 642/3000\n",
      "800/800 [==============================] - 0s 128us/step - loss: 0.4841 - accuracy: 0.8625 - val_loss: 0.5498 - val_accuracy: 0.8300\n",
      "Epoch 643/3000\n",
      "800/800 [==============================] - 0s 128us/step - loss: 0.4828 - accuracy: 0.8700 - val_loss: 0.5504 - val_accuracy: 0.8350\n",
      "Epoch 644/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.4827 - accuracy: 0.8625 - val_loss: 0.5474 - val_accuracy: 0.8300\n",
      "Epoch 645/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.4825 - accuracy: 0.8600 - val_loss: 0.5491 - val_accuracy: 0.8300\n",
      "Epoch 646/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.4819 - accuracy: 0.8637 - val_loss: 0.5477 - val_accuracy: 0.8300\n",
      "Epoch 647/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.4818 - accuracy: 0.8650 - val_loss: 0.5490 - val_accuracy: 0.8300\n",
      "Epoch 648/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.4808 - accuracy: 0.8650 - val_loss: 0.5476 - val_accuracy: 0.8350\n",
      "Epoch 649/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.4801 - accuracy: 0.8625 - val_loss: 0.5465 - val_accuracy: 0.8300\n",
      "Epoch 650/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.4795 - accuracy: 0.8650 - val_loss: 0.5458 - val_accuracy: 0.8300\n",
      "Epoch 651/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.4797 - accuracy: 0.8612 - val_loss: 0.5451 - val_accuracy: 0.8300\n",
      "Epoch 652/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.4790 - accuracy: 0.8637 - val_loss: 0.5444 - val_accuracy: 0.8300\n",
      "Epoch 653/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.4773 - accuracy: 0.8625 - val_loss: 0.5451 - val_accuracy: 0.8300\n",
      "Epoch 654/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.4783 - accuracy: 0.8700 - val_loss: 0.5438 - val_accuracy: 0.8300\n",
      "Epoch 655/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.4776 - accuracy: 0.8612 - val_loss: 0.5445 - val_accuracy: 0.8300\n",
      "Epoch 656/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.4769 - accuracy: 0.8650 - val_loss: 0.5435 - val_accuracy: 0.8300\n",
      "Epoch 657/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.4756 - accuracy: 0.8650 - val_loss: 0.5420 - val_accuracy: 0.8350\n",
      "Epoch 658/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.4756 - accuracy: 0.8675 - val_loss: 0.5419 - val_accuracy: 0.8300\n",
      "Epoch 659/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.4752 - accuracy: 0.8637 - val_loss: 0.5414 - val_accuracy: 0.8300\n",
      "Epoch 660/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.4739 - accuracy: 0.8675 - val_loss: 0.5416 - val_accuracy: 0.8300\n",
      "Epoch 661/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.4749 - accuracy: 0.8625 - val_loss: 0.5425 - val_accuracy: 0.8350\n",
      "Epoch 662/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.4734 - accuracy: 0.8662 - val_loss: 0.5408 - val_accuracy: 0.8300\n",
      "Epoch 663/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.4735 - accuracy: 0.8650 - val_loss: 0.5404 - val_accuracy: 0.8300\n",
      "Epoch 664/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.4728 - accuracy: 0.8650 - val_loss: 0.5395 - val_accuracy: 0.8300\n",
      "Epoch 665/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.4729 - accuracy: 0.8700 - val_loss: 0.5404 - val_accuracy: 0.8400\n",
      "Epoch 666/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.4716 - accuracy: 0.8675 - val_loss: 0.5387 - val_accuracy: 0.8300\n",
      "Epoch 667/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.4718 - accuracy: 0.8675 - val_loss: 0.5380 - val_accuracy: 0.8350\n",
      "Epoch 668/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.4703 - accuracy: 0.8637 - val_loss: 0.5390 - val_accuracy: 0.8300\n",
      "Epoch 669/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.4704 - accuracy: 0.8650 - val_loss: 0.5377 - val_accuracy: 0.8300\n",
      "Epoch 670/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.4693 - accuracy: 0.8637 - val_loss: 0.5397 - val_accuracy: 0.8400\n",
      "Epoch 671/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.4704 - accuracy: 0.8687 - val_loss: 0.5365 - val_accuracy: 0.8300\n",
      "Epoch 672/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.4691 - accuracy: 0.8687 - val_loss: 0.5359 - val_accuracy: 0.8300\n",
      "Epoch 673/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.4687 - accuracy: 0.8700 - val_loss: 0.5346 - val_accuracy: 0.8300\n",
      "Epoch 674/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.4686 - accuracy: 0.8675 - val_loss: 0.5358 - val_accuracy: 0.8300\n",
      "Epoch 675/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.4675 - accuracy: 0.8662 - val_loss: 0.5349 - val_accuracy: 0.8300\n",
      "Epoch 676/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.4677 - accuracy: 0.8625 - val_loss: 0.5349 - val_accuracy: 0.8350\n",
      "Epoch 677/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.4661 - accuracy: 0.8700 - val_loss: 0.5337 - val_accuracy: 0.8300\n",
      "Epoch 678/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.4660 - accuracy: 0.8700 - val_loss: 0.5347 - val_accuracy: 0.8400\n",
      "Epoch 679/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.4661 - accuracy: 0.8625 - val_loss: 0.5333 - val_accuracy: 0.8300\n",
      "Epoch 680/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.4648 - accuracy: 0.8687 - val_loss: 0.5338 - val_accuracy: 0.8350\n",
      "Epoch 681/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.4643 - accuracy: 0.8700 - val_loss: 0.5334 - val_accuracy: 0.8400\n",
      "Epoch 682/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.4641 - accuracy: 0.8650 - val_loss: 0.5328 - val_accuracy: 0.8300\n",
      "Epoch 683/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.4638 - accuracy: 0.8712 - val_loss: 0.5326 - val_accuracy: 0.8300\n",
      "Epoch 684/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.4634 - accuracy: 0.8700 - val_loss: 0.5307 - val_accuracy: 0.8300\n",
      "Epoch 685/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.4628 - accuracy: 0.8662 - val_loss: 0.5306 - val_accuracy: 0.8300\n",
      "Epoch 686/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.4622 - accuracy: 0.8700 - val_loss: 0.5320 - val_accuracy: 0.8400\n",
      "Epoch 687/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.4622 - accuracy: 0.8662 - val_loss: 0.5291 - val_accuracy: 0.8350\n",
      "Epoch 688/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.4611 - accuracy: 0.8687 - val_loss: 0.5290 - val_accuracy: 0.8300\n",
      "Epoch 689/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.4607 - accuracy: 0.8700 - val_loss: 0.5281 - val_accuracy: 0.8300\n",
      "Epoch 690/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.4602 - accuracy: 0.8675 - val_loss: 0.5294 - val_accuracy: 0.8300\n",
      "Epoch 691/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.4597 - accuracy: 0.8712 - val_loss: 0.5272 - val_accuracy: 0.8300\n",
      "Epoch 692/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.4603 - accuracy: 0.8675 - val_loss: 0.5280 - val_accuracy: 0.8350\n",
      "Epoch 693/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.4597 - accuracy: 0.8700 - val_loss: 0.5271 - val_accuracy: 0.8300\n",
      "Epoch 694/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.4582 - accuracy: 0.8700 - val_loss: 0.5261 - val_accuracy: 0.8350\n",
      "Epoch 695/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.4578 - accuracy: 0.8637 - val_loss: 0.5264 - val_accuracy: 0.8300\n",
      "Epoch 696/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.4578 - accuracy: 0.8725 - val_loss: 0.5255 - val_accuracy: 0.8300\n",
      "Epoch 697/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.4572 - accuracy: 0.8662 - val_loss: 0.5252 - val_accuracy: 0.8300\n",
      "Epoch 698/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.4565 - accuracy: 0.8700 - val_loss: 0.5257 - val_accuracy: 0.8450\n",
      "Epoch 699/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.4567 - accuracy: 0.8687 - val_loss: 0.5249 - val_accuracy: 0.8450\n",
      "Epoch 700/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.4560 - accuracy: 0.8725 - val_loss: 0.5248 - val_accuracy: 0.8400\n",
      "Epoch 701/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.4557 - accuracy: 0.8675 - val_loss: 0.5251 - val_accuracy: 0.8400\n",
      "Epoch 702/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.4550 - accuracy: 0.8712 - val_loss: 0.5225 - val_accuracy: 0.8300\n",
      "Epoch 703/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.4542 - accuracy: 0.8675 - val_loss: 0.5223 - val_accuracy: 0.8350\n",
      "Epoch 704/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.4540 - accuracy: 0.8712 - val_loss: 0.5227 - val_accuracy: 0.8450\n",
      "Epoch 705/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.4533 - accuracy: 0.8737 - val_loss: 0.5225 - val_accuracy: 0.8350\n",
      "Epoch 706/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.4536 - accuracy: 0.8725 - val_loss: 0.5229 - val_accuracy: 0.8350\n",
      "Epoch 707/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.4526 - accuracy: 0.8675 - val_loss: 0.5218 - val_accuracy: 0.8400\n",
      "Epoch 708/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.4531 - accuracy: 0.8687 - val_loss: 0.5207 - val_accuracy: 0.8350\n",
      "Epoch 709/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.4523 - accuracy: 0.8700 - val_loss: 0.5213 - val_accuracy: 0.8400\n",
      "Epoch 710/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.4509 - accuracy: 0.8712 - val_loss: 0.5213 - val_accuracy: 0.8450\n",
      "Epoch 711/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.4512 - accuracy: 0.8763 - val_loss: 0.5194 - val_accuracy: 0.8350\n",
      "Epoch 712/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.4507 - accuracy: 0.8687 - val_loss: 0.5197 - val_accuracy: 0.8450\n",
      "Epoch 713/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.4496 - accuracy: 0.8675 - val_loss: 0.5194 - val_accuracy: 0.8450\n",
      "Epoch 714/3000\n",
      "800/800 [==============================] - 0s 125us/step - loss: 0.4506 - accuracy: 0.8725 - val_loss: 0.5187 - val_accuracy: 0.8350\n",
      "Epoch 715/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.4488 - accuracy: 0.8662 - val_loss: 0.5192 - val_accuracy: 0.8400\n",
      "Epoch 716/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.4488 - accuracy: 0.8700 - val_loss: 0.5188 - val_accuracy: 0.8350\n",
      "Epoch 717/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.4482 - accuracy: 0.8712 - val_loss: 0.5178 - val_accuracy: 0.8450\n",
      "Epoch 718/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.4478 - accuracy: 0.8687 - val_loss: 0.5185 - val_accuracy: 0.8350\n",
      "Epoch 719/3000\n",
      "800/800 [==============================] - 0s 136us/step - loss: 0.4471 - accuracy: 0.8750 - val_loss: 0.5172 - val_accuracy: 0.8550\n",
      "Epoch 720/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.4477 - accuracy: 0.8687 - val_loss: 0.5164 - val_accuracy: 0.8350\n",
      "Epoch 721/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.4472 - accuracy: 0.8700 - val_loss: 0.5164 - val_accuracy: 0.8300\n",
      "Epoch 722/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.4456 - accuracy: 0.8687 - val_loss: 0.5154 - val_accuracy: 0.8350\n",
      "Epoch 723/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.4456 - accuracy: 0.8737 - val_loss: 0.5149 - val_accuracy: 0.8350\n",
      "Epoch 724/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.4451 - accuracy: 0.8763 - val_loss: 0.5148 - val_accuracy: 0.8400\n",
      "Epoch 725/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.4451 - accuracy: 0.8687 - val_loss: 0.5167 - val_accuracy: 0.8500\n",
      "Epoch 726/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.4454 - accuracy: 0.8737 - val_loss: 0.5137 - val_accuracy: 0.8350\n",
      "Epoch 727/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.4435 - accuracy: 0.8737 - val_loss: 0.5142 - val_accuracy: 0.8500\n",
      "Epoch 728/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.4434 - accuracy: 0.8687 - val_loss: 0.5153 - val_accuracy: 0.8400\n",
      "Epoch 729/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.4439 - accuracy: 0.8725 - val_loss: 0.5147 - val_accuracy: 0.8450\n",
      "Epoch 730/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.4420 - accuracy: 0.8725 - val_loss: 0.5137 - val_accuracy: 0.8350\n",
      "Epoch 731/3000\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.4417 - accuracy: 0.8712 - val_loss: 0.5111 - val_accuracy: 0.8400\n",
      "Epoch 732/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.4421 - accuracy: 0.8712 - val_loss: 0.5113 - val_accuracy: 0.8400\n",
      "Epoch 733/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.4412 - accuracy: 0.8700 - val_loss: 0.5127 - val_accuracy: 0.8500\n",
      "Epoch 734/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.4407 - accuracy: 0.8763 - val_loss: 0.5120 - val_accuracy: 0.8450\n",
      "Epoch 735/3000\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.4403 - accuracy: 0.8750 - val_loss: 0.5103 - val_accuracy: 0.8350\n",
      "Epoch 736/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.4402 - accuracy: 0.8750 - val_loss: 0.5105 - val_accuracy: 0.8400\n",
      "Epoch 737/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.4394 - accuracy: 0.8725 - val_loss: 0.5094 - val_accuracy: 0.8350\n",
      "Epoch 738/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.4395 - accuracy: 0.8750 - val_loss: 0.5109 - val_accuracy: 0.8550\n",
      "Epoch 739/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.4390 - accuracy: 0.8725 - val_loss: 0.5107 - val_accuracy: 0.8500\n",
      "Epoch 740/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.4388 - accuracy: 0.8763 - val_loss: 0.5096 - val_accuracy: 0.8450\n",
      "Epoch 741/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.4380 - accuracy: 0.8725 - val_loss: 0.5100 - val_accuracy: 0.8450\n",
      "Epoch 742/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.4381 - accuracy: 0.8763 - val_loss: 0.5086 - val_accuracy: 0.8500\n",
      "Epoch 743/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.4375 - accuracy: 0.8763 - val_loss: 0.5102 - val_accuracy: 0.8450\n",
      "Epoch 744/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.4364 - accuracy: 0.8775 - val_loss: 0.5070 - val_accuracy: 0.8400\n",
      "Epoch 745/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.4379 - accuracy: 0.8712 - val_loss: 0.5063 - val_accuracy: 0.8400\n",
      "Epoch 746/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.4357 - accuracy: 0.8725 - val_loss: 0.5069 - val_accuracy: 0.8450\n",
      "Epoch 747/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.4358 - accuracy: 0.8737 - val_loss: 0.5066 - val_accuracy: 0.8400\n",
      "Epoch 748/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.4349 - accuracy: 0.8725 - val_loss: 0.5076 - val_accuracy: 0.8400\n",
      "Epoch 749/3000\n",
      "800/800 [==============================] - 0s 130us/step - loss: 0.4348 - accuracy: 0.8775 - val_loss: 0.5060 - val_accuracy: 0.8500\n",
      "Epoch 750/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.4346 - accuracy: 0.8750 - val_loss: 0.5057 - val_accuracy: 0.8500\n",
      "Epoch 751/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.4336 - accuracy: 0.8763 - val_loss: 0.5039 - val_accuracy: 0.8400\n",
      "Epoch 752/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4302 - accuracy: 0.87 - 0s 124us/step - loss: 0.4339 - accuracy: 0.8725 - val_loss: 0.5043 - val_accuracy: 0.8400\n",
      "Epoch 753/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.4333 - accuracy: 0.8737 - val_loss: 0.5044 - val_accuracy: 0.8450\n",
      "Epoch 754/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.4331 - accuracy: 0.8737 - val_loss: 0.5049 - val_accuracy: 0.8500\n",
      "Epoch 755/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.4322 - accuracy: 0.8750 - val_loss: 0.5040 - val_accuracy: 0.8500\n",
      "Epoch 756/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.4317 - accuracy: 0.8750 - val_loss: 0.5042 - val_accuracy: 0.8500\n",
      "Epoch 757/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.4312 - accuracy: 0.8763 - val_loss: 0.5038 - val_accuracy: 0.8600\n",
      "Epoch 758/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.4304 - accuracy: 0.8788 - val_loss: 0.5047 - val_accuracy: 0.8450\n",
      "Epoch 759/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.4308 - accuracy: 0.8850 - val_loss: 0.5011 - val_accuracy: 0.8350\n",
      "Epoch 760/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.4305 - accuracy: 0.8775 - val_loss: 0.5019 - val_accuracy: 0.8450\n",
      "Epoch 761/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.4300 - accuracy: 0.8775 - val_loss: 0.5010 - val_accuracy: 0.8450\n",
      "Epoch 762/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.4291 - accuracy: 0.8775 - val_loss: 0.5007 - val_accuracy: 0.8500\n",
      "Epoch 763/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.4296 - accuracy: 0.8775 - val_loss: 0.5012 - val_accuracy: 0.8400\n",
      "Epoch 764/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.4285 - accuracy: 0.8750 - val_loss: 0.5024 - val_accuracy: 0.8450\n",
      "Epoch 765/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.4286 - accuracy: 0.8750 - val_loss: 0.5001 - val_accuracy: 0.8600\n",
      "Epoch 766/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.4284 - accuracy: 0.8775 - val_loss: 0.5001 - val_accuracy: 0.8600\n",
      "Epoch 767/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.4280 - accuracy: 0.8800 - val_loss: 0.5009 - val_accuracy: 0.8550\n",
      "Epoch 768/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4307 - accuracy: 0.87 - 0s 95us/step - loss: 0.4269 - accuracy: 0.8775 - val_loss: 0.4998 - val_accuracy: 0.8500\n",
      "Epoch 769/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.4266 - accuracy: 0.8737 - val_loss: 0.4998 - val_accuracy: 0.8450\n",
      "Epoch 770/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.4259 - accuracy: 0.8800 - val_loss: 0.4978 - val_accuracy: 0.8400\n",
      "Epoch 771/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.4260 - accuracy: 0.8750 - val_loss: 0.4975 - val_accuracy: 0.8450\n",
      "Epoch 772/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.4258 - accuracy: 0.8750 - val_loss: 0.4976 - val_accuracy: 0.8450\n",
      "Epoch 773/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.4254 - accuracy: 0.8712 - val_loss: 0.4968 - val_accuracy: 0.8550\n",
      "Epoch 774/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.4246 - accuracy: 0.8775 - val_loss: 0.4971 - val_accuracy: 0.8600\n",
      "Epoch 775/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.4241 - accuracy: 0.8763 - val_loss: 0.4993 - val_accuracy: 0.8550\n",
      "Epoch 776/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.4246 - accuracy: 0.8813 - val_loss: 0.4972 - val_accuracy: 0.8450\n",
      "Epoch 777/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.4232 - accuracy: 0.8838 - val_loss: 0.4957 - val_accuracy: 0.8400\n",
      "Epoch 778/3000\n",
      "800/800 [==============================] - 0s 59us/step - loss: 0.4236 - accuracy: 0.8800 - val_loss: 0.4960 - val_accuracy: 0.8450\n",
      "Epoch 779/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.4239 - accuracy: 0.8750 - val_loss: 0.4948 - val_accuracy: 0.8400\n",
      "Epoch 780/3000\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.4226 - accuracy: 0.8763 - val_loss: 0.4950 - val_accuracy: 0.8400\n",
      "Epoch 781/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.4221 - accuracy: 0.8750 - val_loss: 0.4957 - val_accuracy: 0.8500\n",
      "Epoch 782/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.4217 - accuracy: 0.8825 - val_loss: 0.4952 - val_accuracy: 0.8550\n",
      "Epoch 783/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.4212 - accuracy: 0.8838 - val_loss: 0.4940 - val_accuracy: 0.8400\n",
      "Epoch 784/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.4210 - accuracy: 0.8750 - val_loss: 0.4937 - val_accuracy: 0.8400\n",
      "Epoch 785/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.4204 - accuracy: 0.8737 - val_loss: 0.4942 - val_accuracy: 0.8550\n",
      "Epoch 786/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.4205 - accuracy: 0.8788 - val_loss: 0.4934 - val_accuracy: 0.8550\n",
      "Epoch 787/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.4195 - accuracy: 0.8813 - val_loss: 0.4935 - val_accuracy: 0.8450\n",
      "Epoch 788/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.4194 - accuracy: 0.8763 - val_loss: 0.4933 - val_accuracy: 0.8500\n",
      "Epoch 789/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.4190 - accuracy: 0.8825 - val_loss: 0.4931 - val_accuracy: 0.8400\n",
      "Epoch 790/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.4193 - accuracy: 0.8813 - val_loss: 0.4911 - val_accuracy: 0.8400\n",
      "Epoch 791/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.4179 - accuracy: 0.8788 - val_loss: 0.4918 - val_accuracy: 0.8600\n",
      "Epoch 792/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.4185 - accuracy: 0.8800 - val_loss: 0.4916 - val_accuracy: 0.8550\n",
      "Epoch 793/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.4171 - accuracy: 0.8800 - val_loss: 0.4909 - val_accuracy: 0.8650\n",
      "Epoch 794/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.4175 - accuracy: 0.8763 - val_loss: 0.4916 - val_accuracy: 0.8550\n",
      "Epoch 795/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.4178 - accuracy: 0.8800 - val_loss: 0.4904 - val_accuracy: 0.8650\n",
      "Epoch 796/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.4156 - accuracy: 0.8788 - val_loss: 0.4920 - val_accuracy: 0.8550\n",
      "Epoch 797/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.4161 - accuracy: 0.8825 - val_loss: 0.4898 - val_accuracy: 0.8650\n",
      "Epoch 798/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.4156 - accuracy: 0.8775 - val_loss: 0.4903 - val_accuracy: 0.8500\n",
      "Epoch 799/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.4147 - accuracy: 0.8825 - val_loss: 0.4887 - val_accuracy: 0.8600\n",
      "Epoch 800/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.4147 - accuracy: 0.8800 - val_loss: 0.4882 - val_accuracy: 0.8600\n",
      "Epoch 801/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.4146 - accuracy: 0.8825 - val_loss: 0.4880 - val_accuracy: 0.8650\n",
      "Epoch 802/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.4138 - accuracy: 0.8813 - val_loss: 0.4872 - val_accuracy: 0.8500\n",
      "Epoch 803/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.4132 - accuracy: 0.8850 - val_loss: 0.4871 - val_accuracy: 0.8550\n",
      "Epoch 804/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.4131 - accuracy: 0.8788 - val_loss: 0.4867 - val_accuracy: 0.8600\n",
      "Epoch 805/3000\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.4126 - accuracy: 0.8800 - val_loss: 0.4879 - val_accuracy: 0.8600\n",
      "Epoch 806/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.4125 - accuracy: 0.8813 - val_loss: 0.4872 - val_accuracy: 0.8650\n",
      "Epoch 807/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.4125 - accuracy: 0.8900 - val_loss: 0.4857 - val_accuracy: 0.8600\n",
      "Epoch 808/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.4112 - accuracy: 0.8775 - val_loss: 0.4852 - val_accuracy: 0.8500\n",
      "Epoch 809/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.4116 - accuracy: 0.8875 - val_loss: 0.4838 - val_accuracy: 0.8400\n",
      "Epoch 810/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.4105 - accuracy: 0.8813 - val_loss: 0.4836 - val_accuracy: 0.8600\n",
      "Epoch 811/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.4105 - accuracy: 0.8863 - val_loss: 0.4849 - val_accuracy: 0.8700\n",
      "Epoch 812/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.4104 - accuracy: 0.8875 - val_loss: 0.4834 - val_accuracy: 0.8650\n",
      "Epoch 813/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.4103 - accuracy: 0.8850 - val_loss: 0.4825 - val_accuracy: 0.8550\n",
      "Epoch 814/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.4093 - accuracy: 0.8838 - val_loss: 0.4824 - val_accuracy: 0.8450\n",
      "Epoch 815/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.4090 - accuracy: 0.8838 - val_loss: 0.4819 - val_accuracy: 0.8600\n",
      "Epoch 816/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.4087 - accuracy: 0.8800 - val_loss: 0.4824 - val_accuracy: 0.8600\n",
      "Epoch 817/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.4091 - accuracy: 0.8850 - val_loss: 0.4822 - val_accuracy: 0.8450\n",
      "Epoch 818/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.4068 - accuracy: 0.8825 - val_loss: 0.4814 - val_accuracy: 0.8600\n",
      "Epoch 819/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.4084 - accuracy: 0.8800 - val_loss: 0.4822 - val_accuracy: 0.8600\n",
      "Epoch 820/3000\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.4074 - accuracy: 0.8800 - val_loss: 0.4818 - val_accuracy: 0.8650\n",
      "Epoch 821/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.4067 - accuracy: 0.8863 - val_loss: 0.4801 - val_accuracy: 0.8600\n",
      "Epoch 822/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.4067 - accuracy: 0.8875 - val_loss: 0.4805 - val_accuracy: 0.8600\n",
      "Epoch 823/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.4067 - accuracy: 0.8825 - val_loss: 0.4804 - val_accuracy: 0.8700\n",
      "Epoch 824/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.4055 - accuracy: 0.8838 - val_loss: 0.4796 - val_accuracy: 0.8600\n",
      "Epoch 825/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.4056 - accuracy: 0.8825 - val_loss: 0.4794 - val_accuracy: 0.8600\n",
      "Epoch 826/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.4050 - accuracy: 0.8800 - val_loss: 0.4805 - val_accuracy: 0.8600\n",
      "Epoch 827/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.4050 - accuracy: 0.8863 - val_loss: 0.4785 - val_accuracy: 0.8600\n",
      "Epoch 828/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.4047 - accuracy: 0.8875 - val_loss: 0.4782 - val_accuracy: 0.8600\n",
      "Epoch 829/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.4040 - accuracy: 0.8825 - val_loss: 0.4788 - val_accuracy: 0.8550\n",
      "Epoch 830/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.4040 - accuracy: 0.8838 - val_loss: 0.4799 - val_accuracy: 0.8550\n",
      "Epoch 831/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.4033 - accuracy: 0.8838 - val_loss: 0.4775 - val_accuracy: 0.8400\n",
      "Epoch 832/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.4030 - accuracy: 0.8875 - val_loss: 0.4768 - val_accuracy: 0.8600\n",
      "Epoch 833/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.4020 - accuracy: 0.8838 - val_loss: 0.4774 - val_accuracy: 0.8450\n",
      "Epoch 834/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.4022 - accuracy: 0.8825 - val_loss: 0.4766 - val_accuracy: 0.8650\n",
      "Epoch 835/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.4021 - accuracy: 0.8838 - val_loss: 0.4775 - val_accuracy: 0.8550\n",
      "Epoch 836/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.4018 - accuracy: 0.8875 - val_loss: 0.4762 - val_accuracy: 0.8550\n",
      "Epoch 837/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.4011 - accuracy: 0.8900 - val_loss: 0.4749 - val_accuracy: 0.8500\n",
      "Epoch 838/3000\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.4008 - accuracy: 0.8813 - val_loss: 0.4752 - val_accuracy: 0.8650\n",
      "Epoch 839/3000\n",
      "800/800 [==============================] - 0s 59us/step - loss: 0.4004 - accuracy: 0.8875 - val_loss: 0.4749 - val_accuracy: 0.8700\n",
      "Epoch 840/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.4006 - accuracy: 0.8838 - val_loss: 0.4737 - val_accuracy: 0.8600\n",
      "Epoch 841/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.4001 - accuracy: 0.8863 - val_loss: 0.4753 - val_accuracy: 0.8650\n",
      "Epoch 842/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.3995 - accuracy: 0.8850 - val_loss: 0.4739 - val_accuracy: 0.8550\n",
      "Epoch 843/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.3994 - accuracy: 0.8850 - val_loss: 0.4749 - val_accuracy: 0.8600\n",
      "Epoch 844/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.3986 - accuracy: 0.8875 - val_loss: 0.4746 - val_accuracy: 0.8650\n",
      "Epoch 845/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.3985 - accuracy: 0.8900 - val_loss: 0.4724 - val_accuracy: 0.8650\n",
      "Epoch 846/3000\n",
      "800/800 [==============================] - 0s 60us/step - loss: 0.3984 - accuracy: 0.8813 - val_loss: 0.4733 - val_accuracy: 0.8700\n",
      "Epoch 847/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.3973 - accuracy: 0.8913 - val_loss: 0.4724 - val_accuracy: 0.8600\n",
      "Epoch 848/3000\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.3974 - accuracy: 0.8863 - val_loss: 0.4720 - val_accuracy: 0.8650\n",
      "Epoch 849/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.3972 - accuracy: 0.8863 - val_loss: 0.4716 - val_accuracy: 0.8650\n",
      "Epoch 850/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.3971 - accuracy: 0.8838 - val_loss: 0.4712 - val_accuracy: 0.8600\n",
      "Epoch 851/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.3965 - accuracy: 0.8888 - val_loss: 0.4717 - val_accuracy: 0.8700\n",
      "Epoch 852/3000\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.3963 - accuracy: 0.8863 - val_loss: 0.4702 - val_accuracy: 0.8600\n",
      "Epoch 853/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.3957 - accuracy: 0.8850 - val_loss: 0.4704 - val_accuracy: 0.8600\n",
      "Epoch 854/3000\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.3956 - accuracy: 0.8800 - val_loss: 0.4701 - val_accuracy: 0.8600\n",
      "Epoch 855/3000\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.3951 - accuracy: 0.8863 - val_loss: 0.4700 - val_accuracy: 0.8700\n",
      "Epoch 856/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.3938 - accuracy: 0.8863 - val_loss: 0.4701 - val_accuracy: 0.8650\n",
      "Epoch 857/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.3934 - accuracy: 0.8875 - val_loss: 0.4693 - val_accuracy: 0.8700\n",
      "Epoch 858/3000\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.3943 - accuracy: 0.8900 - val_loss: 0.4700 - val_accuracy: 0.8600\n",
      "Epoch 859/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.3943 - accuracy: 0.8850 - val_loss: 0.4682 - val_accuracy: 0.8650\n",
      "Epoch 860/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.3934 - accuracy: 0.8875 - val_loss: 0.4690 - val_accuracy: 0.8650\n",
      "Epoch 861/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.3928 - accuracy: 0.8913 - val_loss: 0.4683 - val_accuracy: 0.8600\n",
      "Epoch 862/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.3924 - accuracy: 0.8838 - val_loss: 0.4687 - val_accuracy: 0.8600\n",
      "Epoch 863/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.3919 - accuracy: 0.8888 - val_loss: 0.4678 - val_accuracy: 0.8550\n",
      "Epoch 864/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.3917 - accuracy: 0.8888 - val_loss: 0.4670 - val_accuracy: 0.8600\n",
      "Epoch 865/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.3920 - accuracy: 0.8838 - val_loss: 0.4672 - val_accuracy: 0.8600\n",
      "Epoch 866/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.3914 - accuracy: 0.8863 - val_loss: 0.4685 - val_accuracy: 0.8650\n",
      "Epoch 867/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.3905 - accuracy: 0.8838 - val_loss: 0.4664 - val_accuracy: 0.8650\n",
      "Epoch 868/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.3908 - accuracy: 0.8925 - val_loss: 0.4654 - val_accuracy: 0.8650\n",
      "Epoch 869/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4079 - accuracy: 0.89 - 0s 71us/step - loss: 0.3902 - accuracy: 0.8888 - val_loss: 0.4655 - val_accuracy: 0.8700\n",
      "Epoch 870/3000\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.3905 - accuracy: 0.8838 - val_loss: 0.4669 - val_accuracy: 0.8700\n",
      "Epoch 871/3000\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.3897 - accuracy: 0.8875 - val_loss: 0.4650 - val_accuracy: 0.8650\n",
      "Epoch 872/3000\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.3892 - accuracy: 0.8875 - val_loss: 0.4645 - val_accuracy: 0.8700\n",
      "Epoch 873/3000\n",
      "800/800 [==============================] - 0s 149us/step - loss: 0.3888 - accuracy: 0.8875 - val_loss: 0.4656 - val_accuracy: 0.8650\n",
      "Epoch 874/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.3882 - accuracy: 0.8863 - val_loss: 0.4644 - val_accuracy: 0.8700\n",
      "Epoch 875/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.3885 - accuracy: 0.8888 - val_loss: 0.4640 - val_accuracy: 0.8700\n",
      "Epoch 876/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.3881 - accuracy: 0.8888 - val_loss: 0.4642 - val_accuracy: 0.8700\n",
      "Epoch 877/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.3874 - accuracy: 0.8913 - val_loss: 0.4634 - val_accuracy: 0.8650\n",
      "Epoch 878/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.3875 - accuracy: 0.8875 - val_loss: 0.4640 - val_accuracy: 0.8700\n",
      "Epoch 879/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2840 - accuracy: 0.95 - 0s 85us/step - loss: 0.3873 - accuracy: 0.8888 - val_loss: 0.4625 - val_accuracy: 0.8650\n",
      "Epoch 880/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.3868 - accuracy: 0.8838 - val_loss: 0.4627 - val_accuracy: 0.8650\n",
      "Epoch 881/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.3862 - accuracy: 0.8875 - val_loss: 0.4621 - val_accuracy: 0.8700\n",
      "Epoch 882/3000\n",
      "800/800 [==============================] - 0s 125us/step - loss: 0.3854 - accuracy: 0.8900 - val_loss: 0.4626 - val_accuracy: 0.8600\n",
      "Epoch 883/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.3853 - accuracy: 0.8913 - val_loss: 0.4639 - val_accuracy: 0.8700\n",
      "Epoch 884/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.3852 - accuracy: 0.8888 - val_loss: 0.4618 - val_accuracy: 0.8650\n",
      "Epoch 885/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.3849 - accuracy: 0.8863 - val_loss: 0.4624 - val_accuracy: 0.8600\n",
      "Epoch 886/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.3847 - accuracy: 0.8875 - val_loss: 0.4627 - val_accuracy: 0.8650\n",
      "Epoch 887/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.3844 - accuracy: 0.8850 - val_loss: 0.4625 - val_accuracy: 0.8750\n",
      "Epoch 888/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.3841 - accuracy: 0.8975 - val_loss: 0.4611 - val_accuracy: 0.8700\n",
      "Epoch 889/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3867 - accuracy: 0.88 - 0s 96us/step - loss: 0.3833 - accuracy: 0.8900 - val_loss: 0.4598 - val_accuracy: 0.8650\n",
      "Epoch 890/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.3833 - accuracy: 0.8925 - val_loss: 0.4609 - val_accuracy: 0.8700\n",
      "Epoch 891/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.3829 - accuracy: 0.8850 - val_loss: 0.4601 - val_accuracy: 0.8700\n",
      "Epoch 892/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.3831 - accuracy: 0.8913 - val_loss: 0.4608 - val_accuracy: 0.8650\n",
      "Epoch 893/3000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 0.3820 - accuracy: 0.8900 - val_loss: 0.4607 - val_accuracy: 0.8700\n",
      "Epoch 894/3000\n",
      "800/800 [==============================] - 0s 144us/step - loss: 0.3821 - accuracy: 0.8913 - val_loss: 0.4586 - val_accuracy: 0.8650\n",
      "Epoch 895/3000\n",
      "800/800 [==============================] - 0s 129us/step - loss: 0.3814 - accuracy: 0.8875 - val_loss: 0.4576 - val_accuracy: 0.8600\n",
      "Epoch 896/3000\n",
      "800/800 [==============================] - 0s 125us/step - loss: 0.3813 - accuracy: 0.8925 - val_loss: 0.4576 - val_accuracy: 0.8700\n",
      "Epoch 897/3000\n",
      "800/800 [==============================] - 0s 134us/step - loss: 0.3810 - accuracy: 0.8975 - val_loss: 0.4570 - val_accuracy: 0.8650\n",
      "Epoch 898/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.3812 - accuracy: 0.8938 - val_loss: 0.4571 - val_accuracy: 0.8700\n",
      "Epoch 899/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.3809 - accuracy: 0.8900 - val_loss: 0.4566 - val_accuracy: 0.8650\n",
      "Epoch 900/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.3802 - accuracy: 0.8925 - val_loss: 0.4569 - val_accuracy: 0.8750\n",
      "Epoch 901/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.3793 - accuracy: 0.8925 - val_loss: 0.4557 - val_accuracy: 0.8700\n",
      "Epoch 902/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.3804 - accuracy: 0.8875 - val_loss: 0.4561 - val_accuracy: 0.8750\n",
      "Epoch 903/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.3792 - accuracy: 0.8913 - val_loss: 0.4557 - val_accuracy: 0.8700\n",
      "Epoch 904/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.3789 - accuracy: 0.8875 - val_loss: 0.4567 - val_accuracy: 0.8750\n",
      "Epoch 905/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.3789 - accuracy: 0.8925 - val_loss: 0.4578 - val_accuracy: 0.8700\n",
      "Epoch 906/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.3791 - accuracy: 0.8913 - val_loss: 0.4564 - val_accuracy: 0.8750\n",
      "Epoch 907/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.3777 - accuracy: 0.8925 - val_loss: 0.4553 - val_accuracy: 0.8700\n",
      "Epoch 908/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.3775 - accuracy: 0.8900 - val_loss: 0.4551 - val_accuracy: 0.8650\n",
      "Epoch 909/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.3777 - accuracy: 0.8900 - val_loss: 0.4537 - val_accuracy: 0.8650\n",
      "Epoch 910/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.3772 - accuracy: 0.8888 - val_loss: 0.4531 - val_accuracy: 0.8700\n",
      "Epoch 911/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.3760 - accuracy: 0.8925 - val_loss: 0.4536 - val_accuracy: 0.8650\n",
      "Epoch 912/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.3767 - accuracy: 0.8888 - val_loss: 0.4548 - val_accuracy: 0.8700\n",
      "Epoch 913/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.3759 - accuracy: 0.8963 - val_loss: 0.4541 - val_accuracy: 0.8700\n",
      "Epoch 914/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.3763 - accuracy: 0.8900 - val_loss: 0.4531 - val_accuracy: 0.8650\n",
      "Epoch 915/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.3749 - accuracy: 0.8900 - val_loss: 0.4524 - val_accuracy: 0.8650\n",
      "Epoch 916/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.3752 - accuracy: 0.8900 - val_loss: 0.4538 - val_accuracy: 0.8700\n",
      "Epoch 917/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.3743 - accuracy: 0.8913 - val_loss: 0.4532 - val_accuracy: 0.8700\n",
      "Epoch 918/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.3748 - accuracy: 0.8913 - val_loss: 0.4523 - val_accuracy: 0.8700\n",
      "Epoch 919/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.3742 - accuracy: 0.8950 - val_loss: 0.4523 - val_accuracy: 0.8750\n",
      "Epoch 920/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.3739 - accuracy: 0.8938 - val_loss: 0.4517 - val_accuracy: 0.8750\n",
      "Epoch 921/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.3737 - accuracy: 0.8913 - val_loss: 0.4508 - val_accuracy: 0.8750\n",
      "Epoch 922/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.3732 - accuracy: 0.8963 - val_loss: 0.4502 - val_accuracy: 0.8650\n",
      "Epoch 923/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.3732 - accuracy: 0.8863 - val_loss: 0.4498 - val_accuracy: 0.8700\n",
      "Epoch 924/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.3727 - accuracy: 0.8963 - val_loss: 0.4492 - val_accuracy: 0.8650\n",
      "Epoch 925/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.3722 - accuracy: 0.8925 - val_loss: 0.4503 - val_accuracy: 0.8650\n",
      "Epoch 926/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.3732 - accuracy: 0.8938 - val_loss: 0.4483 - val_accuracy: 0.8700\n",
      "Epoch 927/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.3708 - accuracy: 0.8900 - val_loss: 0.4506 - val_accuracy: 0.8800\n",
      "Epoch 928/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.3725 - accuracy: 0.8975 - val_loss: 0.4499 - val_accuracy: 0.8750\n",
      "Epoch 929/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.3707 - accuracy: 0.8938 - val_loss: 0.4482 - val_accuracy: 0.8650\n",
      "Epoch 930/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.3710 - accuracy: 0.8938 - val_loss: 0.4479 - val_accuracy: 0.8700\n",
      "Epoch 931/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.3702 - accuracy: 0.8963 - val_loss: 0.4482 - val_accuracy: 0.8750\n",
      "Epoch 932/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.3715 - accuracy: 0.8900 - val_loss: 0.4482 - val_accuracy: 0.8700\n",
      "Epoch 933/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.3694 - accuracy: 0.8925 - val_loss: 0.4484 - val_accuracy: 0.8750\n",
      "Epoch 934/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3618 - accuracy: 0.89 - 0s 100us/step - loss: 0.3695 - accuracy: 0.8963 - val_loss: 0.4480 - val_accuracy: 0.8750\n",
      "Epoch 935/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.3692 - accuracy: 0.8938 - val_loss: 0.4471 - val_accuracy: 0.8750\n",
      "Epoch 936/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.3696 - accuracy: 0.8950 - val_loss: 0.4473 - val_accuracy: 0.8750\n",
      "Epoch 937/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.3685 - accuracy: 0.8900 - val_loss: 0.4474 - val_accuracy: 0.8750\n",
      "Epoch 938/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.3689 - accuracy: 0.8975 - val_loss: 0.4466 - val_accuracy: 0.8650\n",
      "Epoch 939/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.3687 - accuracy: 0.8913 - val_loss: 0.4465 - val_accuracy: 0.8700\n",
      "Epoch 940/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.3676 - accuracy: 0.8963 - val_loss: 0.4475 - val_accuracy: 0.8700\n",
      "Epoch 941/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.3678 - accuracy: 0.8938 - val_loss: 0.4462 - val_accuracy: 0.8700\n",
      "Epoch 942/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.3676 - accuracy: 0.8925 - val_loss: 0.4467 - val_accuracy: 0.8750\n",
      "Epoch 943/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.3671 - accuracy: 0.8950 - val_loss: 0.4438 - val_accuracy: 0.8700\n",
      "Epoch 944/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.3669 - accuracy: 0.8950 - val_loss: 0.4442 - val_accuracy: 0.8700\n",
      "Epoch 945/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.3660 - accuracy: 0.8963 - val_loss: 0.4438 - val_accuracy: 0.8700\n",
      "Epoch 946/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.3662 - accuracy: 0.8975 - val_loss: 0.4444 - val_accuracy: 0.8750\n",
      "Epoch 947/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.3658 - accuracy: 0.8950 - val_loss: 0.4425 - val_accuracy: 0.8700\n",
      "Epoch 948/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.3654 - accuracy: 0.8950 - val_loss: 0.4434 - val_accuracy: 0.8650\n",
      "Epoch 949/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.3653 - accuracy: 0.8963 - val_loss: 0.4430 - val_accuracy: 0.8750\n",
      "Epoch 950/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.3644 - accuracy: 0.8938 - val_loss: 0.4444 - val_accuracy: 0.8700\n",
      "Epoch 951/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.3647 - accuracy: 0.8938 - val_loss: 0.4426 - val_accuracy: 0.8700\n",
      "Epoch 952/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.3637 - accuracy: 0.8938 - val_loss: 0.4415 - val_accuracy: 0.8650\n",
      "Epoch 953/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.3641 - accuracy: 0.8938 - val_loss: 0.4419 - val_accuracy: 0.8650\n",
      "Epoch 954/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.3637 - accuracy: 0.8925 - val_loss: 0.4419 - val_accuracy: 0.8750\n",
      "Epoch 955/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.3636 - accuracy: 0.8975 - val_loss: 0.4419 - val_accuracy: 0.8700\n",
      "Epoch 956/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.3632 - accuracy: 0.8988 - val_loss: 0.4407 - val_accuracy: 0.8650\n",
      "Epoch 957/3000\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.3633 - accuracy: 0.8925 - val_loss: 0.4411 - val_accuracy: 0.8700\n",
      "Epoch 958/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3184 - accuracy: 0.93 - 0s 80us/step - loss: 0.3612 - accuracy: 0.8988 - val_loss: 0.4419 - val_accuracy: 0.8600\n",
      "Epoch 959/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.3626 - accuracy: 0.8950 - val_loss: 0.4403 - val_accuracy: 0.8650\n",
      "Epoch 960/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.3626 - accuracy: 0.8938 - val_loss: 0.4399 - val_accuracy: 0.8750\n",
      "Epoch 961/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.3616 - accuracy: 0.8975 - val_loss: 0.4404 - val_accuracy: 0.8800\n",
      "Epoch 962/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.3617 - accuracy: 0.8950 - val_loss: 0.4415 - val_accuracy: 0.8800\n",
      "Epoch 963/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.3612 - accuracy: 0.9000 - val_loss: 0.4396 - val_accuracy: 0.8700\n",
      "Epoch 964/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.3612 - accuracy: 0.8913 - val_loss: 0.4388 - val_accuracy: 0.8650\n",
      "Epoch 965/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.3615 - accuracy: 0.8975 - val_loss: 0.4382 - val_accuracy: 0.8650\n",
      "Epoch 966/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.3600 - accuracy: 0.8950 - val_loss: 0.4385 - val_accuracy: 0.8750\n",
      "Epoch 967/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.3593 - accuracy: 0.8938 - val_loss: 0.4380 - val_accuracy: 0.8700\n",
      "Epoch 968/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.3598 - accuracy: 0.8963 - val_loss: 0.4394 - val_accuracy: 0.8750\n",
      "Epoch 969/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3343 - accuracy: 0.92 - 0s 78us/step - loss: 0.3589 - accuracy: 0.9000 - val_loss: 0.4376 - val_accuracy: 0.8650\n",
      "Epoch 970/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.3594 - accuracy: 0.8950 - val_loss: 0.4379 - val_accuracy: 0.8750\n",
      "Epoch 971/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.3582 - accuracy: 0.8988 - val_loss: 0.4361 - val_accuracy: 0.8650\n",
      "Epoch 972/3000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 0.3577 - accuracy: 0.8913 - val_loss: 0.4380 - val_accuracy: 0.8700\n",
      "Epoch 973/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3506 - accuracy: 0.90 - 0s 216us/step - loss: 0.3591 - accuracy: 0.8988 - val_loss: 0.4359 - val_accuracy: 0.8700\n",
      "Epoch 974/3000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.3571 - accuracy: 0.8938 - val_loss: 0.4385 - val_accuracy: 0.8800\n",
      "Epoch 975/3000\n",
      "800/800 [==============================] - 0s 220us/step - loss: 0.3580 - accuracy: 0.9013 - val_loss: 0.4360 - val_accuracy: 0.8700\n",
      "Epoch 976/3000\n",
      "800/800 [==============================] - 0s 221us/step - loss: 0.3570 - accuracy: 0.8975 - val_loss: 0.4388 - val_accuracy: 0.8750\n",
      "Epoch 977/3000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 0.3572 - accuracy: 0.8975 - val_loss: 0.4370 - val_accuracy: 0.8800\n",
      "Epoch 978/3000\n",
      "800/800 [==============================] - 0s 239us/step - loss: 0.3561 - accuracy: 0.8988 - val_loss: 0.4379 - val_accuracy: 0.8800\n",
      "Epoch 979/3000\n",
      "800/800 [==============================] - 0s 220us/step - loss: 0.3571 - accuracy: 0.9025 - val_loss: 0.4371 - val_accuracy: 0.8700\n",
      "Epoch 980/3000\n",
      "800/800 [==============================] - 0s 236us/step - loss: 0.3572 - accuracy: 0.8963 - val_loss: 0.4352 - val_accuracy: 0.8650\n",
      "Epoch 981/3000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.3558 - accuracy: 0.8975 - val_loss: 0.4356 - val_accuracy: 0.8700\n",
      "Epoch 982/3000\n",
      "800/800 [==============================] - 0s 484us/step - loss: 0.3564 - accuracy: 0.8950 - val_loss: 0.4343 - val_accuracy: 0.8700\n",
      "Epoch 983/3000\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.3553 - accuracy: 0.8975 - val_loss: 0.4346 - val_accuracy: 0.8750\n",
      "Epoch 984/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.3552 - accuracy: 0.8988 - val_loss: 0.4337 - val_accuracy: 0.8700\n",
      "Epoch 985/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.3548 - accuracy: 0.9000 - val_loss: 0.4346 - val_accuracy: 0.8800\n",
      "Epoch 986/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.3548 - accuracy: 0.8975 - val_loss: 0.4346 - val_accuracy: 0.8850\n",
      "Epoch 987/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.3542 - accuracy: 0.8988 - val_loss: 0.4338 - val_accuracy: 0.8750\n",
      "Epoch 988/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.3545 - accuracy: 0.8963 - val_loss: 0.4335 - val_accuracy: 0.8850\n",
      "Epoch 989/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3489 - accuracy: 0.90 - 0s 100us/step - loss: 0.3540 - accuracy: 0.9013 - val_loss: 0.4333 - val_accuracy: 0.8750\n",
      "Epoch 990/3000\n",
      "800/800 [==============================] - 0s 124us/step - loss: 0.3533 - accuracy: 0.8988 - val_loss: 0.4315 - val_accuracy: 0.8700\n",
      "Epoch 991/3000\n",
      "800/800 [==============================] - 0s 125us/step - loss: 0.3533 - accuracy: 0.8950 - val_loss: 0.4323 - val_accuracy: 0.8750\n",
      "Epoch 992/3000\n",
      "800/800 [==============================] - 0s 133us/step - loss: 0.3531 - accuracy: 0.8950 - val_loss: 0.4318 - val_accuracy: 0.8700\n",
      "Epoch 993/3000\n",
      "800/800 [==============================] - 0s 175us/step - loss: 0.3529 - accuracy: 0.8963 - val_loss: 0.4305 - val_accuracy: 0.8700\n",
      "Epoch 994/3000\n",
      "800/800 [==============================] - 0s 164us/step - loss: 0.3517 - accuracy: 0.9000 - val_loss: 0.4324 - val_accuracy: 0.8600\n",
      "Epoch 995/3000\n",
      "800/800 [==============================] - 0s 233us/step - loss: 0.3528 - accuracy: 0.9013 - val_loss: 0.4319 - val_accuracy: 0.8650\n",
      "Epoch 996/3000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 0.3516 - accuracy: 0.8950 - val_loss: 0.4332 - val_accuracy: 0.8700\n",
      "Epoch 997/3000\n",
      "800/800 [==============================] - 0s 128us/step - loss: 0.3524 - accuracy: 0.9025 - val_loss: 0.4316 - val_accuracy: 0.8800\n",
      "Epoch 998/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.3513 - accuracy: 0.9025 - val_loss: 0.4314 - val_accuracy: 0.8750\n",
      "Epoch 999/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.3514 - accuracy: 0.9050 - val_loss: 0.4296 - val_accuracy: 0.8700\n",
      "Epoch 1000/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.3514 - accuracy: 0.8975 - val_loss: 0.4290 - val_accuracy: 0.8700\n",
      "Epoch 1001/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.3510 - accuracy: 0.9000 - val_loss: 0.4298 - val_accuracy: 0.8700\n",
      "Epoch 1002/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.3499 - accuracy: 0.8988 - val_loss: 0.4285 - val_accuracy: 0.8700\n",
      "Epoch 1003/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.3500 - accuracy: 0.9013 - val_loss: 0.4285 - val_accuracy: 0.8650\n",
      "Epoch 1004/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.3506 - accuracy: 0.8963 - val_loss: 0.4297 - val_accuracy: 0.8700\n",
      "Epoch 1005/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.3495 - accuracy: 0.9038 - val_loss: 0.4284 - val_accuracy: 0.8700\n",
      "Epoch 1006/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.3495 - accuracy: 0.9000 - val_loss: 0.4294 - val_accuracy: 0.8750\n",
      "Epoch 1007/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.3490 - accuracy: 0.9013 - val_loss: 0.4302 - val_accuracy: 0.8800\n",
      "Epoch 1008/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.3493 - accuracy: 0.9013 - val_loss: 0.4288 - val_accuracy: 0.8800\n",
      "Epoch 1009/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.3479 - accuracy: 0.9062 - val_loss: 0.4271 - val_accuracy: 0.8700\n",
      "Epoch 1010/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3791 - accuracy: 0.87 - 0s 81us/step - loss: 0.3481 - accuracy: 0.9013 - val_loss: 0.4267 - val_accuracy: 0.8650\n",
      "Epoch 1011/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.3478 - accuracy: 0.8975 - val_loss: 0.4278 - val_accuracy: 0.8700\n",
      "Epoch 1012/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.3476 - accuracy: 0.9000 - val_loss: 0.4270 - val_accuracy: 0.8700\n",
      "Epoch 1013/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3511 - accuracy: 0.90 - 0s 101us/step - loss: 0.3474 - accuracy: 0.9062 - val_loss: 0.4271 - val_accuracy: 0.8700\n",
      "Epoch 1014/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.3476 - accuracy: 0.8988 - val_loss: 0.4275 - val_accuracy: 0.8800\n",
      "Epoch 1015/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.3467 - accuracy: 0.8963 - val_loss: 0.4256 - val_accuracy: 0.8650\n",
      "Epoch 1016/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.3463 - accuracy: 0.8963 - val_loss: 0.4275 - val_accuracy: 0.8650\n",
      "Epoch 1017/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.3468 - accuracy: 0.8988 - val_loss: 0.4262 - val_accuracy: 0.8700\n",
      "Epoch 1018/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.3456 - accuracy: 0.9062 - val_loss: 0.4259 - val_accuracy: 0.8700\n",
      "Epoch 1019/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.3456 - accuracy: 0.8963 - val_loss: 0.4252 - val_accuracy: 0.8700\n",
      "Epoch 1020/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.3465 - accuracy: 0.8988 - val_loss: 0.4263 - val_accuracy: 0.8700\n",
      "Epoch 1021/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.3449 - accuracy: 0.9000 - val_loss: 0.4253 - val_accuracy: 0.8750\n",
      "Epoch 1022/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.3455 - accuracy: 0.8975 - val_loss: 0.4255 - val_accuracy: 0.8850\n",
      "Epoch 1023/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.3444 - accuracy: 0.9025 - val_loss: 0.4258 - val_accuracy: 0.8750\n",
      "Epoch 1024/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.3448 - accuracy: 0.9025 - val_loss: 0.4250 - val_accuracy: 0.8750\n",
      "Epoch 1025/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.3441 - accuracy: 0.9000 - val_loss: 0.4244 - val_accuracy: 0.8750\n",
      "Epoch 1026/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.3440 - accuracy: 0.9038 - val_loss: 0.4239 - val_accuracy: 0.8700\n",
      "Epoch 1027/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.3438 - accuracy: 0.9013 - val_loss: 0.4246 - val_accuracy: 0.8800\n",
      "Epoch 1028/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.3438 - accuracy: 0.9038 - val_loss: 0.4240 - val_accuracy: 0.8800\n",
      "Epoch 1029/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3347 - accuracy: 0.90 - 0s 120us/step - loss: 0.3435 - accuracy: 0.9062 - val_loss: 0.4230 - val_accuracy: 0.8700\n",
      "Epoch 1030/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.3427 - accuracy: 0.8988 - val_loss: 0.4241 - val_accuracy: 0.8750\n",
      "Epoch 1031/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3377 - accuracy: 0.90 - 0s 108us/step - loss: 0.3422 - accuracy: 0.9038 - val_loss: 0.4216 - val_accuracy: 0.8650\n",
      "Epoch 1032/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.3426 - accuracy: 0.9000 - val_loss: 0.4223 - val_accuracy: 0.8750\n",
      "Epoch 1033/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.3421 - accuracy: 0.9062 - val_loss: 0.4220 - val_accuracy: 0.8700\n",
      "Epoch 1034/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.3419 - accuracy: 0.9038 - val_loss: 0.4226 - val_accuracy: 0.8750\n",
      "Epoch 1035/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.3423 - accuracy: 0.8988 - val_loss: 0.4224 - val_accuracy: 0.8850\n",
      "Epoch 1036/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.3408 - accuracy: 0.9013 - val_loss: 0.4233 - val_accuracy: 0.8750\n",
      "Epoch 1037/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.3406 - accuracy: 0.9062 - val_loss: 0.4214 - val_accuracy: 0.8700\n",
      "Epoch 1038/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.3405 - accuracy: 0.9000 - val_loss: 0.4227 - val_accuracy: 0.8800\n",
      "Epoch 1039/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.3415 - accuracy: 0.9025 - val_loss: 0.4211 - val_accuracy: 0.8750\n",
      "Epoch 1040/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.3395 - accuracy: 0.9038 - val_loss: 0.4222 - val_accuracy: 0.8700\n",
      "Epoch 1041/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.3404 - accuracy: 0.9000 - val_loss: 0.4201 - val_accuracy: 0.8700\n",
      "Epoch 1042/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.3395 - accuracy: 0.9025 - val_loss: 0.4208 - val_accuracy: 0.8750\n",
      "Epoch 1043/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.3393 - accuracy: 0.9038 - val_loss: 0.4198 - val_accuracy: 0.8750\n",
      "Epoch 1044/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.3392 - accuracy: 0.9025 - val_loss: 0.4205 - val_accuracy: 0.8700\n",
      "Epoch 1045/3000\n",
      "800/800 [==============================] - 0s 123us/step - loss: 0.3393 - accuracy: 0.9013 - val_loss: 0.4213 - val_accuracy: 0.8850\n",
      "Epoch 1046/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.3389 - accuracy: 0.9038 - val_loss: 0.4195 - val_accuracy: 0.8800\n",
      "Epoch 1047/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3587 - accuracy: 0.87 - 0s 79us/step - loss: 0.3388 - accuracy: 0.9038 - val_loss: 0.4199 - val_accuracy: 0.8850\n",
      "Epoch 1048/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.3381 - accuracy: 0.9050 - val_loss: 0.4177 - val_accuracy: 0.8750\n",
      "Epoch 1049/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.3383 - accuracy: 0.9000 - val_loss: 0.4194 - val_accuracy: 0.8750\n",
      "Epoch 1050/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.3373 - accuracy: 0.9025 - val_loss: 0.4204 - val_accuracy: 0.8800\n",
      "Epoch 1051/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.3378 - accuracy: 0.9050 - val_loss: 0.4193 - val_accuracy: 0.8800\n",
      "Epoch 1052/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.3378 - accuracy: 0.9038 - val_loss: 0.4185 - val_accuracy: 0.8700\n",
      "Epoch 1053/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.3367 - accuracy: 0.9062 - val_loss: 0.4173 - val_accuracy: 0.8700\n",
      "Epoch 1054/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.3371 - accuracy: 0.9025 - val_loss: 0.4166 - val_accuracy: 0.8700\n",
      "Epoch 1055/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.3372 - accuracy: 0.8988 - val_loss: 0.4160 - val_accuracy: 0.8700\n",
      "Epoch 1056/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.3361 - accuracy: 0.9013 - val_loss: 0.4167 - val_accuracy: 0.8700\n",
      "Epoch 1057/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.3357 - accuracy: 0.9075 - val_loss: 0.4171 - val_accuracy: 0.8650\n",
      "Epoch 1058/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.3365 - accuracy: 0.9000 - val_loss: 0.4160 - val_accuracy: 0.8650\n",
      "Epoch 1059/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.3361 - accuracy: 0.9000 - val_loss: 0.4153 - val_accuracy: 0.8700\n",
      "Epoch 1060/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.3354 - accuracy: 0.9050 - val_loss: 0.4160 - val_accuracy: 0.8650\n",
      "Epoch 1061/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.3352 - accuracy: 0.9050 - val_loss: 0.4171 - val_accuracy: 0.8850\n",
      "Epoch 1062/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.3351 - accuracy: 0.9075 - val_loss: 0.4158 - val_accuracy: 0.8750\n",
      "Epoch 1063/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.3347 - accuracy: 0.9062 - val_loss: 0.4158 - val_accuracy: 0.8650\n",
      "Epoch 1064/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.3346 - accuracy: 0.8975 - val_loss: 0.4149 - val_accuracy: 0.8750\n",
      "Epoch 1065/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3194 - accuracy: 0.87 - 0s 81us/step - loss: 0.3343 - accuracy: 0.9100 - val_loss: 0.4148 - val_accuracy: 0.8700\n",
      "Epoch 1066/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.3339 - accuracy: 0.9025 - val_loss: 0.4148 - val_accuracy: 0.8800\n",
      "Epoch 1067/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.3338 - accuracy: 0.9100 - val_loss: 0.4154 - val_accuracy: 0.8850\n",
      "Epoch 1068/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.3339 - accuracy: 0.9050 - val_loss: 0.4137 - val_accuracy: 0.8700\n",
      "Epoch 1069/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.3333 - accuracy: 0.9025 - val_loss: 0.4138 - val_accuracy: 0.8800\n",
      "Epoch 1070/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.3332 - accuracy: 0.9062 - val_loss: 0.4145 - val_accuracy: 0.8800\n",
      "Epoch 1071/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.3323 - accuracy: 0.9075 - val_loss: 0.4144 - val_accuracy: 0.8750\n",
      "Epoch 1072/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.3322 - accuracy: 0.9050 - val_loss: 0.4147 - val_accuracy: 0.8850\n",
      "Epoch 1073/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.3322 - accuracy: 0.9025 - val_loss: 0.4131 - val_accuracy: 0.8750\n",
      "Epoch 1074/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.3317 - accuracy: 0.9038 - val_loss: 0.4122 - val_accuracy: 0.8700\n",
      "Epoch 1075/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.3316 - accuracy: 0.9062 - val_loss: 0.4130 - val_accuracy: 0.8700\n",
      "Epoch 1076/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.3305 - accuracy: 0.9013 - val_loss: 0.4118 - val_accuracy: 0.8650\n",
      "Epoch 1077/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.3318 - accuracy: 0.9025 - val_loss: 0.4124 - val_accuracy: 0.8800\n",
      "Epoch 1078/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.3311 - accuracy: 0.9062 - val_loss: 0.4117 - val_accuracy: 0.8700\n",
      "Epoch 1079/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.3311 - accuracy: 0.9050 - val_loss: 0.4126 - val_accuracy: 0.8800\n",
      "Epoch 1080/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.3301 - accuracy: 0.9050 - val_loss: 0.4129 - val_accuracy: 0.8850\n",
      "Epoch 1081/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.3304 - accuracy: 0.9062 - val_loss: 0.4114 - val_accuracy: 0.8700\n",
      "Epoch 1082/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.3295 - accuracy: 0.9025 - val_loss: 0.4123 - val_accuracy: 0.8800\n",
      "Epoch 1083/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.3300 - accuracy: 0.9013 - val_loss: 0.4096 - val_accuracy: 0.8700\n",
      "Epoch 1084/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3177 - accuracy: 0.91 - 0s 103us/step - loss: 0.3300 - accuracy: 0.9050 - val_loss: 0.4103 - val_accuracy: 0.8800\n",
      "Epoch 1085/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.3293 - accuracy: 0.9075 - val_loss: 0.4093 - val_accuracy: 0.8650\n",
      "Epoch 1086/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.3285 - accuracy: 0.9013 - val_loss: 0.4113 - val_accuracy: 0.8800\n",
      "Epoch 1087/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.3284 - accuracy: 0.9050 - val_loss: 0.4108 - val_accuracy: 0.8700\n",
      "Epoch 1088/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.3283 - accuracy: 0.9038 - val_loss: 0.4110 - val_accuracy: 0.8800\n",
      "Epoch 1089/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.3282 - accuracy: 0.9038 - val_loss: 0.4097 - val_accuracy: 0.8650\n",
      "Epoch 1090/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.3272 - accuracy: 0.9025 - val_loss: 0.4082 - val_accuracy: 0.8700\n",
      "Epoch 1091/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.3273 - accuracy: 0.9038 - val_loss: 0.4091 - val_accuracy: 0.8700\n",
      "Epoch 1092/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.3277 - accuracy: 0.9062 - val_loss: 0.4085 - val_accuracy: 0.8750\n",
      "Epoch 1093/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.3277 - accuracy: 0.9075 - val_loss: 0.4093 - val_accuracy: 0.8700\n",
      "Epoch 1094/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.3270 - accuracy: 0.9038 - val_loss: 0.4088 - val_accuracy: 0.8700\n",
      "Epoch 1095/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.3264 - accuracy: 0.9038 - val_loss: 0.4073 - val_accuracy: 0.8650\n",
      "Epoch 1096/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.3270 - accuracy: 0.9038 - val_loss: 0.4084 - val_accuracy: 0.8800\n",
      "Epoch 1097/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.3262 - accuracy: 0.9062 - val_loss: 0.4089 - val_accuracy: 0.8800\n",
      "Epoch 1098/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.3264 - accuracy: 0.9025 - val_loss: 0.4078 - val_accuracy: 0.8800\n",
      "Epoch 1099/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.3253 - accuracy: 0.9075 - val_loss: 0.4087 - val_accuracy: 0.8750\n",
      "Epoch 1100/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.3260 - accuracy: 0.9087 - val_loss: 0.4081 - val_accuracy: 0.8800\n",
      "Epoch 1101/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.3258 - accuracy: 0.9087 - val_loss: 0.4068 - val_accuracy: 0.8800\n",
      "Epoch 1102/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.3251 - accuracy: 0.9062 - val_loss: 0.4081 - val_accuracy: 0.8800\n",
      "Epoch 1103/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.3250 - accuracy: 0.9075 - val_loss: 0.4081 - val_accuracy: 0.8850\n",
      "Epoch 1104/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.3247 - accuracy: 0.9075 - val_loss: 0.4069 - val_accuracy: 0.8700\n",
      "Epoch 1105/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.3244 - accuracy: 0.9050 - val_loss: 0.4082 - val_accuracy: 0.8850\n",
      "Epoch 1106/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.3246 - accuracy: 0.9038 - val_loss: 0.4068 - val_accuracy: 0.8800\n",
      "Epoch 1107/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.3246 - accuracy: 0.9050 - val_loss: 0.4050 - val_accuracy: 0.8700\n",
      "Epoch 1108/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.3238 - accuracy: 0.9050 - val_loss: 0.4041 - val_accuracy: 0.8700\n",
      "Epoch 1109/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.3242 - accuracy: 0.9050 - val_loss: 0.4051 - val_accuracy: 0.8800\n",
      "Epoch 1110/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.3229 - accuracy: 0.9013 - val_loss: 0.4051 - val_accuracy: 0.8800\n",
      "Epoch 1111/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.3241 - accuracy: 0.9075 - val_loss: 0.4052 - val_accuracy: 0.8800\n",
      "Epoch 1112/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3210 - accuracy: 0.90 - 0s 96us/step - loss: 0.3229 - accuracy: 0.9075 - val_loss: 0.4055 - val_accuracy: 0.8800\n",
      "Epoch 1113/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.3239 - accuracy: 0.9075 - val_loss: 0.4043 - val_accuracy: 0.8750\n",
      "Epoch 1114/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.3222 - accuracy: 0.9050 - val_loss: 0.4052 - val_accuracy: 0.8700\n",
      "Epoch 1115/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.3230 - accuracy: 0.9062 - val_loss: 0.4037 - val_accuracy: 0.8700\n",
      "Epoch 1116/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.3222 - accuracy: 0.9050 - val_loss: 0.4037 - val_accuracy: 0.8700\n",
      "Epoch 1117/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.3213 - accuracy: 0.9075 - val_loss: 0.4053 - val_accuracy: 0.8700\n",
      "Epoch 1118/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.3219 - accuracy: 0.9075 - val_loss: 0.4047 - val_accuracy: 0.8700\n",
      "Epoch 1119/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.3214 - accuracy: 0.9075 - val_loss: 0.4034 - val_accuracy: 0.8800\n",
      "Epoch 1120/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.3213 - accuracy: 0.9075 - val_loss: 0.4031 - val_accuracy: 0.8650\n",
      "Epoch 1121/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.3210 - accuracy: 0.9075 - val_loss: 0.4016 - val_accuracy: 0.8650\n",
      "Epoch 1122/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.3211 - accuracy: 0.9062 - val_loss: 0.4026 - val_accuracy: 0.8800\n",
      "Epoch 1123/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.3203 - accuracy: 0.9087 - val_loss: 0.4009 - val_accuracy: 0.8700\n",
      "Epoch 1124/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.3204 - accuracy: 0.9087 - val_loss: 0.4017 - val_accuracy: 0.8700\n",
      "Epoch 1125/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.3203 - accuracy: 0.9112 - val_loss: 0.4034 - val_accuracy: 0.8650\n",
      "Epoch 1126/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.3199 - accuracy: 0.9062 - val_loss: 0.4030 - val_accuracy: 0.8800\n",
      "Epoch 1127/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.3198 - accuracy: 0.9087 - val_loss: 0.4036 - val_accuracy: 0.8850\n",
      "Epoch 1128/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.3193 - accuracy: 0.9075 - val_loss: 0.4021 - val_accuracy: 0.8800\n",
      "Epoch 1129/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.3198 - accuracy: 0.9087 - val_loss: 0.4026 - val_accuracy: 0.8800\n",
      "Epoch 1130/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.3191 - accuracy: 0.9087 - val_loss: 0.4023 - val_accuracy: 0.8800\n",
      "Epoch 1131/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3213 - accuracy: 0.90 - 0s 109us/step - loss: 0.3189 - accuracy: 0.9087 - val_loss: 0.4018 - val_accuracy: 0.8800\n",
      "Epoch 1132/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.3183 - accuracy: 0.9050 - val_loss: 0.4002 - val_accuracy: 0.8800\n",
      "Epoch 1133/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.3183 - accuracy: 0.9062 - val_loss: 0.4009 - val_accuracy: 0.8800\n",
      "Epoch 1134/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.3183 - accuracy: 0.9062 - val_loss: 0.4001 - val_accuracy: 0.8650\n",
      "Epoch 1135/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.3181 - accuracy: 0.9087 - val_loss: 0.4002 - val_accuracy: 0.8800\n",
      "Epoch 1136/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.3180 - accuracy: 0.9062 - val_loss: 0.4013 - val_accuracy: 0.8800\n",
      "Epoch 1137/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.3166 - accuracy: 0.9075 - val_loss: 0.3984 - val_accuracy: 0.8700\n",
      "Epoch 1138/3000\n",
      "800/800 [==============================] - 0s 124us/step - loss: 0.3177 - accuracy: 0.9112 - val_loss: 0.3988 - val_accuracy: 0.8800\n",
      "Epoch 1139/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.3168 - accuracy: 0.9137 - val_loss: 0.3985 - val_accuracy: 0.8700\n",
      "Epoch 1140/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.3169 - accuracy: 0.9100 - val_loss: 0.3988 - val_accuracy: 0.8800\n",
      "Epoch 1141/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.3164 - accuracy: 0.9087 - val_loss: 0.3986 - val_accuracy: 0.8800\n",
      "Epoch 1142/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.3166 - accuracy: 0.9075 - val_loss: 0.3994 - val_accuracy: 0.8700\n",
      "Epoch 1143/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.3163 - accuracy: 0.9062 - val_loss: 0.3981 - val_accuracy: 0.8700\n",
      "Epoch 1144/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.3157 - accuracy: 0.9075 - val_loss: 0.3982 - val_accuracy: 0.8800\n",
      "Epoch 1145/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.3160 - accuracy: 0.9100 - val_loss: 0.3980 - val_accuracy: 0.8800\n",
      "Epoch 1146/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.3153 - accuracy: 0.9087 - val_loss: 0.3982 - val_accuracy: 0.8800\n",
      "Epoch 1147/3000\n",
      "800/800 [==============================] - 0s 228us/step - loss: 0.3154 - accuracy: 0.9062 - val_loss: 0.3975 - val_accuracy: 0.8800\n",
      "Epoch 1148/3000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 0.3154 - accuracy: 0.9112 - val_loss: 0.3971 - val_accuracy: 0.8700\n",
      "Epoch 1149/3000\n",
      "800/800 [==============================] - 0s 321us/step - loss: 0.3156 - accuracy: 0.9087 - val_loss: 0.3962 - val_accuracy: 0.8650\n",
      "Epoch 1150/3000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 0.3146 - accuracy: 0.9075 - val_loss: 0.3959 - val_accuracy: 0.8700\n",
      "Epoch 1151/3000\n",
      "800/800 [==============================] - 0s 286us/step - loss: 0.3144 - accuracy: 0.9137 - val_loss: 0.3978 - val_accuracy: 0.8700\n",
      "Epoch 1152/3000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.3142 - accuracy: 0.9062 - val_loss: 0.3977 - val_accuracy: 0.8800\n",
      "Epoch 1153/3000\n",
      "800/800 [==============================] - 0s 236us/step - loss: 0.3143 - accuracy: 0.9112 - val_loss: 0.3954 - val_accuracy: 0.8700\n",
      "Epoch 1154/3000\n",
      "800/800 [==============================] - 0s 134us/step - loss: 0.3139 - accuracy: 0.9100 - val_loss: 0.3960 - val_accuracy: 0.8800\n",
      "Epoch 1155/3000\n",
      "800/800 [==============================] - 0s 153us/step - loss: 0.3128 - accuracy: 0.9100 - val_loss: 0.3960 - val_accuracy: 0.8800\n",
      "Epoch 1156/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.3135 - accuracy: 0.9087 - val_loss: 0.3973 - val_accuracy: 0.8700\n",
      "Epoch 1157/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.3133 - accuracy: 0.9100 - val_loss: 0.3973 - val_accuracy: 0.8750\n",
      "Epoch 1158/3000\n",
      "800/800 [==============================] - 0s 136us/step - loss: 0.3131 - accuracy: 0.9038 - val_loss: 0.3960 - val_accuracy: 0.8800\n",
      "Epoch 1159/3000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 0.3126 - accuracy: 0.9100 - val_loss: 0.3951 - val_accuracy: 0.8700\n",
      "Epoch 1160/3000\n",
      "800/800 [==============================] - 0s 164us/step - loss: 0.3125 - accuracy: 0.9100 - val_loss: 0.3963 - val_accuracy: 0.8800\n",
      "Epoch 1161/3000\n",
      "800/800 [==============================] - 0s 149us/step - loss: 0.3122 - accuracy: 0.9100 - val_loss: 0.3947 - val_accuracy: 0.8800\n",
      "Epoch 1162/3000\n",
      "800/800 [==============================] - 0s 173us/step - loss: 0.3123 - accuracy: 0.9125 - val_loss: 0.3955 - val_accuracy: 0.8800\n",
      "Epoch 1163/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.3117 - accuracy: 0.9112 - val_loss: 0.3931 - val_accuracy: 0.8750\n",
      "Epoch 1164/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.3116 - accuracy: 0.9125 - val_loss: 0.3936 - val_accuracy: 0.8800\n",
      "Epoch 1165/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.3111 - accuracy: 0.9137 - val_loss: 0.3956 - val_accuracy: 0.8800\n",
      "Epoch 1166/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.3117 - accuracy: 0.9112 - val_loss: 0.3947 - val_accuracy: 0.8800\n",
      "Epoch 1167/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.3106 - accuracy: 0.9100 - val_loss: 0.3970 - val_accuracy: 0.8750\n",
      "Epoch 1168/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.3115 - accuracy: 0.9112 - val_loss: 0.3955 - val_accuracy: 0.8850\n",
      "Epoch 1169/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.3102 - accuracy: 0.9075 - val_loss: 0.3937 - val_accuracy: 0.8800\n",
      "Epoch 1170/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.3103 - accuracy: 0.9150 - val_loss: 0.3939 - val_accuracy: 0.8650\n",
      "Epoch 1171/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.3107 - accuracy: 0.9100 - val_loss: 0.3920 - val_accuracy: 0.8800\n",
      "Epoch 1172/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.3101 - accuracy: 0.9112 - val_loss: 0.3920 - val_accuracy: 0.8800\n",
      "Epoch 1173/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.3095 - accuracy: 0.9150 - val_loss: 0.3934 - val_accuracy: 0.8800\n",
      "Epoch 1174/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.3095 - accuracy: 0.9087 - val_loss: 0.3935 - val_accuracy: 0.8800\n",
      "Epoch 1175/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.3090 - accuracy: 0.9125 - val_loss: 0.3946 - val_accuracy: 0.8800\n",
      "Epoch 1176/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.3082 - accuracy: 0.9112 - val_loss: 0.3939 - val_accuracy: 0.8800\n",
      "Epoch 1177/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.3091 - accuracy: 0.9150 - val_loss: 0.3941 - val_accuracy: 0.8800\n",
      "Epoch 1178/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.3085 - accuracy: 0.9150 - val_loss: 0.3936 - val_accuracy: 0.8800\n",
      "Epoch 1179/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.3090 - accuracy: 0.9125 - val_loss: 0.3921 - val_accuracy: 0.8800\n",
      "Epoch 1180/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.3087 - accuracy: 0.9100 - val_loss: 0.3920 - val_accuracy: 0.8800\n",
      "Epoch 1181/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.3081 - accuracy: 0.9125 - val_loss: 0.3919 - val_accuracy: 0.8800\n",
      "Epoch 1182/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.3076 - accuracy: 0.9125 - val_loss: 0.3901 - val_accuracy: 0.8750\n",
      "Epoch 1183/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.3077 - accuracy: 0.9150 - val_loss: 0.3905 - val_accuracy: 0.8800\n",
      "Epoch 1184/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.3072 - accuracy: 0.9125 - val_loss: 0.3893 - val_accuracy: 0.8650\n",
      "Epoch 1185/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.3073 - accuracy: 0.9100 - val_loss: 0.3908 - val_accuracy: 0.8800\n",
      "Epoch 1186/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.3070 - accuracy: 0.9100 - val_loss: 0.3905 - val_accuracy: 0.8800\n",
      "Epoch 1187/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3358 - accuracy: 0.87 - 0s 83us/step - loss: 0.3064 - accuracy: 0.9125 - val_loss: 0.3894 - val_accuracy: 0.8700\n",
      "Epoch 1188/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.3068 - accuracy: 0.9100 - val_loss: 0.3885 - val_accuracy: 0.8800\n",
      "Epoch 1189/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.3062 - accuracy: 0.9137 - val_loss: 0.3901 - val_accuracy: 0.8800\n",
      "Epoch 1190/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.3059 - accuracy: 0.9137 - val_loss: 0.3894 - val_accuracy: 0.8800\n",
      "Epoch 1191/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.3065 - accuracy: 0.9112 - val_loss: 0.3911 - val_accuracy: 0.8800\n",
      "Epoch 1192/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.3059 - accuracy: 0.9125 - val_loss: 0.3901 - val_accuracy: 0.8800\n",
      "Epoch 1193/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.3056 - accuracy: 0.9087 - val_loss: 0.3882 - val_accuracy: 0.8750\n",
      "Epoch 1194/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.3049 - accuracy: 0.9112 - val_loss: 0.3883 - val_accuracy: 0.8800\n",
      "Epoch 1195/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.3053 - accuracy: 0.9187 - val_loss: 0.3886 - val_accuracy: 0.8650\n",
      "Epoch 1196/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.3058 - accuracy: 0.9125 - val_loss: 0.3881 - val_accuracy: 0.8800\n",
      "Epoch 1197/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.3042 - accuracy: 0.9125 - val_loss: 0.3879 - val_accuracy: 0.8750\n",
      "Epoch 1198/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.3045 - accuracy: 0.9150 - val_loss: 0.3875 - val_accuracy: 0.8800\n",
      "Epoch 1199/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.3042 - accuracy: 0.9125 - val_loss: 0.3881 - val_accuracy: 0.8800\n",
      "Epoch 1200/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.3045 - accuracy: 0.9162 - val_loss: 0.3884 - val_accuracy: 0.8800\n",
      "Epoch 1201/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.3043 - accuracy: 0.9125 - val_loss: 0.3881 - val_accuracy: 0.8800\n",
      "Epoch 1202/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.3043 - accuracy: 0.9137 - val_loss: 0.3876 - val_accuracy: 0.8800\n",
      "Epoch 1203/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.3033 - accuracy: 0.9125 - val_loss: 0.3890 - val_accuracy: 0.8800\n",
      "Epoch 1204/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.3034 - accuracy: 0.9137 - val_loss: 0.3884 - val_accuracy: 0.8800\n",
      "Epoch 1205/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3040 - accuracy: 0.91 - 0s 98us/step - loss: 0.3036 - accuracy: 0.9112 - val_loss: 0.3856 - val_accuracy: 0.8800\n",
      "Epoch 1206/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.3030 - accuracy: 0.9125 - val_loss: 0.3866 - val_accuracy: 0.8800\n",
      "Epoch 1207/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.3031 - accuracy: 0.9112 - val_loss: 0.3862 - val_accuracy: 0.8800\n",
      "Epoch 1208/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.3024 - accuracy: 0.9137 - val_loss: 0.3879 - val_accuracy: 0.8800\n",
      "Epoch 1209/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.3022 - accuracy: 0.9125 - val_loss: 0.3852 - val_accuracy: 0.8800\n",
      "Epoch 1210/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.3018 - accuracy: 0.9137 - val_loss: 0.3859 - val_accuracy: 0.8800\n",
      "Epoch 1211/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.3018 - accuracy: 0.9125 - val_loss: 0.3863 - val_accuracy: 0.8800\n",
      "Epoch 1212/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.3014 - accuracy: 0.9150 - val_loss: 0.3872 - val_accuracy: 0.8800\n",
      "Epoch 1213/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.3022 - accuracy: 0.9125 - val_loss: 0.3854 - val_accuracy: 0.8800\n",
      "Epoch 1214/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.3013 - accuracy: 0.9150 - val_loss: 0.3862 - val_accuracy: 0.8800\n",
      "Epoch 1215/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.3009 - accuracy: 0.9137 - val_loss: 0.3869 - val_accuracy: 0.8800\n",
      "Epoch 1216/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.3009 - accuracy: 0.9112 - val_loss: 0.3844 - val_accuracy: 0.8800\n",
      "Epoch 1217/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.3001 - accuracy: 0.9162 - val_loss: 0.3838 - val_accuracy: 0.8800\n",
      "Epoch 1218/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.3005 - accuracy: 0.9125 - val_loss: 0.3841 - val_accuracy: 0.8800\n",
      "Epoch 1219/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.3000 - accuracy: 0.9125 - val_loss: 0.3859 - val_accuracy: 0.8800\n",
      "Epoch 1220/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.3002 - accuracy: 0.9112 - val_loss: 0.3852 - val_accuracy: 0.8750\n",
      "Epoch 1221/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2991 - accuracy: 0.9100 - val_loss: 0.3857 - val_accuracy: 0.8800\n",
      "Epoch 1222/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.3009 - accuracy: 0.9137 - val_loss: 0.3849 - val_accuracy: 0.8800\n",
      "Epoch 1223/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2996 - accuracy: 0.9137 - val_loss: 0.3844 - val_accuracy: 0.8800\n",
      "Epoch 1224/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.2993 - accuracy: 0.9150 - val_loss: 0.3857 - val_accuracy: 0.8800\n",
      "Epoch 1225/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.2989 - accuracy: 0.9125 - val_loss: 0.3828 - val_accuracy: 0.8800\n",
      "Epoch 1226/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.2995 - accuracy: 0.9162 - val_loss: 0.3842 - val_accuracy: 0.8800\n",
      "Epoch 1227/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2942 - accuracy: 0.91 - 0s 101us/step - loss: 0.2986 - accuracy: 0.9150 - val_loss: 0.3830 - val_accuracy: 0.8800\n",
      "Epoch 1228/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2991 - accuracy: 0.9150 - val_loss: 0.3830 - val_accuracy: 0.8800\n",
      "Epoch 1229/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.2982 - accuracy: 0.9137 - val_loss: 0.3831 - val_accuracy: 0.8750\n",
      "Epoch 1230/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.2980 - accuracy: 0.9150 - val_loss: 0.3822 - val_accuracy: 0.8800\n",
      "Epoch 1231/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2986 - accuracy: 0.9137 - val_loss: 0.3822 - val_accuracy: 0.8800\n",
      "Epoch 1232/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.2972 - accuracy: 0.9162 - val_loss: 0.3814 - val_accuracy: 0.8800\n",
      "Epoch 1233/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.2972 - accuracy: 0.9137 - val_loss: 0.3832 - val_accuracy: 0.8800\n",
      "Epoch 1234/3000\n",
      "800/800 [==============================] - 0s 148us/step - loss: 0.2973 - accuracy: 0.9150 - val_loss: 0.3827 - val_accuracy: 0.8800\n",
      "Epoch 1235/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.2972 - accuracy: 0.9150 - val_loss: 0.3825 - val_accuracy: 0.8800\n",
      "Epoch 1236/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.2974 - accuracy: 0.9100 - val_loss: 0.3803 - val_accuracy: 0.8800\n",
      "Epoch 1237/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.2969 - accuracy: 0.9187 - val_loss: 0.3801 - val_accuracy: 0.8800\n",
      "Epoch 1238/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.2959 - accuracy: 0.9175 - val_loss: 0.3797 - val_accuracy: 0.8700\n",
      "Epoch 1239/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2957 - accuracy: 0.9150 - val_loss: 0.3822 - val_accuracy: 0.8800\n",
      "Epoch 1240/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2965 - accuracy: 0.9162 - val_loss: 0.3817 - val_accuracy: 0.8750\n",
      "Epoch 1241/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2961 - accuracy: 0.9137 - val_loss: 0.3800 - val_accuracy: 0.8800\n",
      "Epoch 1242/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.2962 - accuracy: 0.9150 - val_loss: 0.3785 - val_accuracy: 0.8750\n",
      "Epoch 1243/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2952 - accuracy: 0.9150 - val_loss: 0.3800 - val_accuracy: 0.8650\n",
      "Epoch 1244/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2730 - accuracy: 0.92 - 0s 110us/step - loss: 0.2953 - accuracy: 0.9150 - val_loss: 0.3795 - val_accuracy: 0.8800\n",
      "Epoch 1245/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2949 - accuracy: 0.91 - 0s 104us/step - loss: 0.2955 - accuracy: 0.9137 - val_loss: 0.3799 - val_accuracy: 0.8800\n",
      "Epoch 1246/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.2957 - accuracy: 0.9125 - val_loss: 0.3792 - val_accuracy: 0.8800\n",
      "Epoch 1247/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.2946 - accuracy: 0.9150 - val_loss: 0.3793 - val_accuracy: 0.8800\n",
      "Epoch 1248/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.2944 - accuracy: 0.9137 - val_loss: 0.3798 - val_accuracy: 0.8750\n",
      "Epoch 1249/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2941 - accuracy: 0.9175 - val_loss: 0.3803 - val_accuracy: 0.8800\n",
      "Epoch 1250/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.2947 - accuracy: 0.9150 - val_loss: 0.3777 - val_accuracy: 0.8800\n",
      "Epoch 1251/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2945 - accuracy: 0.9162 - val_loss: 0.3772 - val_accuracy: 0.8750\n",
      "Epoch 1252/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.2940 - accuracy: 0.9175 - val_loss: 0.3786 - val_accuracy: 0.8750\n",
      "Epoch 1253/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.2947 - accuracy: 0.9137 - val_loss: 0.3784 - val_accuracy: 0.8800\n",
      "Epoch 1254/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2933 - accuracy: 0.9150 - val_loss: 0.3790 - val_accuracy: 0.8800\n",
      "Epoch 1255/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2931 - accuracy: 0.9125 - val_loss: 0.3765 - val_accuracy: 0.8750\n",
      "Epoch 1256/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2935 - accuracy: 0.9150 - val_loss: 0.3772 - val_accuracy: 0.8800\n",
      "Epoch 1257/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.2927 - accuracy: 0.9175 - val_loss: 0.3776 - val_accuracy: 0.8800\n",
      "Epoch 1258/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2925 - accuracy: 0.9162 - val_loss: 0.3776 - val_accuracy: 0.8800\n",
      "Epoch 1259/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2931 - accuracy: 0.9150 - val_loss: 0.3758 - val_accuracy: 0.8800\n",
      "Epoch 1260/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2936 - accuracy: 0.90 - 0s 79us/step - loss: 0.2920 - accuracy: 0.9150 - val_loss: 0.3766 - val_accuracy: 0.8750\n",
      "Epoch 1261/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2926 - accuracy: 0.9175 - val_loss: 0.3762 - val_accuracy: 0.8800\n",
      "Epoch 1262/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.2921 - accuracy: 0.9162 - val_loss: 0.3767 - val_accuracy: 0.8750\n",
      "Epoch 1263/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.2924 - accuracy: 0.9175 - val_loss: 0.3768 - val_accuracy: 0.8800\n",
      "Epoch 1264/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.2917 - accuracy: 0.9137 - val_loss: 0.3756 - val_accuracy: 0.8800\n",
      "Epoch 1265/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.2923 - accuracy: 0.9200 - val_loss: 0.3765 - val_accuracy: 0.8800\n",
      "Epoch 1266/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.2914 - accuracy: 0.9187 - val_loss: 0.3767 - val_accuracy: 0.8800\n",
      "Epoch 1267/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.2908 - accuracy: 0.9212 - val_loss: 0.3761 - val_accuracy: 0.8800\n",
      "Epoch 1268/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.2915 - accuracy: 0.9150 - val_loss: 0.3758 - val_accuracy: 0.8800\n",
      "Epoch 1269/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.2910 - accuracy: 0.9150 - val_loss: 0.3756 - val_accuracy: 0.8800\n",
      "Epoch 1270/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.2902 - accuracy: 0.9162 - val_loss: 0.3760 - val_accuracy: 0.8800\n",
      "Epoch 1271/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.2906 - accuracy: 0.9137 - val_loss: 0.3769 - val_accuracy: 0.8800\n",
      "Epoch 1272/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.2900 - accuracy: 0.9187 - val_loss: 0.3736 - val_accuracy: 0.8800\n",
      "Epoch 1273/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.2907 - accuracy: 0.9162 - val_loss: 0.3747 - val_accuracy: 0.8800\n",
      "Epoch 1274/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.2901 - accuracy: 0.9212 - val_loss: 0.3758 - val_accuracy: 0.8800\n",
      "Epoch 1275/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.2897 - accuracy: 0.9175 - val_loss: 0.3760 - val_accuracy: 0.8750\n",
      "Epoch 1276/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2898 - accuracy: 0.9125 - val_loss: 0.3739 - val_accuracy: 0.8750\n",
      "Epoch 1277/3000\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.2890 - accuracy: 0.9175 - val_loss: 0.3753 - val_accuracy: 0.8800\n",
      "Epoch 1278/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2893 - accuracy: 0.9200 - val_loss: 0.3750 - val_accuracy: 0.8800\n",
      "Epoch 1279/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.2895 - accuracy: 0.9187 - val_loss: 0.3746 - val_accuracy: 0.8800\n",
      "Epoch 1280/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.2882 - accuracy: 0.9175 - val_loss: 0.3739 - val_accuracy: 0.8800\n",
      "Epoch 1281/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.2889 - accuracy: 0.9187 - val_loss: 0.3745 - val_accuracy: 0.8750\n",
      "Epoch 1282/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.2884 - accuracy: 0.9162 - val_loss: 0.3730 - val_accuracy: 0.8800\n",
      "Epoch 1283/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2888 - accuracy: 0.9200 - val_loss: 0.3730 - val_accuracy: 0.8800\n",
      "Epoch 1284/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2875 - accuracy: 0.9187 - val_loss: 0.3732 - val_accuracy: 0.8800\n",
      "Epoch 1285/3000\n",
      "800/800 [==============================] - 0s 125us/step - loss: 0.2882 - accuracy: 0.9187 - val_loss: 0.3737 - val_accuracy: 0.8800\n",
      "Epoch 1286/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2873 - accuracy: 0.9162 - val_loss: 0.3718 - val_accuracy: 0.8800\n",
      "Epoch 1287/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2873 - accuracy: 0.9187 - val_loss: 0.3723 - val_accuracy: 0.8800\n",
      "Epoch 1288/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.2875 - accuracy: 0.9187 - val_loss: 0.3718 - val_accuracy: 0.8800\n",
      "Epoch 1289/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.2871 - accuracy: 0.9175 - val_loss: 0.3727 - val_accuracy: 0.8800\n",
      "Epoch 1290/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.2867 - accuracy: 0.9175 - val_loss: 0.3729 - val_accuracy: 0.8800\n",
      "Epoch 1291/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2874 - accuracy: 0.9150 - val_loss: 0.3717 - val_accuracy: 0.8750\n",
      "Epoch 1292/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.2865 - accuracy: 0.9212 - val_loss: 0.3712 - val_accuracy: 0.8800\n",
      "Epoch 1293/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.2859 - accuracy: 0.9175 - val_loss: 0.3715 - val_accuracy: 0.8800\n",
      "Epoch 1294/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2858 - accuracy: 0.9175 - val_loss: 0.3737 - val_accuracy: 0.8800\n",
      "Epoch 1295/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2861 - accuracy: 0.9175 - val_loss: 0.3728 - val_accuracy: 0.8800\n",
      "Epoch 1296/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2955 - accuracy: 0.93 - 0s 93us/step - loss: 0.2858 - accuracy: 0.9162 - val_loss: 0.3696 - val_accuracy: 0.8750\n",
      "Epoch 1297/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2888 - accuracy: 0.91 - 0s 103us/step - loss: 0.2854 - accuracy: 0.9175 - val_loss: 0.3715 - val_accuracy: 0.8800\n",
      "Epoch 1298/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2852 - accuracy: 0.9187 - val_loss: 0.3704 - val_accuracy: 0.8800\n",
      "Epoch 1299/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.2851 - accuracy: 0.9212 - val_loss: 0.3727 - val_accuracy: 0.8800\n",
      "Epoch 1300/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2845 - accuracy: 0.9200 - val_loss: 0.3718 - val_accuracy: 0.8750\n",
      "Epoch 1301/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2846 - accuracy: 0.9125 - val_loss: 0.3689 - val_accuracy: 0.8750\n",
      "Epoch 1302/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2853 - accuracy: 0.9187 - val_loss: 0.3705 - val_accuracy: 0.8750\n",
      "Epoch 1303/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.2845 - accuracy: 0.9200 - val_loss: 0.3714 - val_accuracy: 0.8750\n",
      "Epoch 1304/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2891 - accuracy: 0.91 - 0s 113us/step - loss: 0.2840 - accuracy: 0.9187 - val_loss: 0.3692 - val_accuracy: 0.8750\n",
      "Epoch 1305/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.2841 - accuracy: 0.9175 - val_loss: 0.3689 - val_accuracy: 0.8750\n",
      "Epoch 1306/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2683 - accuracy: 0.92 - 0s 84us/step - loss: 0.2845 - accuracy: 0.9212 - val_loss: 0.3687 - val_accuracy: 0.8750\n",
      "Epoch 1307/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.2843 - accuracy: 0.9212 - val_loss: 0.3684 - val_accuracy: 0.8750\n",
      "Epoch 1308/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2835 - accuracy: 0.9187 - val_loss: 0.3696 - val_accuracy: 0.8750\n",
      "Epoch 1309/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2839 - accuracy: 0.9200 - val_loss: 0.3687 - val_accuracy: 0.8800\n",
      "Epoch 1310/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3007 - accuracy: 0.89 - 0s 78us/step - loss: 0.2839 - accuracy: 0.9175 - val_loss: 0.3683 - val_accuracy: 0.8800\n",
      "Epoch 1311/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2815 - accuracy: 0.91 - 0s 108us/step - loss: 0.2832 - accuracy: 0.9187 - val_loss: 0.3690 - val_accuracy: 0.8800\n",
      "Epoch 1312/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.2825 - accuracy: 0.9200 - val_loss: 0.3682 - val_accuracy: 0.8800\n",
      "Epoch 1313/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.2832 - accuracy: 0.9187 - val_loss: 0.3702 - val_accuracy: 0.8800\n",
      "Epoch 1314/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2827 - accuracy: 0.9200 - val_loss: 0.3698 - val_accuracy: 0.8800\n",
      "Epoch 1315/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.2822 - accuracy: 0.9200 - val_loss: 0.3692 - val_accuracy: 0.8800\n",
      "Epoch 1316/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.2824 - accuracy: 0.9162 - val_loss: 0.3663 - val_accuracy: 0.8750\n",
      "Epoch 1317/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.2820 - accuracy: 0.9225 - val_loss: 0.3665 - val_accuracy: 0.8750\n",
      "Epoch 1318/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.2816 - accuracy: 0.9225 - val_loss: 0.3669 - val_accuracy: 0.8800\n",
      "Epoch 1319/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2815 - accuracy: 0.9187 - val_loss: 0.3660 - val_accuracy: 0.8750\n",
      "Epoch 1320/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2821 - accuracy: 0.9200 - val_loss: 0.3670 - val_accuracy: 0.8800\n",
      "Epoch 1321/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.2815 - accuracy: 0.9200 - val_loss: 0.3662 - val_accuracy: 0.8800\n",
      "Epoch 1322/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.2819 - accuracy: 0.9200 - val_loss: 0.3669 - val_accuracy: 0.8800\n",
      "Epoch 1323/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2807 - accuracy: 0.9187 - val_loss: 0.3677 - val_accuracy: 0.8750\n",
      "Epoch 1324/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.2815 - accuracy: 0.9175 - val_loss: 0.3658 - val_accuracy: 0.8800\n",
      "Epoch 1325/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2812 - accuracy: 0.9200 - val_loss: 0.3662 - val_accuracy: 0.8800\n",
      "Epoch 1326/3000\n",
      "800/800 [==============================] - 0s 160us/step - loss: 0.2808 - accuracy: 0.9237 - val_loss: 0.3653 - val_accuracy: 0.8750\n",
      "Epoch 1327/3000\n",
      "800/800 [==============================] - 0s 134us/step - loss: 0.2809 - accuracy: 0.9175 - val_loss: 0.3654 - val_accuracy: 0.8800\n",
      "Epoch 1328/3000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 0.2802 - accuracy: 0.9200 - val_loss: 0.3653 - val_accuracy: 0.8750\n",
      "Epoch 1329/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.2798 - accuracy: 0.9225 - val_loss: 0.3662 - val_accuracy: 0.8750\n",
      "Epoch 1330/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2801 - accuracy: 0.9212 - val_loss: 0.3670 - val_accuracy: 0.8800\n",
      "Epoch 1331/3000\n",
      "800/800 [==============================] - 0s 240us/step - loss: 0.2803 - accuracy: 0.9187 - val_loss: 0.3654 - val_accuracy: 0.8750\n",
      "Epoch 1332/3000\n",
      "800/800 [==============================] - 0s 184us/step - loss: 0.2793 - accuracy: 0.9225 - val_loss: 0.3638 - val_accuracy: 0.8750\n",
      "Epoch 1333/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2804 - accuracy: 0.91 - 0s 179us/step - loss: 0.2793 - accuracy: 0.9187 - val_loss: 0.3658 - val_accuracy: 0.8800\n",
      "Epoch 1334/3000\n",
      "800/800 [==============================] - 0s 164us/step - loss: 0.2791 - accuracy: 0.9212 - val_loss: 0.3646 - val_accuracy: 0.8800\n",
      "Epoch 1335/3000\n",
      "800/800 [==============================] - 0s 145us/step - loss: 0.2794 - accuracy: 0.9212 - val_loss: 0.3641 - val_accuracy: 0.8800\n",
      "Epoch 1336/3000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.2786 - accuracy: 0.9225 - val_loss: 0.3659 - val_accuracy: 0.8750\n",
      "Epoch 1337/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2427 - accuracy: 0.89 - 0s 121us/step - loss: 0.2789 - accuracy: 0.9200 - val_loss: 0.3651 - val_accuracy: 0.8800\n",
      "Epoch 1338/3000\n",
      "800/800 [==============================] - 0s 156us/step - loss: 0.2787 - accuracy: 0.9237 - val_loss: 0.3645 - val_accuracy: 0.8800\n",
      "Epoch 1339/3000\n",
      "800/800 [==============================] - 0s 174us/step - loss: 0.2782 - accuracy: 0.9200 - val_loss: 0.3643 - val_accuracy: 0.8750\n",
      "Epoch 1340/3000\n",
      "800/800 [==============================] - 0s 174us/step - loss: 0.2788 - accuracy: 0.9212 - val_loss: 0.3640 - val_accuracy: 0.8800\n",
      "Epoch 1341/3000\n",
      "800/800 [==============================] - 0s 129us/step - loss: 0.2776 - accuracy: 0.9250 - val_loss: 0.3639 - val_accuracy: 0.8800\n",
      "Epoch 1342/3000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.2773 - accuracy: 0.9225 - val_loss: 0.3623 - val_accuracy: 0.8800\n",
      "Epoch 1343/3000\n",
      "800/800 [==============================] - 0s 221us/step - loss: 0.2786 - accuracy: 0.9187 - val_loss: 0.3650 - val_accuracy: 0.8800\n",
      "Epoch 1344/3000\n",
      "800/800 [==============================] - 0s 130us/step - loss: 0.2773 - accuracy: 0.9225 - val_loss: 0.3642 - val_accuracy: 0.8750\n",
      "Epoch 1345/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2778 - accuracy: 0.9225 - val_loss: 0.3642 - val_accuracy: 0.8750\n",
      "Epoch 1346/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.2778 - accuracy: 0.9200 - val_loss: 0.3648 - val_accuracy: 0.8800\n",
      "Epoch 1347/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2757 - accuracy: 0.91 - 0s 103us/step - loss: 0.2763 - accuracy: 0.9187 - val_loss: 0.3628 - val_accuracy: 0.8800\n",
      "Epoch 1348/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2769 - accuracy: 0.9237 - val_loss: 0.3642 - val_accuracy: 0.8750\n",
      "Epoch 1349/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2761 - accuracy: 0.9200 - val_loss: 0.3632 - val_accuracy: 0.8800\n",
      "Epoch 1350/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2772 - accuracy: 0.9212 - val_loss: 0.3615 - val_accuracy: 0.8750\n",
      "Epoch 1351/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2763 - accuracy: 0.9225 - val_loss: 0.3606 - val_accuracy: 0.8750\n",
      "Epoch 1352/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2775 - accuracy: 0.91 - 0s 105us/step - loss: 0.2765 - accuracy: 0.9200 - val_loss: 0.3625 - val_accuracy: 0.8800\n",
      "Epoch 1353/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2048 - accuracy: 0.96 - 0s 88us/step - loss: 0.2757 - accuracy: 0.9250 - val_loss: 0.3619 - val_accuracy: 0.8800\n",
      "Epoch 1354/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2760 - accuracy: 0.9225 - val_loss: 0.3619 - val_accuracy: 0.8800\n",
      "Epoch 1355/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2755 - accuracy: 0.9237 - val_loss: 0.3623 - val_accuracy: 0.8800\n",
      "Epoch 1356/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2758 - accuracy: 0.9225 - val_loss: 0.3627 - val_accuracy: 0.8800\n",
      "Epoch 1357/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.2755 - accuracy: 0.9175 - val_loss: 0.3628 - val_accuracy: 0.8800\n",
      "Epoch 1358/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.2759 - accuracy: 0.9212 - val_loss: 0.3617 - val_accuracy: 0.8800\n",
      "Epoch 1359/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2748 - accuracy: 0.9212 - val_loss: 0.3622 - val_accuracy: 0.8800\n",
      "Epoch 1360/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2748 - accuracy: 0.9250 - val_loss: 0.3610 - val_accuracy: 0.8750\n",
      "Epoch 1361/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.2745 - accuracy: 0.9262 - val_loss: 0.3634 - val_accuracy: 0.8750\n",
      "Epoch 1362/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2742 - accuracy: 0.9175 - val_loss: 0.3617 - val_accuracy: 0.8800\n",
      "Epoch 1363/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.2741 - accuracy: 0.9262 - val_loss: 0.3621 - val_accuracy: 0.8800\n",
      "Epoch 1364/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2740 - accuracy: 0.9237 - val_loss: 0.3599 - val_accuracy: 0.8800\n",
      "Epoch 1365/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.2742 - accuracy: 0.9237 - val_loss: 0.3596 - val_accuracy: 0.8800\n",
      "Epoch 1366/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2741 - accuracy: 0.9212 - val_loss: 0.3605 - val_accuracy: 0.8750\n",
      "Epoch 1367/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2659 - accuracy: 0.92 - 0s 104us/step - loss: 0.2738 - accuracy: 0.9212 - val_loss: 0.3609 - val_accuracy: 0.8750\n",
      "Epoch 1368/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.2738 - accuracy: 0.9150 - val_loss: 0.3604 - val_accuracy: 0.8800\n",
      "Epoch 1369/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2741 - accuracy: 0.9212 - val_loss: 0.3591 - val_accuracy: 0.8800\n",
      "Epoch 1370/3000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 0.2720 - accuracy: 0.9237 - val_loss: 0.3608 - val_accuracy: 0.8750\n",
      "Epoch 1371/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2731 - accuracy: 0.9225 - val_loss: 0.3598 - val_accuracy: 0.8800\n",
      "Epoch 1372/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.2733 - accuracy: 0.9237 - val_loss: 0.3600 - val_accuracy: 0.8750\n",
      "Epoch 1373/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2724 - accuracy: 0.9225 - val_loss: 0.3605 - val_accuracy: 0.8800\n",
      "Epoch 1374/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2723 - accuracy: 0.9225 - val_loss: 0.3602 - val_accuracy: 0.8800\n",
      "Epoch 1375/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2721 - accuracy: 0.9262 - val_loss: 0.3608 - val_accuracy: 0.8800\n",
      "Epoch 1376/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2724 - accuracy: 0.9225 - val_loss: 0.3602 - val_accuracy: 0.8750\n",
      "Epoch 1377/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.2725 - accuracy: 0.9262 - val_loss: 0.3583 - val_accuracy: 0.8750\n",
      "Epoch 1378/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2720 - accuracy: 0.9225 - val_loss: 0.3586 - val_accuracy: 0.8750\n",
      "Epoch 1379/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.2712 - accuracy: 0.9212 - val_loss: 0.3574 - val_accuracy: 0.8750\n",
      "Epoch 1380/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.2721 - accuracy: 0.9250 - val_loss: 0.3571 - val_accuracy: 0.8750\n",
      "Epoch 1381/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2711 - accuracy: 0.9237 - val_loss: 0.3584 - val_accuracy: 0.8750\n",
      "Epoch 1382/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.2715 - accuracy: 0.9225 - val_loss: 0.3573 - val_accuracy: 0.8750\n",
      "Epoch 1383/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.2715 - accuracy: 0.9212 - val_loss: 0.3574 - val_accuracy: 0.8750\n",
      "Epoch 1384/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.2712 - accuracy: 0.9200 - val_loss: 0.3595 - val_accuracy: 0.8800\n",
      "Epoch 1385/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.2715 - accuracy: 0.9237 - val_loss: 0.3583 - val_accuracy: 0.8750\n",
      "Epoch 1386/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.2703 - accuracy: 0.9225 - val_loss: 0.3574 - val_accuracy: 0.8800\n",
      "Epoch 1387/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.2704 - accuracy: 0.9237 - val_loss: 0.3567 - val_accuracy: 0.8800\n",
      "Epoch 1388/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.2707 - accuracy: 0.9225 - val_loss: 0.3570 - val_accuracy: 0.8800\n",
      "Epoch 1389/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.2694 - accuracy: 0.9250 - val_loss: 0.3585 - val_accuracy: 0.8800\n",
      "Epoch 1390/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2712 - accuracy: 0.9250 - val_loss: 0.3571 - val_accuracy: 0.8800\n",
      "Epoch 1391/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2695 - accuracy: 0.9237 - val_loss: 0.3582 - val_accuracy: 0.8800\n",
      "Epoch 1392/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2698 - accuracy: 0.9237 - val_loss: 0.3566 - val_accuracy: 0.8800\n",
      "Epoch 1393/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.2694 - accuracy: 0.9225 - val_loss: 0.3581 - val_accuracy: 0.8800\n",
      "Epoch 1394/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.2693 - accuracy: 0.9225 - val_loss: 0.3568 - val_accuracy: 0.8800\n",
      "Epoch 1395/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2698 - accuracy: 0.9262 - val_loss: 0.3566 - val_accuracy: 0.8800\n",
      "Epoch 1396/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2681 - accuracy: 0.9212 - val_loss: 0.3601 - val_accuracy: 0.8800\n",
      "Epoch 1397/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2694 - accuracy: 0.9212 - val_loss: 0.3577 - val_accuracy: 0.8800\n",
      "Epoch 1398/3000\n",
      "800/800 [==============================] - 0s 131us/step - loss: 0.2686 - accuracy: 0.9225 - val_loss: 0.3555 - val_accuracy: 0.8800\n",
      "Epoch 1399/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.2694 - accuracy: 0.9225 - val_loss: 0.3539 - val_accuracy: 0.8800\n",
      "Epoch 1400/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.2686 - accuracy: 0.9225 - val_loss: 0.3552 - val_accuracy: 0.8750\n",
      "Epoch 1401/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2680 - accuracy: 0.9225 - val_loss: 0.3556 - val_accuracy: 0.8750\n",
      "Epoch 1402/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.2681 - accuracy: 0.9237 - val_loss: 0.3551 - val_accuracy: 0.8750\n",
      "Epoch 1403/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.2680 - accuracy: 0.9212 - val_loss: 0.3549 - val_accuracy: 0.8750\n",
      "Epoch 1404/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2680 - accuracy: 0.9237 - val_loss: 0.3545 - val_accuracy: 0.8750\n",
      "Epoch 1405/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2677 - accuracy: 0.9250 - val_loss: 0.3552 - val_accuracy: 0.8800\n",
      "Epoch 1406/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2675 - accuracy: 0.9237 - val_loss: 0.3545 - val_accuracy: 0.8750\n",
      "Epoch 1407/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2671 - accuracy: 0.9237 - val_loss: 0.3548 - val_accuracy: 0.8800\n",
      "Epoch 1408/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.2675 - accuracy: 0.9212 - val_loss: 0.3546 - val_accuracy: 0.8800\n",
      "Epoch 1409/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2669 - accuracy: 0.9250 - val_loss: 0.3536 - val_accuracy: 0.8800\n",
      "Epoch 1410/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2675 - accuracy: 0.9237 - val_loss: 0.3548 - val_accuracy: 0.8750\n",
      "Epoch 1411/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.2661 - accuracy: 0.9225 - val_loss: 0.3553 - val_accuracy: 0.8800\n",
      "Epoch 1412/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2668 - accuracy: 0.9237 - val_loss: 0.3566 - val_accuracy: 0.8800\n",
      "Epoch 1413/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.2666 - accuracy: 0.9225 - val_loss: 0.3562 - val_accuracy: 0.8750\n",
      "Epoch 1414/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2661 - accuracy: 0.9250 - val_loss: 0.3547 - val_accuracy: 0.8800\n",
      "Epoch 1415/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2661 - accuracy: 0.9237 - val_loss: 0.3534 - val_accuracy: 0.8800\n",
      "Epoch 1416/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.2658 - accuracy: 0.9237 - val_loss: 0.3525 - val_accuracy: 0.8800\n",
      "Epoch 1417/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2659 - accuracy: 0.9225 - val_loss: 0.3533 - val_accuracy: 0.8750\n",
      "Epoch 1418/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.2658 - accuracy: 0.9225 - val_loss: 0.3542 - val_accuracy: 0.8750\n",
      "Epoch 1419/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2647 - accuracy: 0.92 - 0s 109us/step - loss: 0.2651 - accuracy: 0.9275 - val_loss: 0.3554 - val_accuracy: 0.8800\n",
      "Epoch 1420/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3233 - accuracy: 0.89 - 0s 81us/step - loss: 0.2654 - accuracy: 0.9262 - val_loss: 0.3538 - val_accuracy: 0.8750\n",
      "Epoch 1421/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2651 - accuracy: 0.9237 - val_loss: 0.3551 - val_accuracy: 0.8750\n",
      "Epoch 1422/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2653 - accuracy: 0.9212 - val_loss: 0.3539 - val_accuracy: 0.8800\n",
      "Epoch 1423/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.2645 - accuracy: 0.9237 - val_loss: 0.3540 - val_accuracy: 0.8800\n",
      "Epoch 1424/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.2645 - accuracy: 0.9262 - val_loss: 0.3526 - val_accuracy: 0.8800\n",
      "Epoch 1425/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2651 - accuracy: 0.9237 - val_loss: 0.3530 - val_accuracy: 0.8800\n",
      "Epoch 1426/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.2649 - accuracy: 0.9250 - val_loss: 0.3521 - val_accuracy: 0.8800\n",
      "Epoch 1427/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.2647 - accuracy: 0.9212 - val_loss: 0.3516 - val_accuracy: 0.8800\n",
      "Epoch 1428/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.2643 - accuracy: 0.9225 - val_loss: 0.3516 - val_accuracy: 0.8800\n",
      "Epoch 1429/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2640 - accuracy: 0.9237 - val_loss: 0.3529 - val_accuracy: 0.8750\n",
      "Epoch 1430/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2641 - accuracy: 0.9250 - val_loss: 0.3530 - val_accuracy: 0.8800\n",
      "Epoch 1431/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2643 - accuracy: 0.9262 - val_loss: 0.3518 - val_accuracy: 0.8750\n",
      "Epoch 1432/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2631 - accuracy: 0.9237 - val_loss: 0.3504 - val_accuracy: 0.8750\n",
      "Epoch 1433/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2636 - accuracy: 0.9237 - val_loss: 0.3521 - val_accuracy: 0.8800\n",
      "Epoch 1434/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2633 - accuracy: 0.9250 - val_loss: 0.3517 - val_accuracy: 0.8750\n",
      "Epoch 1435/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2631 - accuracy: 0.9212 - val_loss: 0.3518 - val_accuracy: 0.8800\n",
      "Epoch 1436/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2623 - accuracy: 0.9262 - val_loss: 0.3507 - val_accuracy: 0.8750\n",
      "Epoch 1437/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.2630 - accuracy: 0.9250 - val_loss: 0.3518 - val_accuracy: 0.8800\n",
      "Epoch 1438/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.2625 - accuracy: 0.9250 - val_loss: 0.3511 - val_accuracy: 0.8750\n",
      "Epoch 1439/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.2616 - accuracy: 0.9262 - val_loss: 0.3536 - val_accuracy: 0.8800\n",
      "Epoch 1440/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2629 - accuracy: 0.9237 - val_loss: 0.3506 - val_accuracy: 0.8750\n",
      "Epoch 1441/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.2616 - accuracy: 0.9225 - val_loss: 0.3502 - val_accuracy: 0.8700\n",
      "Epoch 1442/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2617 - accuracy: 0.9237 - val_loss: 0.3488 - val_accuracy: 0.8750\n",
      "Epoch 1443/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3178 - accuracy: 0.87 - ETA: 0s - loss: 0.2644 - accuracy: 0.92 - 0s 105us/step - loss: 0.2626 - accuracy: 0.9237 - val_loss: 0.3510 - val_accuracy: 0.8750\n",
      "Epoch 1444/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.2616 - accuracy: 0.9275 - val_loss: 0.3525 - val_accuracy: 0.8750\n",
      "Epoch 1445/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2623 - accuracy: 0.9237 - val_loss: 0.3498 - val_accuracy: 0.8750\n",
      "Epoch 1446/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.2614 - accuracy: 0.9275 - val_loss: 0.3493 - val_accuracy: 0.8750\n",
      "Epoch 1447/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4456 - accuracy: 0.85 - 0s 83us/step - loss: 0.2617 - accuracy: 0.9250 - val_loss: 0.3485 - val_accuracy: 0.8750\n",
      "Epoch 1448/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2612 - accuracy: 0.9225 - val_loss: 0.3489 - val_accuracy: 0.8750\n",
      "Epoch 1449/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2612 - accuracy: 0.9237 - val_loss: 0.3492 - val_accuracy: 0.8800\n",
      "Epoch 1450/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2606 - accuracy: 0.9275 - val_loss: 0.3492 - val_accuracy: 0.8800\n",
      "Epoch 1451/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2874 - accuracy: 0.89 - 0s 93us/step - loss: 0.2611 - accuracy: 0.9250 - val_loss: 0.3482 - val_accuracy: 0.8750\n",
      "Epoch 1452/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.2605 - accuracy: 0.9237 - val_loss: 0.3485 - val_accuracy: 0.8800\n",
      "Epoch 1453/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2606 - accuracy: 0.9237 - val_loss: 0.3493 - val_accuracy: 0.8750\n",
      "Epoch 1454/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.2603 - accuracy: 0.9225 - val_loss: 0.3481 - val_accuracy: 0.8750\n",
      "Epoch 1455/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2600 - accuracy: 0.9212 - val_loss: 0.3483 - val_accuracy: 0.8750\n",
      "Epoch 1456/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.2599 - accuracy: 0.9237 - val_loss: 0.3492 - val_accuracy: 0.8750\n",
      "Epoch 1457/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2596 - accuracy: 0.95 - 0s 84us/step - loss: 0.2603 - accuracy: 0.9275 - val_loss: 0.3495 - val_accuracy: 0.8750\n",
      "Epoch 1458/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2591 - accuracy: 0.9275 - val_loss: 0.3488 - val_accuracy: 0.8750\n",
      "Epoch 1459/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.2596 - accuracy: 0.9287 - val_loss: 0.3475 - val_accuracy: 0.8800\n",
      "Epoch 1460/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2591 - accuracy: 0.9250 - val_loss: 0.3476 - val_accuracy: 0.8800\n",
      "Epoch 1461/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2617 - accuracy: 0.92 - 0s 113us/step - loss: 0.2586 - accuracy: 0.9250 - val_loss: 0.3500 - val_accuracy: 0.8800\n",
      "Epoch 1462/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2591 - accuracy: 0.9225 - val_loss: 0.3477 - val_accuracy: 0.8750\n",
      "Epoch 1463/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.2587 - accuracy: 0.9212 - val_loss: 0.3473 - val_accuracy: 0.8800\n",
      "Epoch 1464/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2579 - accuracy: 0.9262 - val_loss: 0.3457 - val_accuracy: 0.8750\n",
      "Epoch 1465/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2632 - accuracy: 0.92 - 0s 105us/step - loss: 0.2588 - accuracy: 0.9262 - val_loss: 0.3462 - val_accuracy: 0.8750\n",
      "Epoch 1466/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2585 - accuracy: 0.9237 - val_loss: 0.3457 - val_accuracy: 0.8800\n",
      "Epoch 1467/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.2578 - accuracy: 0.9237 - val_loss: 0.3465 - val_accuracy: 0.8800\n",
      "Epoch 1468/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.2586 - accuracy: 0.9250 - val_loss: 0.3462 - val_accuracy: 0.8800\n",
      "Epoch 1469/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.2577 - accuracy: 0.9275 - val_loss: 0.3462 - val_accuracy: 0.8800\n",
      "Epoch 1470/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.2581 - accuracy: 0.9250 - val_loss: 0.3474 - val_accuracy: 0.8750\n",
      "Epoch 1471/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.2575 - accuracy: 0.9287 - val_loss: 0.3454 - val_accuracy: 0.8750\n",
      "Epoch 1472/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2582 - accuracy: 0.9275 - val_loss: 0.3452 - val_accuracy: 0.8750\n",
      "Epoch 1473/3000\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.2575 - accuracy: 0.9275 - val_loss: 0.3459 - val_accuracy: 0.8750\n",
      "Epoch 1474/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.2577 - accuracy: 0.9275 - val_loss: 0.3476 - val_accuracy: 0.8800\n",
      "Epoch 1475/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.2573 - accuracy: 0.9275 - val_loss: 0.3470 - val_accuracy: 0.8800\n",
      "Epoch 1476/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.2568 - accuracy: 0.9275 - val_loss: 0.3459 - val_accuracy: 0.8750\n",
      "Epoch 1477/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.2569 - accuracy: 0.9287 - val_loss: 0.3462 - val_accuracy: 0.8750\n",
      "Epoch 1478/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2566 - accuracy: 0.9275 - val_loss: 0.3438 - val_accuracy: 0.8750\n",
      "Epoch 1479/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.2561 - accuracy: 0.9250 - val_loss: 0.3471 - val_accuracy: 0.8750\n",
      "Epoch 1480/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2561 - accuracy: 0.9262 - val_loss: 0.3444 - val_accuracy: 0.8750\n",
      "Epoch 1481/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2561 - accuracy: 0.9250 - val_loss: 0.3449 - val_accuracy: 0.8750\n",
      "Epoch 1482/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.2571 - accuracy: 0.9262 - val_loss: 0.3436 - val_accuracy: 0.8750\n",
      "Epoch 1483/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.2557 - accuracy: 0.9237 - val_loss: 0.3434 - val_accuracy: 0.8750\n",
      "Epoch 1484/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.2555 - accuracy: 0.9250 - val_loss: 0.3470 - val_accuracy: 0.8750\n",
      "Epoch 1485/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.2556 - accuracy: 0.9287 - val_loss: 0.3446 - val_accuracy: 0.8750\n",
      "Epoch 1486/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.2556 - accuracy: 0.9287 - val_loss: 0.3445 - val_accuracy: 0.8750\n",
      "Epoch 1487/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2563 - accuracy: 0.9250 - val_loss: 0.3454 - val_accuracy: 0.8750\n",
      "Epoch 1488/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2559 - accuracy: 0.9287 - val_loss: 0.3450 - val_accuracy: 0.8750\n",
      "Epoch 1489/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2546 - accuracy: 0.9275 - val_loss: 0.3460 - val_accuracy: 0.8750\n",
      "Epoch 1490/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2556 - accuracy: 0.9275 - val_loss: 0.3436 - val_accuracy: 0.8750\n",
      "Epoch 1491/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2549 - accuracy: 0.9225 - val_loss: 0.3447 - val_accuracy: 0.8800\n",
      "Epoch 1492/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2544 - accuracy: 0.9275 - val_loss: 0.3430 - val_accuracy: 0.8800\n",
      "Epoch 1493/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.2540 - accuracy: 0.9237 - val_loss: 0.3434 - val_accuracy: 0.8850\n",
      "Epoch 1494/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.2554 - accuracy: 0.9262 - val_loss: 0.3432 - val_accuracy: 0.8750\n",
      "Epoch 1495/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.2542 - accuracy: 0.9262 - val_loss: 0.3452 - val_accuracy: 0.8800\n",
      "Epoch 1496/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2545 - accuracy: 0.9237 - val_loss: 0.3427 - val_accuracy: 0.8750\n",
      "Epoch 1497/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2538 - accuracy: 0.9287 - val_loss: 0.3423 - val_accuracy: 0.8800\n",
      "Epoch 1498/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.2539 - accuracy: 0.9250 - val_loss: 0.3417 - val_accuracy: 0.8750\n",
      "Epoch 1499/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.2540 - accuracy: 0.9275 - val_loss: 0.3427 - val_accuracy: 0.8750\n",
      "Epoch 1500/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2476 - accuracy: 0.93 - 0s 108us/step - loss: 0.2535 - accuracy: 0.9275 - val_loss: 0.3444 - val_accuracy: 0.8750\n",
      "Epoch 1501/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2701 - accuracy: 0.91 - 0s 111us/step - loss: 0.2538 - accuracy: 0.9250 - val_loss: 0.3429 - val_accuracy: 0.8750\n",
      "Epoch 1502/3000\n",
      "800/800 [==============================] - 0s 328us/step - loss: 0.2537 - accuracy: 0.9250 - val_loss: 0.3416 - val_accuracy: 0.8850\n",
      "Epoch 1503/3000\n",
      "800/800 [==============================] - 0s 221us/step - loss: 0.2536 - accuracy: 0.9250 - val_loss: 0.3431 - val_accuracy: 0.8750\n",
      "Epoch 1504/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.2519 - accuracy: 0.9287 - val_loss: 0.3457 - val_accuracy: 0.8750\n",
      "Epoch 1505/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2603 - accuracy: 0.92 - 0s 228us/step - loss: 0.2523 - accuracy: 0.9275 - val_loss: 0.3421 - val_accuracy: 0.8800\n",
      "Epoch 1506/3000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 0.2534 - accuracy: 0.9262 - val_loss: 0.3420 - val_accuracy: 0.8750\n",
      "Epoch 1507/3000\n",
      "800/800 [==============================] - 0s 215us/step - loss: 0.2527 - accuracy: 0.9275 - val_loss: 0.3413 - val_accuracy: 0.8750\n",
      "Epoch 1508/3000\n",
      "800/800 [==============================] - 0s 295us/step - loss: 0.2525 - accuracy: 0.9275 - val_loss: 0.3413 - val_accuracy: 0.8750\n",
      "Epoch 1509/3000\n",
      "800/800 [==============================] - 0s 273us/step - loss: 0.2520 - accuracy: 0.9262 - val_loss: 0.3428 - val_accuracy: 0.8750\n",
      "Epoch 1510/3000\n",
      "800/800 [==============================] - 0s 163us/step - loss: 0.2526 - accuracy: 0.9262 - val_loss: 0.3417 - val_accuracy: 0.8800\n",
      "Epoch 1511/3000\n",
      "800/800 [==============================] - 0s 168us/step - loss: 0.2515 - accuracy: 0.9262 - val_loss: 0.3433 - val_accuracy: 0.8800\n",
      "Epoch 1512/3000\n",
      "800/800 [==============================] - 0s 301us/step - loss: 0.2521 - accuracy: 0.9275 - val_loss: 0.3419 - val_accuracy: 0.8800\n",
      "Epoch 1513/3000\n",
      "800/800 [==============================] - 0s 263us/step - loss: 0.2519 - accuracy: 0.9300 - val_loss: 0.3408 - val_accuracy: 0.8850\n",
      "Epoch 1514/3000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.2517 - accuracy: 0.9250 - val_loss: 0.3414 - val_accuracy: 0.8750\n",
      "Epoch 1515/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2520 - accuracy: 0.9262 - val_loss: 0.3430 - val_accuracy: 0.8750\n",
      "Epoch 1516/3000\n",
      "800/800 [==============================] - 0s 131us/step - loss: 0.2525 - accuracy: 0.9275 - val_loss: 0.3414 - val_accuracy: 0.8750\n",
      "Epoch 1517/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.2522 - accuracy: 0.9250 - val_loss: 0.3405 - val_accuracy: 0.8800\n",
      "Epoch 1518/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2517 - accuracy: 0.9287 - val_loss: 0.3401 - val_accuracy: 0.8750\n",
      "Epoch 1519/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.2512 - accuracy: 0.9287 - val_loss: 0.3403 - val_accuracy: 0.8750\n",
      "Epoch 1520/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.2509 - accuracy: 0.9287 - val_loss: 0.3408 - val_accuracy: 0.8750\n",
      "Epoch 1521/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2500 - accuracy: 0.9250 - val_loss: 0.3413 - val_accuracy: 0.8700\n",
      "Epoch 1522/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2515 - accuracy: 0.9275 - val_loss: 0.3390 - val_accuracy: 0.8750\n",
      "Epoch 1523/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2329 - accuracy: 0.93 - 0s 85us/step - loss: 0.2515 - accuracy: 0.9262 - val_loss: 0.3394 - val_accuracy: 0.8750\n",
      "Epoch 1524/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2640 - accuracy: 0.92 - 0s 106us/step - loss: 0.2499 - accuracy: 0.9262 - val_loss: 0.3392 - val_accuracy: 0.8800\n",
      "Epoch 1525/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2504 - accuracy: 0.9287 - val_loss: 0.3405 - val_accuracy: 0.8750\n",
      "Epoch 1526/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2507 - accuracy: 0.9262 - val_loss: 0.3409 - val_accuracy: 0.8750\n",
      "Epoch 1527/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2428 - accuracy: 0.93 - 0s 119us/step - loss: 0.2501 - accuracy: 0.9300 - val_loss: 0.3411 - val_accuracy: 0.8800\n",
      "Epoch 1528/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.2495 - accuracy: 0.9312 - val_loss: 0.3396 - val_accuracy: 0.8750\n",
      "Epoch 1529/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.2495 - accuracy: 0.9225 - val_loss: 0.3408 - val_accuracy: 0.8800\n",
      "Epoch 1530/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.2494 - accuracy: 0.9300 - val_loss: 0.3417 - val_accuracy: 0.8800\n",
      "Epoch 1531/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2492 - accuracy: 0.9300 - val_loss: 0.3416 - val_accuracy: 0.8800\n",
      "Epoch 1532/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2496 - accuracy: 0.9287 - val_loss: 0.3409 - val_accuracy: 0.8750\n",
      "Epoch 1533/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2497 - accuracy: 0.9237 - val_loss: 0.3387 - val_accuracy: 0.8800\n",
      "Epoch 1534/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2486 - accuracy: 0.9300 - val_loss: 0.3378 - val_accuracy: 0.8800\n",
      "Epoch 1535/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2372 - accuracy: 0.93 - 0s 104us/step - loss: 0.2494 - accuracy: 0.9300 - val_loss: 0.3382 - val_accuracy: 0.8750\n",
      "Epoch 1536/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.2484 - accuracy: 0.9262 - val_loss: 0.3398 - val_accuracy: 0.8800\n",
      "Epoch 1537/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2490 - accuracy: 0.9275 - val_loss: 0.3386 - val_accuracy: 0.8750\n",
      "Epoch 1538/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.2488 - accuracy: 0.9312 - val_loss: 0.3394 - val_accuracy: 0.8750\n",
      "Epoch 1539/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2485 - accuracy: 0.9275 - val_loss: 0.3390 - val_accuracy: 0.8850\n",
      "Epoch 1540/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2480 - accuracy: 0.9262 - val_loss: 0.3386 - val_accuracy: 0.8750\n",
      "Epoch 1541/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2496 - accuracy: 0.9287 - val_loss: 0.3367 - val_accuracy: 0.8750\n",
      "Epoch 1542/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2481 - accuracy: 0.9287 - val_loss: 0.3366 - val_accuracy: 0.8800\n",
      "Epoch 1543/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2481 - accuracy: 0.9300 - val_loss: 0.3364 - val_accuracy: 0.8800\n",
      "Epoch 1544/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2482 - accuracy: 0.9300 - val_loss: 0.3377 - val_accuracy: 0.8750\n",
      "Epoch 1545/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.2479 - accuracy: 0.9300 - val_loss: 0.3370 - val_accuracy: 0.8800\n",
      "Epoch 1546/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2467 - accuracy: 0.9325 - val_loss: 0.3375 - val_accuracy: 0.8850\n",
      "Epoch 1547/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2484 - accuracy: 0.9262 - val_loss: 0.3370 - val_accuracy: 0.8800\n",
      "Epoch 1548/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2476 - accuracy: 0.9312 - val_loss: 0.3380 - val_accuracy: 0.8800\n",
      "Epoch 1549/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2472 - accuracy: 0.9275 - val_loss: 0.3389 - val_accuracy: 0.8800\n",
      "Epoch 1550/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2473 - accuracy: 0.9275 - val_loss: 0.3378 - val_accuracy: 0.8800\n",
      "Epoch 1551/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2462 - accuracy: 0.9225 - val_loss: 0.3363 - val_accuracy: 0.8800\n",
      "Epoch 1552/3000\n",
      "800/800 [==============================] - 0s 124us/step - loss: 0.2474 - accuracy: 0.9275 - val_loss: 0.3371 - val_accuracy: 0.8800\n",
      "Epoch 1553/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2469 - accuracy: 0.9275 - val_loss: 0.3366 - val_accuracy: 0.8800\n",
      "Epoch 1554/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2750 - accuracy: 0.92 - 0s 86us/step - loss: 0.2459 - accuracy: 0.9287 - val_loss: 0.3377 - val_accuracy: 0.8850\n",
      "Epoch 1555/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.2460 - accuracy: 0.9312 - val_loss: 0.3342 - val_accuracy: 0.8800\n",
      "Epoch 1556/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2461 - accuracy: 0.9287 - val_loss: 0.3359 - val_accuracy: 0.8800\n",
      "Epoch 1557/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2459 - accuracy: 0.9275 - val_loss: 0.3361 - val_accuracy: 0.8800\n",
      "Epoch 1558/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2394 - accuracy: 0.93 - 0s 106us/step - loss: 0.2467 - accuracy: 0.9300 - val_loss: 0.3364 - val_accuracy: 0.8750\n",
      "Epoch 1559/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.2460 - accuracy: 0.9312 - val_loss: 0.3358 - val_accuracy: 0.8800\n",
      "Epoch 1560/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.2460 - accuracy: 0.9287 - val_loss: 0.3364 - val_accuracy: 0.8850\n",
      "Epoch 1561/3000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 0.2453 - accuracy: 0.9325 - val_loss: 0.3359 - val_accuracy: 0.8750\n",
      "Epoch 1562/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.2455 - accuracy: 0.9300 - val_loss: 0.3365 - val_accuracy: 0.8800\n",
      "Epoch 1563/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2458 - accuracy: 0.9275 - val_loss: 0.3354 - val_accuracy: 0.8800\n",
      "Epoch 1564/3000\n",
      "800/800 [==============================] - 0s 146us/step - loss: 0.2454 - accuracy: 0.9287 - val_loss: 0.3346 - val_accuracy: 0.8800\n",
      "Epoch 1565/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2454 - accuracy: 0.9325 - val_loss: 0.3348 - val_accuracy: 0.8800\n",
      "Epoch 1566/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.2441 - accuracy: 0.9312 - val_loss: 0.3346 - val_accuracy: 0.8800\n",
      "Epoch 1567/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.2452 - accuracy: 0.9287 - val_loss: 0.3364 - val_accuracy: 0.8800\n",
      "Epoch 1568/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.2449 - accuracy: 0.9287 - val_loss: 0.3352 - val_accuracy: 0.8800\n",
      "Epoch 1569/3000\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.2444 - accuracy: 0.9287 - val_loss: 0.3347 - val_accuracy: 0.8800\n",
      "Epoch 1570/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.2445 - accuracy: 0.9287 - val_loss: 0.3339 - val_accuracy: 0.8800\n",
      "Epoch 1571/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2442 - accuracy: 0.9312 - val_loss: 0.3340 - val_accuracy: 0.8750\n",
      "Epoch 1572/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2446 - accuracy: 0.9287 - val_loss: 0.3347 - val_accuracy: 0.8750\n",
      "Epoch 1573/3000\n",
      "800/800 [==============================] - 0s 136us/step - loss: 0.2437 - accuracy: 0.9287 - val_loss: 0.3326 - val_accuracy: 0.8800\n",
      "Epoch 1574/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2434 - accuracy: 0.9337 - val_loss: 0.3324 - val_accuracy: 0.8850\n",
      "Epoch 1575/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2408 - accuracy: 0.92 - 0s 120us/step - loss: 0.2436 - accuracy: 0.9275 - val_loss: 0.3350 - val_accuracy: 0.8800\n",
      "Epoch 1576/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2435 - accuracy: 0.9300 - val_loss: 0.3340 - val_accuracy: 0.8800\n",
      "Epoch 1577/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2444 - accuracy: 0.9300 - val_loss: 0.3335 - val_accuracy: 0.8800\n",
      "Epoch 1578/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.2437 - accuracy: 0.9287 - val_loss: 0.3332 - val_accuracy: 0.8850\n",
      "Epoch 1579/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2424 - accuracy: 0.9325 - val_loss: 0.3345 - val_accuracy: 0.8800\n",
      "Epoch 1580/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.2433 - accuracy: 0.9300 - val_loss: 0.3347 - val_accuracy: 0.8800\n",
      "Epoch 1581/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2433 - accuracy: 0.9275 - val_loss: 0.3339 - val_accuracy: 0.8850\n",
      "Epoch 1582/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2428 - accuracy: 0.9312 - val_loss: 0.3329 - val_accuracy: 0.8800\n",
      "Epoch 1583/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.2431 - accuracy: 0.9287 - val_loss: 0.3335 - val_accuracy: 0.8800\n",
      "Epoch 1584/3000\n",
      "800/800 [==============================] - 0s 128us/step - loss: 0.2437 - accuracy: 0.9312 - val_loss: 0.3334 - val_accuracy: 0.8800\n",
      "Epoch 1585/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.2425 - accuracy: 0.9300 - val_loss: 0.3335 - val_accuracy: 0.8800\n",
      "Epoch 1586/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.2418 - accuracy: 0.9275 - val_loss: 0.3331 - val_accuracy: 0.8850\n",
      "Epoch 1587/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2430 - accuracy: 0.9262 - val_loss: 0.3328 - val_accuracy: 0.8800\n",
      "Epoch 1588/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2417 - accuracy: 0.9300 - val_loss: 0.3350 - val_accuracy: 0.8850\n",
      "Epoch 1589/3000\n",
      "800/800 [==============================] - 0s 159us/step - loss: 0.2432 - accuracy: 0.9300 - val_loss: 0.3350 - val_accuracy: 0.8800\n",
      "Epoch 1590/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2414 - accuracy: 0.9325 - val_loss: 0.3320 - val_accuracy: 0.8800\n",
      "Epoch 1591/3000\n",
      "800/800 [==============================] - 0s 128us/step - loss: 0.2412 - accuracy: 0.9287 - val_loss: 0.3327 - val_accuracy: 0.8850\n",
      "Epoch 1592/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2415 - accuracy: 0.9300 - val_loss: 0.3335 - val_accuracy: 0.8850\n",
      "Epoch 1593/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2414 - accuracy: 0.9300 - val_loss: 0.3331 - val_accuracy: 0.8850\n",
      "Epoch 1594/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2421 - accuracy: 0.9287 - val_loss: 0.3318 - val_accuracy: 0.8800\n",
      "Epoch 1595/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2409 - accuracy: 0.9287 - val_loss: 0.3310 - val_accuracy: 0.8800\n",
      "Epoch 1596/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2414 - accuracy: 0.9300 - val_loss: 0.3305 - val_accuracy: 0.8800\n",
      "Epoch 1597/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2413 - accuracy: 0.9312 - val_loss: 0.3324 - val_accuracy: 0.8800\n",
      "Epoch 1598/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.2405 - accuracy: 0.9300 - val_loss: 0.3297 - val_accuracy: 0.8800\n",
      "Epoch 1599/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2413 - accuracy: 0.9300 - val_loss: 0.3326 - val_accuracy: 0.8800\n",
      "Epoch 1600/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2403 - accuracy: 0.9337 - val_loss: 0.3307 - val_accuracy: 0.8850\n",
      "Epoch 1601/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1771 - accuracy: 0.95 - ETA: 0s - loss: 0.2326 - accuracy: 0.93 - 0s 109us/step - loss: 0.2403 - accuracy: 0.9300 - val_loss: 0.3305 - val_accuracy: 0.8800\n",
      "Epoch 1602/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.2404 - accuracy: 0.9287 - val_loss: 0.3327 - val_accuracy: 0.8850\n",
      "Epoch 1603/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2403 - accuracy: 0.9350 - val_loss: 0.3332 - val_accuracy: 0.8800\n",
      "Epoch 1604/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2394 - accuracy: 0.9312 - val_loss: 0.3318 - val_accuracy: 0.8800\n",
      "Epoch 1605/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2397 - accuracy: 0.9300 - val_loss: 0.3310 - val_accuracy: 0.8800\n",
      "Epoch 1606/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2027 - accuracy: 0.96 - 0s 75us/step - loss: 0.2402 - accuracy: 0.9300 - val_loss: 0.3322 - val_accuracy: 0.8800\n",
      "Epoch 1607/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.2401 - accuracy: 0.9312 - val_loss: 0.3303 - val_accuracy: 0.8800\n",
      "Epoch 1608/3000\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.2400 - accuracy: 0.9287 - val_loss: 0.3310 - val_accuracy: 0.8800\n",
      "Epoch 1609/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2396 - accuracy: 0.9325 - val_loss: 0.3302 - val_accuracy: 0.8800\n",
      "Epoch 1610/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2395 - accuracy: 0.9275 - val_loss: 0.3294 - val_accuracy: 0.8850\n",
      "Epoch 1611/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2400 - accuracy: 0.9275 - val_loss: 0.3309 - val_accuracy: 0.8800\n",
      "Epoch 1612/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.2400 - accuracy: 0.9325 - val_loss: 0.3292 - val_accuracy: 0.8800\n",
      "Epoch 1613/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.2388 - accuracy: 0.9300 - val_loss: 0.3302 - val_accuracy: 0.8800\n",
      "Epoch 1614/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.2392 - accuracy: 0.9300 - val_loss: 0.3316 - val_accuracy: 0.8800\n",
      "Epoch 1615/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.2387 - accuracy: 0.9300 - val_loss: 0.3278 - val_accuracy: 0.8800\n",
      "Epoch 1616/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.2378 - accuracy: 0.9325 - val_loss: 0.3286 - val_accuracy: 0.8850\n",
      "Epoch 1617/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.2396 - accuracy: 0.9325 - val_loss: 0.3295 - val_accuracy: 0.8800\n",
      "Epoch 1618/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.2375 - accuracy: 0.9300 - val_loss: 0.3302 - val_accuracy: 0.8850\n",
      "Epoch 1619/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2377 - accuracy: 0.9287 - val_loss: 0.3337 - val_accuracy: 0.8850\n",
      "Epoch 1620/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.2387 - accuracy: 0.9325 - val_loss: 0.3319 - val_accuracy: 0.8850\n",
      "Epoch 1621/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2381 - accuracy: 0.93 - 0s 101us/step - loss: 0.2386 - accuracy: 0.9312 - val_loss: 0.3281 - val_accuracy: 0.8800\n",
      "Epoch 1622/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2374 - accuracy: 0.93 - 0s 113us/step - loss: 0.2369 - accuracy: 0.9337 - val_loss: 0.3299 - val_accuracy: 0.8850\n",
      "Epoch 1623/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.2381 - accuracy: 0.9312 - val_loss: 0.3290 - val_accuracy: 0.8850\n",
      "Epoch 1624/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2380 - accuracy: 0.9325 - val_loss: 0.3282 - val_accuracy: 0.8800\n",
      "Epoch 1625/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2382 - accuracy: 0.9275 - val_loss: 0.3290 - val_accuracy: 0.8800\n",
      "Epoch 1626/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.2376 - accuracy: 0.9300 - val_loss: 0.3287 - val_accuracy: 0.8800\n",
      "Epoch 1627/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2368 - accuracy: 0.9312 - val_loss: 0.3294 - val_accuracy: 0.8800\n",
      "Epoch 1628/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2367 - accuracy: 0.9325 - val_loss: 0.3265 - val_accuracy: 0.8850\n",
      "Epoch 1629/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2381 - accuracy: 0.9325 - val_loss: 0.3276 - val_accuracy: 0.8800\n",
      "Epoch 1630/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.2373 - accuracy: 0.9300 - val_loss: 0.3274 - val_accuracy: 0.8800\n",
      "Epoch 1631/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2380 - accuracy: 0.93 - 0s 88us/step - loss: 0.2368 - accuracy: 0.9312 - val_loss: 0.3277 - val_accuracy: 0.8800\n",
      "Epoch 1632/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2391 - accuracy: 0.92 - 0s 99us/step - loss: 0.2371 - accuracy: 0.9300 - val_loss: 0.3285 - val_accuracy: 0.8800\n",
      "Epoch 1633/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2366 - accuracy: 0.9300 - val_loss: 0.3285 - val_accuracy: 0.8850\n",
      "Epoch 1634/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2367 - accuracy: 0.9325 - val_loss: 0.3281 - val_accuracy: 0.8900\n",
      "Epoch 1635/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2361 - accuracy: 0.9300 - val_loss: 0.3281 - val_accuracy: 0.8800\n",
      "Epoch 1636/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2425 - accuracy: 0.92 - 0s 88us/step - loss: 0.2363 - accuracy: 0.9312 - val_loss: 0.3275 - val_accuracy: 0.8900\n",
      "Epoch 1637/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2375 - accuracy: 0.93 - 0s 110us/step - loss: 0.2364 - accuracy: 0.9312 - val_loss: 0.3278 - val_accuracy: 0.8800\n",
      "Epoch 1638/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2359 - accuracy: 0.9287 - val_loss: 0.3275 - val_accuracy: 0.8850\n",
      "Epoch 1639/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2363 - accuracy: 0.9287 - val_loss: 0.3287 - val_accuracy: 0.8800\n",
      "Epoch 1640/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2360 - accuracy: 0.9300 - val_loss: 0.3272 - val_accuracy: 0.8800\n",
      "Epoch 1641/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2358 - accuracy: 0.9300 - val_loss: 0.3284 - val_accuracy: 0.8850\n",
      "Epoch 1642/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2406 - accuracy: 0.92 - 0s 100us/step - loss: 0.2359 - accuracy: 0.9300 - val_loss: 0.3283 - val_accuracy: 0.8850\n",
      "Epoch 1643/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2360 - accuracy: 0.9300 - val_loss: 0.3277 - val_accuracy: 0.8800\n",
      "Epoch 1644/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.2357 - accuracy: 0.9337 - val_loss: 0.3261 - val_accuracy: 0.8800\n",
      "Epoch 1645/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.2354 - accuracy: 0.9312 - val_loss: 0.3274 - val_accuracy: 0.8800\n",
      "Epoch 1646/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.2347 - accuracy: 0.9312 - val_loss: 0.3290 - val_accuracy: 0.8850\n",
      "Epoch 1647/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.2353 - accuracy: 0.9325 - val_loss: 0.3259 - val_accuracy: 0.8800\n",
      "Epoch 1648/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2350 - accuracy: 0.9300 - val_loss: 0.3258 - val_accuracy: 0.8850\n",
      "Epoch 1649/3000\n",
      "800/800 [==============================] - 0s 136us/step - loss: 0.2344 - accuracy: 0.9312 - val_loss: 0.3279 - val_accuracy: 0.8800\n",
      "Epoch 1650/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2349 - accuracy: 0.9312 - val_loss: 0.3265 - val_accuracy: 0.8850\n",
      "Epoch 1651/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.2344 - accuracy: 0.9312 - val_loss: 0.3275 - val_accuracy: 0.8800\n",
      "Epoch 1652/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2347 - accuracy: 0.9312 - val_loss: 0.3274 - val_accuracy: 0.8850\n",
      "Epoch 1653/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.2349 - accuracy: 0.9337 - val_loss: 0.3267 - val_accuracy: 0.8850\n",
      "Epoch 1654/3000\n",
      "800/800 [==============================] - 0s 125us/step - loss: 0.2338 - accuracy: 0.9337 - val_loss: 0.3247 - val_accuracy: 0.8850\n",
      "Epoch 1655/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.2343 - accuracy: 0.9300 - val_loss: 0.3256 - val_accuracy: 0.8800\n",
      "Epoch 1656/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2342 - accuracy: 0.9300 - val_loss: 0.3257 - val_accuracy: 0.8850\n",
      "Epoch 1657/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2343 - accuracy: 0.9300 - val_loss: 0.3257 - val_accuracy: 0.8850\n",
      "Epoch 1658/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2333 - accuracy: 0.9287 - val_loss: 0.3282 - val_accuracy: 0.8850\n",
      "Epoch 1659/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.2337 - accuracy: 0.9312 - val_loss: 0.3282 - val_accuracy: 0.8900\n",
      "Epoch 1660/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2392 - accuracy: 0.92 - 0s 111us/step - loss: 0.2337 - accuracy: 0.9312 - val_loss: 0.3253 - val_accuracy: 0.8850\n",
      "Epoch 1661/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2400 - accuracy: 0.92 - 0s 118us/step - loss: 0.2336 - accuracy: 0.9312 - val_loss: 0.3255 - val_accuracy: 0.8850\n",
      "Epoch 1662/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2380 - accuracy: 0.95 - 0s 95us/step - loss: 0.2337 - accuracy: 0.9300 - val_loss: 0.3256 - val_accuracy: 0.8850\n",
      "Epoch 1663/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.2341 - accuracy: 0.9300 - val_loss: 0.3245 - val_accuracy: 0.8900\n",
      "Epoch 1664/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2370 - accuracy: 0.92 - 0s 91us/step - loss: 0.2331 - accuracy: 0.9312 - val_loss: 0.3246 - val_accuracy: 0.8850\n",
      "Epoch 1665/3000\n",
      "800/800 [==============================] - 0s 154us/step - loss: 0.2322 - accuracy: 0.9312 - val_loss: 0.3235 - val_accuracy: 0.8900\n",
      "Epoch 1666/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2333 - accuracy: 0.9312 - val_loss: 0.3262 - val_accuracy: 0.8850\n",
      "Epoch 1667/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.2332 - accuracy: 0.9337 - val_loss: 0.3254 - val_accuracy: 0.8850\n",
      "Epoch 1668/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2311 - accuracy: 0.92 - 0s 103us/step - loss: 0.2322 - accuracy: 0.9287 - val_loss: 0.3264 - val_accuracy: 0.8850\n",
      "Epoch 1669/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2325 - accuracy: 0.9312 - val_loss: 0.3247 - val_accuracy: 0.8800\n",
      "Epoch 1670/3000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.2324 - accuracy: 0.9350 - val_loss: 0.3232 - val_accuracy: 0.8850\n",
      "Epoch 1671/3000\n",
      "800/800 [==============================] - 0s 368us/step - loss: 0.2323 - accuracy: 0.9300 - val_loss: 0.3248 - val_accuracy: 0.8850\n",
      "Epoch 1672/3000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.2319 - accuracy: 0.9337 - val_loss: 0.3229 - val_accuracy: 0.8850\n",
      "Epoch 1673/3000\n",
      "800/800 [==============================] - 0s 264us/step - loss: 0.2321 - accuracy: 0.9300 - val_loss: 0.3257 - val_accuracy: 0.8850\n",
      "Epoch 1674/3000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 0.2323 - accuracy: 0.9312 - val_loss: 0.3265 - val_accuracy: 0.8850\n",
      "Epoch 1675/3000\n",
      "800/800 [==============================] - 0s 394us/step - loss: 0.2320 - accuracy: 0.9325 - val_loss: 0.3257 - val_accuracy: 0.8800\n",
      "Epoch 1676/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2259 - accuracy: 0.93 - 0s 100us/step - loss: 0.2316 - accuracy: 0.9325 - val_loss: 0.3234 - val_accuracy: 0.8800\n",
      "Epoch 1677/3000\n",
      "800/800 [==============================] - 0s 231us/step - loss: 0.2314 - accuracy: 0.9350 - val_loss: 0.3232 - val_accuracy: 0.8800\n",
      "Epoch 1678/3000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 0.2314 - accuracy: 0.9337 - val_loss: 0.3224 - val_accuracy: 0.8850\n",
      "Epoch 1679/3000\n",
      "800/800 [==============================] - 0s 215us/step - loss: 0.2309 - accuracy: 0.9350 - val_loss: 0.3227 - val_accuracy: 0.8800\n",
      "Epoch 1680/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2473 - accuracy: 0.92 - 0s 246us/step - loss: 0.2320 - accuracy: 0.9312 - val_loss: 0.3237 - val_accuracy: 0.8800\n",
      "Epoch 1681/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2314 - accuracy: 0.9337 - val_loss: 0.3230 - val_accuracy: 0.8800\n",
      "Epoch 1682/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.2314 - accuracy: 0.9312 - val_loss: 0.3228 - val_accuracy: 0.8850\n",
      "Epoch 1683/3000\n",
      "800/800 [==============================] - 0s 149us/step - loss: 0.2302 - accuracy: 0.9337 - val_loss: 0.3234 - val_accuracy: 0.8900\n",
      "Epoch 1684/3000\n",
      "800/800 [==============================] - 0s 130us/step - loss: 0.2315 - accuracy: 0.9337 - val_loss: 0.3229 - val_accuracy: 0.8900\n",
      "Epoch 1685/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.2305 - accuracy: 0.9312 - val_loss: 0.3237 - val_accuracy: 0.8900\n",
      "Epoch 1686/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2314 - accuracy: 0.9312 - val_loss: 0.3231 - val_accuracy: 0.8850\n",
      "Epoch 1687/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2303 - accuracy: 0.9350 - val_loss: 0.3226 - val_accuracy: 0.8850\n",
      "Epoch 1688/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.2299 - accuracy: 0.9337 - val_loss: 0.3245 - val_accuracy: 0.8850\n",
      "Epoch 1689/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2295 - accuracy: 0.9350 - val_loss: 0.3239 - val_accuracy: 0.8900\n",
      "Epoch 1690/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3285 - accuracy: 0.92 - 0s 90us/step - loss: 0.2308 - accuracy: 0.9325 - val_loss: 0.3221 - val_accuracy: 0.8850\n",
      "Epoch 1691/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2303 - accuracy: 0.9312 - val_loss: 0.3223 - val_accuracy: 0.8900\n",
      "Epoch 1692/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.2292 - accuracy: 0.9337 - val_loss: 0.3215 - val_accuracy: 0.8850\n",
      "Epoch 1693/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2343 - accuracy: 0.93 - 0s 104us/step - loss: 0.2297 - accuracy: 0.9350 - val_loss: 0.3228 - val_accuracy: 0.8750\n",
      "Epoch 1694/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.2302 - accuracy: 0.9312 - val_loss: 0.3222 - val_accuracy: 0.8850\n",
      "Epoch 1695/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2293 - accuracy: 0.9300 - val_loss: 0.3214 - val_accuracy: 0.8900\n",
      "Epoch 1696/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2316 - accuracy: 0.93 - 0s 106us/step - loss: 0.2298 - accuracy: 0.9325 - val_loss: 0.3215 - val_accuracy: 0.8900\n",
      "Epoch 1697/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2291 - accuracy: 0.9337 - val_loss: 0.3220 - val_accuracy: 0.8850\n",
      "Epoch 1698/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2300 - accuracy: 0.9312 - val_loss: 0.3226 - val_accuracy: 0.8850\n",
      "Epoch 1699/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.2291 - accuracy: 0.9325 - val_loss: 0.3219 - val_accuracy: 0.8850\n",
      "Epoch 1700/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.2287 - accuracy: 0.9325 - val_loss: 0.3224 - val_accuracy: 0.8850\n",
      "Epoch 1701/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2292 - accuracy: 0.9312 - val_loss: 0.3224 - val_accuracy: 0.8850\n",
      "Epoch 1702/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2294 - accuracy: 0.9325 - val_loss: 0.3216 - val_accuracy: 0.8850\n",
      "Epoch 1703/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2279 - accuracy: 0.9312 - val_loss: 0.3234 - val_accuracy: 0.8900\n",
      "Epoch 1704/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.2293 - accuracy: 0.9337 - val_loss: 0.3217 - val_accuracy: 0.8850\n",
      "Epoch 1705/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.2284 - accuracy: 0.9300 - val_loss: 0.3208 - val_accuracy: 0.8800\n",
      "Epoch 1706/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2138 - accuracy: 0.94 - 0s 121us/step - loss: 0.2285 - accuracy: 0.9350 - val_loss: 0.3198 - val_accuracy: 0.8850\n",
      "Epoch 1707/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.2284 - accuracy: 0.9325 - val_loss: 0.3208 - val_accuracy: 0.8800\n",
      "Epoch 1708/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.2289 - accuracy: 0.9312 - val_loss: 0.3208 - val_accuracy: 0.8850\n",
      "Epoch 1709/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2265 - accuracy: 0.93 - 0s 100us/step - loss: 0.2281 - accuracy: 0.9325 - val_loss: 0.3196 - val_accuracy: 0.8850\n",
      "Epoch 1710/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2280 - accuracy: 0.9300 - val_loss: 0.3218 - val_accuracy: 0.8850\n",
      "Epoch 1711/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2269 - accuracy: 0.9325 - val_loss: 0.3199 - val_accuracy: 0.8850\n",
      "Epoch 1712/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.2276 - accuracy: 0.9300 - val_loss: 0.3210 - val_accuracy: 0.8800\n",
      "Epoch 1713/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.2273 - accuracy: 0.9325 - val_loss: 0.3205 - val_accuracy: 0.8900\n",
      "Epoch 1714/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2282 - accuracy: 0.9325 - val_loss: 0.3198 - val_accuracy: 0.8900\n",
      "Epoch 1715/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.2265 - accuracy: 0.9337 - val_loss: 0.3212 - val_accuracy: 0.8800\n",
      "Epoch 1716/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.2276 - accuracy: 0.9325 - val_loss: 0.3221 - val_accuracy: 0.8850\n",
      "Epoch 1717/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.2280 - accuracy: 0.9337 - val_loss: 0.3213 - val_accuracy: 0.8800\n",
      "Epoch 1718/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2260 - accuracy: 0.92 - 0s 108us/step - loss: 0.2265 - accuracy: 0.9312 - val_loss: 0.3210 - val_accuracy: 0.8850\n",
      "Epoch 1719/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.2259 - accuracy: 0.9325 - val_loss: 0.3211 - val_accuracy: 0.8800\n",
      "Epoch 1720/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2269 - accuracy: 0.93 - 0s 109us/step - loss: 0.2270 - accuracy: 0.9337 - val_loss: 0.3205 - val_accuracy: 0.8900\n",
      "Epoch 1721/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.2267 - accuracy: 0.9300 - val_loss: 0.3214 - val_accuracy: 0.8850\n",
      "Epoch 1722/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2272 - accuracy: 0.9312 - val_loss: 0.3211 - val_accuracy: 0.8900\n",
      "Epoch 1723/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2261 - accuracy: 0.9350 - val_loss: 0.3186 - val_accuracy: 0.8800\n",
      "Epoch 1724/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.2270 - accuracy: 0.9325 - val_loss: 0.3201 - val_accuracy: 0.8850\n",
      "Epoch 1725/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.2261 - accuracy: 0.9325 - val_loss: 0.3191 - val_accuracy: 0.8800\n",
      "Epoch 1726/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.2269 - accuracy: 0.9312 - val_loss: 0.3218 - val_accuracy: 0.8900\n",
      "Epoch 1727/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.2256 - accuracy: 0.9362 - val_loss: 0.3193 - val_accuracy: 0.8850\n",
      "Epoch 1728/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2247 - accuracy: 0.93 - 0s 99us/step - loss: 0.2259 - accuracy: 0.9337 - val_loss: 0.3212 - val_accuracy: 0.8800\n",
      "Epoch 1729/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.2265 - accuracy: 0.9325 - val_loss: 0.3198 - val_accuracy: 0.8900\n",
      "Epoch 1730/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2260 - accuracy: 0.9350 - val_loss: 0.3196 - val_accuracy: 0.8900\n",
      "Epoch 1731/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.93 - 0s 104us/step - loss: 0.2253 - accuracy: 0.9362 - val_loss: 0.3185 - val_accuracy: 0.8850\n",
      "Epoch 1732/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2260 - accuracy: 0.9312 - val_loss: 0.3187 - val_accuracy: 0.8850\n",
      "Epoch 1733/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2251 - accuracy: 0.9350 - val_loss: 0.3200 - val_accuracy: 0.8800\n",
      "Epoch 1734/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2252 - accuracy: 0.9325 - val_loss: 0.3177 - val_accuracy: 0.8800\n",
      "Epoch 1735/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2247 - accuracy: 0.9337 - val_loss: 0.3187 - val_accuracy: 0.8800\n",
      "Epoch 1736/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2254 - accuracy: 0.9362 - val_loss: 0.3191 - val_accuracy: 0.8850\n",
      "Epoch 1737/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2251 - accuracy: 0.9325 - val_loss: 0.3174 - val_accuracy: 0.8850\n",
      "Epoch 1738/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.2246 - accuracy: 0.9325 - val_loss: 0.3194 - val_accuracy: 0.8900\n",
      "Epoch 1739/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2214 - accuracy: 0.93 - 0s 115us/step - loss: 0.2242 - accuracy: 0.9362 - val_loss: 0.3161 - val_accuracy: 0.8850\n",
      "Epoch 1740/3000\n",
      "800/800 [==============================] - 0s 130us/step - loss: 0.2244 - accuracy: 0.9337 - val_loss: 0.3191 - val_accuracy: 0.8800\n",
      "Epoch 1741/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2248 - accuracy: 0.9325 - val_loss: 0.3170 - val_accuracy: 0.8900\n",
      "Epoch 1742/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2242 - accuracy: 0.9337 - val_loss: 0.3173 - val_accuracy: 0.8800\n",
      "Epoch 1743/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.2243 - accuracy: 0.9337 - val_loss: 0.3166 - val_accuracy: 0.8900\n",
      "Epoch 1744/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.2243 - accuracy: 0.9300 - val_loss: 0.3163 - val_accuracy: 0.8900\n",
      "Epoch 1745/3000\n",
      "800/800 [==============================] - 0s 131us/step - loss: 0.2235 - accuracy: 0.9337 - val_loss: 0.3178 - val_accuracy: 0.8850\n",
      "Epoch 1746/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.2239 - accuracy: 0.9325 - val_loss: 0.3163 - val_accuracy: 0.8850\n",
      "Epoch 1747/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.2238 - accuracy: 0.9350 - val_loss: 0.3174 - val_accuracy: 0.8850\n",
      "Epoch 1748/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.2248 - accuracy: 0.9300 - val_loss: 0.3169 - val_accuracy: 0.8900\n",
      "Epoch 1749/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.2230 - accuracy: 0.9337 - val_loss: 0.3184 - val_accuracy: 0.8900\n",
      "Epoch 1750/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2237 - accuracy: 0.9362 - val_loss: 0.3170 - val_accuracy: 0.8900\n",
      "Epoch 1751/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.2235 - accuracy: 0.9350 - val_loss: 0.3168 - val_accuracy: 0.8850\n",
      "Epoch 1752/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2233 - accuracy: 0.9375 - val_loss: 0.3155 - val_accuracy: 0.8850\n",
      "Epoch 1753/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.2232 - accuracy: 0.9337 - val_loss: 0.3161 - val_accuracy: 0.8850\n",
      "Epoch 1754/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2231 - accuracy: 0.9375 - val_loss: 0.3153 - val_accuracy: 0.8900\n",
      "Epoch 1755/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2228 - accuracy: 0.9312 - val_loss: 0.3159 - val_accuracy: 0.8900\n",
      "Epoch 1756/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.2233 - accuracy: 0.9325 - val_loss: 0.3169 - val_accuracy: 0.8800\n",
      "Epoch 1757/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2233 - accuracy: 0.9362 - val_loss: 0.3151 - val_accuracy: 0.8800\n",
      "Epoch 1758/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.2232 - accuracy: 0.9362 - val_loss: 0.3155 - val_accuracy: 0.8850\n",
      "Epoch 1759/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.2228 - accuracy: 0.9300 - val_loss: 0.3172 - val_accuracy: 0.8850\n",
      "Epoch 1760/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2224 - accuracy: 0.9350 - val_loss: 0.3154 - val_accuracy: 0.8900\n",
      "Epoch 1761/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.2224 - accuracy: 0.9312 - val_loss: 0.3147 - val_accuracy: 0.8800\n",
      "Epoch 1762/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2225 - accuracy: 0.9350 - val_loss: 0.3175 - val_accuracy: 0.8900\n",
      "Epoch 1763/3000\n",
      "800/800 [==============================] - 0s 133us/step - loss: 0.2224 - accuracy: 0.9362 - val_loss: 0.3159 - val_accuracy: 0.8850\n",
      "Epoch 1764/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2217 - accuracy: 0.9350 - val_loss: 0.3167 - val_accuracy: 0.8850\n",
      "Epoch 1765/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.2227 - accuracy: 0.9375 - val_loss: 0.3153 - val_accuracy: 0.8900\n",
      "Epoch 1766/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.2223 - accuracy: 0.9350 - val_loss: 0.3154 - val_accuracy: 0.8850\n",
      "Epoch 1767/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.2217 - accuracy: 0.9337 - val_loss: 0.3145 - val_accuracy: 0.8800\n",
      "Epoch 1768/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.2224 - accuracy: 0.9325 - val_loss: 0.3155 - val_accuracy: 0.8850\n",
      "Epoch 1769/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2222 - accuracy: 0.9362 - val_loss: 0.3145 - val_accuracy: 0.8850\n",
      "Epoch 1770/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.2220 - accuracy: 0.9375 - val_loss: 0.3139 - val_accuracy: 0.8850\n",
      "Epoch 1771/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.2213 - accuracy: 0.9312 - val_loss: 0.3158 - val_accuracy: 0.8800\n",
      "Epoch 1772/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2208 - accuracy: 0.9375 - val_loss: 0.3150 - val_accuracy: 0.8850\n",
      "Epoch 1773/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2211 - accuracy: 0.9350 - val_loss: 0.3139 - val_accuracy: 0.8950\n",
      "Epoch 1774/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2258 - accuracy: 0.92 - 0s 110us/step - loss: 0.2215 - accuracy: 0.9287 - val_loss: 0.3132 - val_accuracy: 0.8950\n",
      "Epoch 1775/3000\n",
      "800/800 [==============================] - 0s 123us/step - loss: 0.2215 - accuracy: 0.9337 - val_loss: 0.3143 - val_accuracy: 0.8900\n",
      "Epoch 1776/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.2211 - accuracy: 0.9350 - val_loss: 0.3137 - val_accuracy: 0.8850\n",
      "Epoch 1777/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.2209 - accuracy: 0.9350 - val_loss: 0.3133 - val_accuracy: 0.8900\n",
      "Epoch 1778/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.2212 - accuracy: 0.9350 - val_loss: 0.3144 - val_accuracy: 0.8850\n",
      "Epoch 1779/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.2209 - accuracy: 0.9350 - val_loss: 0.3143 - val_accuracy: 0.8900\n",
      "Epoch 1780/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2207 - accuracy: 0.9325 - val_loss: 0.3142 - val_accuracy: 0.8950\n",
      "Epoch 1781/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.2213 - accuracy: 0.9362 - val_loss: 0.3138 - val_accuracy: 0.8900\n",
      "Epoch 1782/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1762 - accuracy: 0.95 - 0s 88us/step - loss: 0.2204 - accuracy: 0.9362 - val_loss: 0.3138 - val_accuracy: 0.8950\n",
      "Epoch 1783/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2207 - accuracy: 0.9337 - val_loss: 0.3134 - val_accuracy: 0.8900\n",
      "Epoch 1784/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2196 - accuracy: 0.9362 - val_loss: 0.3131 - val_accuracy: 0.8800\n",
      "Epoch 1785/3000\n",
      "800/800 [==============================] - 0s 149us/step - loss: 0.2201 - accuracy: 0.9375 - val_loss: 0.3130 - val_accuracy: 0.8800\n",
      "Epoch 1786/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2202 - accuracy: 0.9325 - val_loss: 0.3154 - val_accuracy: 0.8900\n",
      "Epoch 1787/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2192 - accuracy: 0.9388 - val_loss: 0.3155 - val_accuracy: 0.8900\n",
      "Epoch 1788/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.2199 - accuracy: 0.9350 - val_loss: 0.3147 - val_accuracy: 0.8850\n",
      "Epoch 1789/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.2197 - accuracy: 0.9375 - val_loss: 0.3145 - val_accuracy: 0.8800\n",
      "Epoch 1790/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2177 - accuracy: 0.93 - 0s 105us/step - loss: 0.2195 - accuracy: 0.9362 - val_loss: 0.3145 - val_accuracy: 0.8750\n",
      "Epoch 1791/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.2201 - accuracy: 0.9325 - val_loss: 0.3132 - val_accuracy: 0.8900\n",
      "Epoch 1792/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2191 - accuracy: 0.9388 - val_loss: 0.3118 - val_accuracy: 0.8900\n",
      "Epoch 1793/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.2197 - accuracy: 0.9337 - val_loss: 0.3136 - val_accuracy: 0.8800\n",
      "Epoch 1794/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2216 - accuracy: 0.93 - 0s 91us/step - loss: 0.2195 - accuracy: 0.9325 - val_loss: 0.3141 - val_accuracy: 0.8900\n",
      "Epoch 1795/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2187 - accuracy: 0.9350 - val_loss: 0.3141 - val_accuracy: 0.8850\n",
      "Epoch 1796/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.2197 - accuracy: 0.9350 - val_loss: 0.3139 - val_accuracy: 0.8900\n",
      "Epoch 1797/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.93 - 0s 106us/step - loss: 0.2191 - accuracy: 0.9337 - val_loss: 0.3137 - val_accuracy: 0.8900\n",
      "Epoch 1798/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.2185 - accuracy: 0.9362 - val_loss: 0.3145 - val_accuracy: 0.8950\n",
      "Epoch 1799/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2174 - accuracy: 0.93 - 0s 114us/step - loss: 0.2194 - accuracy: 0.9325 - val_loss: 0.3139 - val_accuracy: 0.8900\n",
      "Epoch 1800/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2188 - accuracy: 0.9325 - val_loss: 0.3129 - val_accuracy: 0.8950\n",
      "Epoch 1801/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2182 - accuracy: 0.9350 - val_loss: 0.3125 - val_accuracy: 0.8950\n",
      "Epoch 1802/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.2184 - accuracy: 0.9375 - val_loss: 0.3143 - val_accuracy: 0.8800\n",
      "Epoch 1803/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2185 - accuracy: 0.9375 - val_loss: 0.3147 - val_accuracy: 0.8850\n",
      "Epoch 1804/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.2187 - accuracy: 0.9388 - val_loss: 0.3156 - val_accuracy: 0.8850\n",
      "Epoch 1805/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.2180 - accuracy: 0.9375 - val_loss: 0.3132 - val_accuracy: 0.8850\n",
      "Epoch 1806/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.2183 - accuracy: 0.9413 - val_loss: 0.3122 - val_accuracy: 0.8900\n",
      "Epoch 1807/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2180 - accuracy: 0.9375 - val_loss: 0.3116 - val_accuracy: 0.8900\n",
      "Epoch 1808/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.2183 - accuracy: 0.9350 - val_loss: 0.3133 - val_accuracy: 0.8800\n",
      "Epoch 1809/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.2180 - accuracy: 0.9337 - val_loss: 0.3132 - val_accuracy: 0.8900\n",
      "Epoch 1810/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.2176 - accuracy: 0.9350 - val_loss: 0.3136 - val_accuracy: 0.8900\n",
      "Epoch 1811/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2173 - accuracy: 0.9350 - val_loss: 0.3125 - val_accuracy: 0.8800\n",
      "Epoch 1812/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2172 - accuracy: 0.9350 - val_loss: 0.3119 - val_accuracy: 0.8850\n",
      "Epoch 1813/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.2182 - accuracy: 0.9350 - val_loss: 0.3132 - val_accuracy: 0.8800\n",
      "Epoch 1814/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2172 - accuracy: 0.9350 - val_loss: 0.3111 - val_accuracy: 0.8900\n",
      "Epoch 1815/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2168 - accuracy: 0.9325 - val_loss: 0.3103 - val_accuracy: 0.8900\n",
      "Epoch 1816/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.2163 - accuracy: 0.9325 - val_loss: 0.3129 - val_accuracy: 0.8900\n",
      "Epoch 1817/3000\n",
      "800/800 [==============================] - 0s 128us/step - loss: 0.2174 - accuracy: 0.9375 - val_loss: 0.3103 - val_accuracy: 0.8950\n",
      "Epoch 1818/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2170 - accuracy: 0.9362 - val_loss: 0.3101 - val_accuracy: 0.8900\n",
      "Epoch 1819/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.2167 - accuracy: 0.9388 - val_loss: 0.3108 - val_accuracy: 0.8850\n",
      "Epoch 1820/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.2174 - accuracy: 0.9337 - val_loss: 0.3111 - val_accuracy: 0.8800\n",
      "Epoch 1821/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2192 - accuracy: 0.93 - 0s 95us/step - loss: 0.2164 - accuracy: 0.9388 - val_loss: 0.3105 - val_accuracy: 0.8950\n",
      "Epoch 1822/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.2166 - accuracy: 0.9350 - val_loss: 0.3116 - val_accuracy: 0.8850\n",
      "Epoch 1823/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2165 - accuracy: 0.9362 - val_loss: 0.3104 - val_accuracy: 0.8850\n",
      "Epoch 1824/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2162 - accuracy: 0.9350 - val_loss: 0.3109 - val_accuracy: 0.8800\n",
      "Epoch 1825/3000\n",
      "800/800 [==============================] - 0s 123us/step - loss: 0.2161 - accuracy: 0.9337 - val_loss: 0.3124 - val_accuracy: 0.8900\n",
      "Epoch 1826/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.2159 - accuracy: 0.9362 - val_loss: 0.3105 - val_accuracy: 0.8950\n",
      "Epoch 1827/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.2150 - accuracy: 0.9375 - val_loss: 0.3137 - val_accuracy: 0.8800\n",
      "Epoch 1828/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2159 - accuracy: 0.9337 - val_loss: 0.3096 - val_accuracy: 0.8900\n",
      "Epoch 1829/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2159 - accuracy: 0.9375 - val_loss: 0.3106 - val_accuracy: 0.8800\n",
      "Epoch 1830/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.2154 - accuracy: 0.9362 - val_loss: 0.3093 - val_accuracy: 0.8900\n",
      "Epoch 1831/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.2156 - accuracy: 0.9400 - val_loss: 0.3094 - val_accuracy: 0.8950\n",
      "Epoch 1832/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2157 - accuracy: 0.9362 - val_loss: 0.3090 - val_accuracy: 0.8900\n",
      "Epoch 1833/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.2162 - accuracy: 0.9362 - val_loss: 0.3096 - val_accuracy: 0.8950\n",
      "Epoch 1834/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2149 - accuracy: 0.9375 - val_loss: 0.3103 - val_accuracy: 0.8900\n",
      "Epoch 1835/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.2152 - accuracy: 0.9375 - val_loss: 0.3092 - val_accuracy: 0.8900\n",
      "Epoch 1836/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2151 - accuracy: 0.9362 - val_loss: 0.3099 - val_accuracy: 0.8900\n",
      "Epoch 1837/3000\n",
      "800/800 [==============================] - 0s 315us/step - loss: 0.2157 - accuracy: 0.9375 - val_loss: 0.3118 - val_accuracy: 0.8900\n",
      "Epoch 1838/3000\n",
      "800/800 [==============================] - 0s 223us/step - loss: 0.2146 - accuracy: 0.9388 - val_loss: 0.3098 - val_accuracy: 0.8900\n",
      "Epoch 1839/3000\n",
      "800/800 [==============================] - 0s 169us/step - loss: 0.2146 - accuracy: 0.9337 - val_loss: 0.3099 - val_accuracy: 0.8800\n",
      "Epoch 1840/3000\n",
      "800/800 [==============================] - 0s 291us/step - loss: 0.2149 - accuracy: 0.9362 - val_loss: 0.3096 - val_accuracy: 0.8850\n",
      "Epoch 1841/3000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.2149 - accuracy: 0.9362 - val_loss: 0.3111 - val_accuracy: 0.8900\n",
      "Epoch 1842/3000\n",
      "800/800 [==============================] - 0s 469us/step - loss: 0.2148 - accuracy: 0.9362 - val_loss: 0.3124 - val_accuracy: 0.8800\n",
      "Epoch 1843/3000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 0.2144 - accuracy: 0.9375 - val_loss: 0.3096 - val_accuracy: 0.8800\n",
      "Epoch 1844/3000\n",
      "800/800 [==============================] - 0s 475us/step - loss: 0.2146 - accuracy: 0.9337 - val_loss: 0.3104 - val_accuracy: 0.8900\n",
      "Epoch 1845/3000\n",
      "800/800 [==============================] - 0s 360us/step - loss: 0.2143 - accuracy: 0.9388 - val_loss: 0.3106 - val_accuracy: 0.8800\n",
      "Epoch 1846/3000\n",
      "800/800 [==============================] - 0s 354us/step - loss: 0.2141 - accuracy: 0.9400 - val_loss: 0.3118 - val_accuracy: 0.8800\n",
      "Epoch 1847/3000\n",
      "800/800 [==============================] - 0s 293us/step - loss: 0.2140 - accuracy: 0.9375 - val_loss: 0.3110 - val_accuracy: 0.8900\n",
      "Epoch 1848/3000\n",
      "800/800 [==============================] - 0s 144us/step - loss: 0.2141 - accuracy: 0.9375 - val_loss: 0.3103 - val_accuracy: 0.8800\n",
      "Epoch 1849/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2144 - accuracy: 0.9350 - val_loss: 0.3089 - val_accuracy: 0.8950\n",
      "Epoch 1850/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2144 - accuracy: 0.9375 - val_loss: 0.3075 - val_accuracy: 0.8850\n",
      "Epoch 1851/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.2135 - accuracy: 0.9375 - val_loss: 0.3103 - val_accuracy: 0.8900\n",
      "Epoch 1852/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2137 - accuracy: 0.9350 - val_loss: 0.3110 - val_accuracy: 0.8900\n",
      "Epoch 1853/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2134 - accuracy: 0.9413 - val_loss: 0.3070 - val_accuracy: 0.8950\n",
      "Epoch 1854/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2136 - accuracy: 0.9362 - val_loss: 0.3079 - val_accuracy: 0.8850\n",
      "Epoch 1855/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.2132 - accuracy: 0.9388 - val_loss: 0.3081 - val_accuracy: 0.8850\n",
      "Epoch 1856/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1843 - accuracy: 0.93 - 0s 90us/step - loss: 0.2137 - accuracy: 0.9375 - val_loss: 0.3099 - val_accuracy: 0.8800\n",
      "Epoch 1857/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.2130 - accuracy: 0.9362 - val_loss: 0.3086 - val_accuracy: 0.8900\n",
      "Epoch 1858/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2129 - accuracy: 0.9350 - val_loss: 0.3101 - val_accuracy: 0.8800\n",
      "Epoch 1859/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.2126 - accuracy: 0.9375 - val_loss: 0.3066 - val_accuracy: 0.8950\n",
      "Epoch 1860/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2132 - accuracy: 0.9362 - val_loss: 0.3080 - val_accuracy: 0.8950\n",
      "Epoch 1861/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2126 - accuracy: 0.9375 - val_loss: 0.3085 - val_accuracy: 0.8900\n",
      "Epoch 1862/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2124 - accuracy: 0.9413 - val_loss: 0.3078 - val_accuracy: 0.8850\n",
      "Epoch 1863/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2129 - accuracy: 0.9362 - val_loss: 0.3068 - val_accuracy: 0.8850\n",
      "Epoch 1864/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.2120 - accuracy: 0.9350 - val_loss: 0.3090 - val_accuracy: 0.8800\n",
      "Epoch 1865/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2125 - accuracy: 0.9362 - val_loss: 0.3086 - val_accuracy: 0.8900\n",
      "Epoch 1866/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2117 - accuracy: 0.9375 - val_loss: 0.3071 - val_accuracy: 0.8950\n",
      "Epoch 1867/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.2115 - accuracy: 0.9400 - val_loss: 0.3072 - val_accuracy: 0.8850\n",
      "Epoch 1868/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2123 - accuracy: 0.9362 - val_loss: 0.3079 - val_accuracy: 0.8950\n",
      "Epoch 1869/3000\n",
      "800/800 [==============================] - 0s 125us/step - loss: 0.2130 - accuracy: 0.9400 - val_loss: 0.3073 - val_accuracy: 0.8900\n",
      "Epoch 1870/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2122 - accuracy: 0.9362 - val_loss: 0.3059 - val_accuracy: 0.8900\n",
      "Epoch 1871/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.2126 - accuracy: 0.9375 - val_loss: 0.3080 - val_accuracy: 0.8950\n",
      "Epoch 1872/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2121 - accuracy: 0.9413 - val_loss: 0.3071 - val_accuracy: 0.8850\n",
      "Epoch 1873/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.2112 - accuracy: 0.9375 - val_loss: 0.3084 - val_accuracy: 0.8900\n",
      "Epoch 1874/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2112 - accuracy: 0.9388 - val_loss: 0.3090 - val_accuracy: 0.8900\n",
      "Epoch 1875/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2120 - accuracy: 0.9400 - val_loss: 0.3076 - val_accuracy: 0.8800\n",
      "Epoch 1876/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.2114 - accuracy: 0.9388 - val_loss: 0.3075 - val_accuracy: 0.8900\n",
      "Epoch 1877/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2113 - accuracy: 0.9375 - val_loss: 0.3081 - val_accuracy: 0.8900\n",
      "Epoch 1878/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2112 - accuracy: 0.9388 - val_loss: 0.3076 - val_accuracy: 0.8800\n",
      "Epoch 1879/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.2108 - accuracy: 0.9413 - val_loss: 0.3063 - val_accuracy: 0.8850\n",
      "Epoch 1880/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2113 - accuracy: 0.9350 - val_loss: 0.3060 - val_accuracy: 0.8950\n",
      "Epoch 1881/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.93 - 0s 118us/step - loss: 0.2110 - accuracy: 0.9375 - val_loss: 0.3071 - val_accuracy: 0.8900\n",
      "Epoch 1882/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2111 - accuracy: 0.9388 - val_loss: 0.3063 - val_accuracy: 0.8900\n",
      "Epoch 1883/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.2110 - accuracy: 0.9375 - val_loss: 0.3069 - val_accuracy: 0.8850\n",
      "Epoch 1884/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.2105 - accuracy: 0.9400 - val_loss: 0.3073 - val_accuracy: 0.8850\n",
      "Epoch 1885/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2076 - accuracy: 0.94 - 0s 106us/step - loss: 0.2105 - accuracy: 0.9400 - val_loss: 0.3063 - val_accuracy: 0.8800\n",
      "Epoch 1886/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.2096 - accuracy: 0.9350 - val_loss: 0.3093 - val_accuracy: 0.8900\n",
      "Epoch 1887/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2104 - accuracy: 0.9362 - val_loss: 0.3072 - val_accuracy: 0.8900\n",
      "Epoch 1888/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.2102 - accuracy: 0.9375 - val_loss: 0.3049 - val_accuracy: 0.8900\n",
      "Epoch 1889/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2105 - accuracy: 0.9350 - val_loss: 0.3052 - val_accuracy: 0.8800\n",
      "Epoch 1890/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2100 - accuracy: 0.9337 - val_loss: 0.3070 - val_accuracy: 0.8900\n",
      "Epoch 1891/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2940 - accuracy: 0.89 - ETA: 0s - loss: 0.1989 - accuracy: 0.94 - 0s 121us/step - loss: 0.2097 - accuracy: 0.9388 - val_loss: 0.3055 - val_accuracy: 0.8950\n",
      "Epoch 1892/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2105 - accuracy: 0.9362 - val_loss: 0.3058 - val_accuracy: 0.8850\n",
      "Epoch 1893/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.2102 - accuracy: 0.9375 - val_loss: 0.3054 - val_accuracy: 0.8800\n",
      "Epoch 1894/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.2093 - accuracy: 0.9388 - val_loss: 0.3070 - val_accuracy: 0.8850\n",
      "Epoch 1895/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2089 - accuracy: 0.9388 - val_loss: 0.3040 - val_accuracy: 0.8850\n",
      "Epoch 1896/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2098 - accuracy: 0.9388 - val_loss: 0.3075 - val_accuracy: 0.8800\n",
      "Epoch 1897/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.2087 - accuracy: 0.9362 - val_loss: 0.3077 - val_accuracy: 0.8900\n",
      "Epoch 1898/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2092 - accuracy: 0.9400 - val_loss: 0.3066 - val_accuracy: 0.8900\n",
      "Epoch 1899/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2092 - accuracy: 0.9362 - val_loss: 0.3071 - val_accuracy: 0.8850\n",
      "Epoch 1900/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.2089 - accuracy: 0.9337 - val_loss: 0.3063 - val_accuracy: 0.8950\n",
      "Epoch 1901/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2091 - accuracy: 0.9388 - val_loss: 0.3048 - val_accuracy: 0.8950\n",
      "Epoch 1902/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.2093 - accuracy: 0.9375 - val_loss: 0.3070 - val_accuracy: 0.8900\n",
      "Epoch 1903/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2073 - accuracy: 0.9400 - val_loss: 0.3050 - val_accuracy: 0.8750\n",
      "Epoch 1904/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2095 - accuracy: 0.9413 - val_loss: 0.3060 - val_accuracy: 0.8800\n",
      "Epoch 1905/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.2078 - accuracy: 0.9400 - val_loss: 0.3051 - val_accuracy: 0.8950\n",
      "Epoch 1906/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2094 - accuracy: 0.9400 - val_loss: 0.3054 - val_accuracy: 0.8900\n",
      "Epoch 1907/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.2089 - accuracy: 0.9400 - val_loss: 0.3057 - val_accuracy: 0.8800\n",
      "Epoch 1908/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.2089 - accuracy: 0.9388 - val_loss: 0.3068 - val_accuracy: 0.8850\n",
      "Epoch 1909/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2084 - accuracy: 0.9362 - val_loss: 0.3044 - val_accuracy: 0.8800\n",
      "Epoch 1910/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.2082 - accuracy: 0.9388 - val_loss: 0.3052 - val_accuracy: 0.8850\n",
      "Epoch 1911/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.2087 - accuracy: 0.9413 - val_loss: 0.3053 - val_accuracy: 0.8800\n",
      "Epoch 1912/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2080 - accuracy: 0.9375 - val_loss: 0.3036 - val_accuracy: 0.8900\n",
      "Epoch 1913/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.94 - 0s 99us/step - loss: 0.2081 - accuracy: 0.9413 - val_loss: 0.3047 - val_accuracy: 0.8850\n",
      "Epoch 1914/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2084 - accuracy: 0.9375 - val_loss: 0.3034 - val_accuracy: 0.8950\n",
      "Epoch 1915/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.2076 - accuracy: 0.9400 - val_loss: 0.3036 - val_accuracy: 0.8900\n",
      "Epoch 1916/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.2076 - accuracy: 0.9362 - val_loss: 0.3056 - val_accuracy: 0.8900\n",
      "Epoch 1917/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.2078 - accuracy: 0.9425 - val_loss: 0.3041 - val_accuracy: 0.8850\n",
      "Epoch 1918/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.2074 - accuracy: 0.9375 - val_loss: 0.3036 - val_accuracy: 0.8950\n",
      "Epoch 1919/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2047 - accuracy: 0.94 - 0s 111us/step - loss: 0.2074 - accuracy: 0.9375 - val_loss: 0.3052 - val_accuracy: 0.8900\n",
      "Epoch 1920/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.2073 - accuracy: 0.9413 - val_loss: 0.3046 - val_accuracy: 0.8850\n",
      "Epoch 1921/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.2074 - accuracy: 0.9400 - val_loss: 0.3023 - val_accuracy: 0.8950\n",
      "Epoch 1922/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2079 - accuracy: 0.9400 - val_loss: 0.3042 - val_accuracy: 0.8950\n",
      "Epoch 1923/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2075 - accuracy: 0.9388 - val_loss: 0.3055 - val_accuracy: 0.8800\n",
      "Epoch 1924/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2073 - accuracy: 0.9400 - val_loss: 0.3053 - val_accuracy: 0.8900\n",
      "Epoch 1925/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2076 - accuracy: 0.9450 - val_loss: 0.3035 - val_accuracy: 0.8950\n",
      "Epoch 1926/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2071 - accuracy: 0.9413 - val_loss: 0.3032 - val_accuracy: 0.8950\n",
      "Epoch 1927/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.2066 - accuracy: 0.9400 - val_loss: 0.3047 - val_accuracy: 0.8850\n",
      "Epoch 1928/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2059 - accuracy: 0.9425 - val_loss: 0.3045 - val_accuracy: 0.8900\n",
      "Epoch 1929/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2063 - accuracy: 0.9400 - val_loss: 0.3031 - val_accuracy: 0.8950\n",
      "Epoch 1930/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2066 - accuracy: 0.9413 - val_loss: 0.3033 - val_accuracy: 0.8850\n",
      "Epoch 1931/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.2063 - accuracy: 0.9400 - val_loss: 0.3042 - val_accuracy: 0.8900\n",
      "Epoch 1932/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.2063 - accuracy: 0.9388 - val_loss: 0.3026 - val_accuracy: 0.8950\n",
      "Epoch 1933/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.2067 - accuracy: 0.9388 - val_loss: 0.3022 - val_accuracy: 0.8950\n",
      "Epoch 1934/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.2057 - accuracy: 0.9400 - val_loss: 0.3015 - val_accuracy: 0.8850\n",
      "Epoch 1935/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.2064 - accuracy: 0.9375 - val_loss: 0.3036 - val_accuracy: 0.8850\n",
      "Epoch 1936/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2067 - accuracy: 0.9375 - val_loss: 0.3027 - val_accuracy: 0.8950\n",
      "Epoch 1937/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.2062 - accuracy: 0.9400 - val_loss: 0.3032 - val_accuracy: 0.8850\n",
      "Epoch 1938/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.2062 - accuracy: 0.9388 - val_loss: 0.3040 - val_accuracy: 0.8800\n",
      "Epoch 1939/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2267 - accuracy: 0.93 - ETA: 0s - loss: 0.2102 - accuracy: 0.93 - 0s 123us/step - loss: 0.2052 - accuracy: 0.9413 - val_loss: 0.3022 - val_accuracy: 0.8900\n",
      "Epoch 1940/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.2053 - accuracy: 0.9400 - val_loss: 0.3026 - val_accuracy: 0.8850\n",
      "Epoch 1941/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.2062 - accuracy: 0.9400 - val_loss: 0.3026 - val_accuracy: 0.8850\n",
      "Epoch 1942/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2056 - accuracy: 0.9375 - val_loss: 0.3042 - val_accuracy: 0.8850\n",
      "Epoch 1943/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.2059 - accuracy: 0.9425 - val_loss: 0.3022 - val_accuracy: 0.8850\n",
      "Epoch 1944/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2032 - accuracy: 0.94 - 0s 100us/step - loss: 0.2050 - accuracy: 0.9413 - val_loss: 0.3025 - val_accuracy: 0.8900\n",
      "Epoch 1945/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.2053 - accuracy: 0.9388 - val_loss: 0.3015 - val_accuracy: 0.8900\n",
      "Epoch 1946/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.2056 - accuracy: 0.9413 - val_loss: 0.3014 - val_accuracy: 0.8850\n",
      "Epoch 1947/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.2047 - accuracy: 0.9413 - val_loss: 0.3009 - val_accuracy: 0.8950\n",
      "Epoch 1948/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.2047 - accuracy: 0.9400 - val_loss: 0.3008 - val_accuracy: 0.8900\n",
      "Epoch 1949/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.2055 - accuracy: 0.9400 - val_loss: 0.3026 - val_accuracy: 0.8900\n",
      "Epoch 1950/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2047 - accuracy: 0.9375 - val_loss: 0.3018 - val_accuracy: 0.8900\n",
      "Epoch 1951/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.94 - 0s 113us/step - loss: 0.2048 - accuracy: 0.9425 - val_loss: 0.3028 - val_accuracy: 0.8850\n",
      "Epoch 1952/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2052 - accuracy: 0.9375 - val_loss: 0.3015 - val_accuracy: 0.8900\n",
      "Epoch 1953/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.2042 - accuracy: 0.9375 - val_loss: 0.2998 - val_accuracy: 0.8900\n",
      "Epoch 1954/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.2046 - accuracy: 0.9388 - val_loss: 0.3010 - val_accuracy: 0.8900\n",
      "Epoch 1955/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.2043 - accuracy: 0.9425 - val_loss: 0.3006 - val_accuracy: 0.8900\n",
      "Epoch 1956/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2043 - accuracy: 0.9362 - val_loss: 0.3010 - val_accuracy: 0.8850\n",
      "Epoch 1957/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2036 - accuracy: 0.9425 - val_loss: 0.2993 - val_accuracy: 0.8850\n",
      "Epoch 1958/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2045 - accuracy: 0.9388 - val_loss: 0.3006 - val_accuracy: 0.8900\n",
      "Epoch 1959/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.2040 - accuracy: 0.9388 - val_loss: 0.3006 - val_accuracy: 0.8900\n",
      "Epoch 1960/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.2041 - accuracy: 0.9375 - val_loss: 0.3020 - val_accuracy: 0.8900\n",
      "Epoch 1961/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2037 - accuracy: 0.9425 - val_loss: 0.3014 - val_accuracy: 0.8850\n",
      "Epoch 1962/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2049 - accuracy: 0.9388 - val_loss: 0.3020 - val_accuracy: 0.8950\n",
      "Epoch 1963/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.2034 - accuracy: 0.9413 - val_loss: 0.3032 - val_accuracy: 0.8850\n",
      "Epoch 1964/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.2039 - accuracy: 0.9425 - val_loss: 0.3034 - val_accuracy: 0.8900\n",
      "Epoch 1965/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2040 - accuracy: 0.9400 - val_loss: 0.3023 - val_accuracy: 0.8850\n",
      "Epoch 1966/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.2034 - accuracy: 0.9425 - val_loss: 0.3008 - val_accuracy: 0.8900\n",
      "Epoch 1967/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2028 - accuracy: 0.9425 - val_loss: 0.3012 - val_accuracy: 0.8950\n",
      "Epoch 1968/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2033 - accuracy: 0.9425 - val_loss: 0.2998 - val_accuracy: 0.8950\n",
      "Epoch 1969/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.2031 - accuracy: 0.9413 - val_loss: 0.2992 - val_accuracy: 0.8950\n",
      "Epoch 1970/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.2035 - accuracy: 0.9400 - val_loss: 0.3007 - val_accuracy: 0.8900\n",
      "Epoch 1971/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2052 - accuracy: 0.94 - 0s 114us/step - loss: 0.2028 - accuracy: 0.9425 - val_loss: 0.3000 - val_accuracy: 0.8850\n",
      "Epoch 1972/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.2031 - accuracy: 0.9425 - val_loss: 0.3008 - val_accuracy: 0.8900\n",
      "Epoch 1973/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.2027 - accuracy: 0.9400 - val_loss: 0.3012 - val_accuracy: 0.8900\n",
      "Epoch 1974/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2028 - accuracy: 0.9438 - val_loss: 0.3044 - val_accuracy: 0.8850\n",
      "Epoch 1975/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.2028 - accuracy: 0.9413 - val_loss: 0.3004 - val_accuracy: 0.8950\n",
      "Epoch 1976/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.2025 - accuracy: 0.9450 - val_loss: 0.2990 - val_accuracy: 0.8900\n",
      "Epoch 1977/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.2022 - accuracy: 0.9425 - val_loss: 0.2983 - val_accuracy: 0.8900\n",
      "Epoch 1978/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.2020 - accuracy: 0.9425 - val_loss: 0.2984 - val_accuracy: 0.8950\n",
      "Epoch 1979/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2015 - accuracy: 0.93 - 0s 103us/step - loss: 0.2032 - accuracy: 0.9388 - val_loss: 0.3001 - val_accuracy: 0.8950\n",
      "Epoch 1980/3000\n",
      "800/800 [==============================] - 0s 123us/step - loss: 0.2025 - accuracy: 0.9413 - val_loss: 0.2988 - val_accuracy: 0.8900\n",
      "Epoch 1981/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2024 - accuracy: 0.9413 - val_loss: 0.2995 - val_accuracy: 0.8900\n",
      "Epoch 1982/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.2020 - accuracy: 0.9413 - val_loss: 0.3001 - val_accuracy: 0.8950\n",
      "Epoch 1983/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.2025 - accuracy: 0.9438 - val_loss: 0.2996 - val_accuracy: 0.8950\n",
      "Epoch 1984/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.2016 - accuracy: 0.9413 - val_loss: 0.2979 - val_accuracy: 0.8950\n",
      "Epoch 1985/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.2018 - accuracy: 0.9388 - val_loss: 0.3020 - val_accuracy: 0.8850\n",
      "Epoch 1986/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.98 - 0s 93us/step - loss: 0.2016 - accuracy: 0.9425 - val_loss: 0.2986 - val_accuracy: 0.8900\n",
      "Epoch 1987/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2086 - accuracy: 0.93 - 0s 110us/step - loss: 0.2017 - accuracy: 0.9413 - val_loss: 0.2992 - val_accuracy: 0.8900\n",
      "Epoch 1988/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.2019 - accuracy: 0.9425 - val_loss: 0.2996 - val_accuracy: 0.8950\n",
      "Epoch 1989/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2189 - accuracy: 0.95 - 0s 84us/step - loss: 0.2016 - accuracy: 0.9425 - val_loss: 0.2988 - val_accuracy: 0.8900\n",
      "Epoch 1990/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.2009 - accuracy: 0.9400 - val_loss: 0.3017 - val_accuracy: 0.8850\n",
      "Epoch 1991/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2021 - accuracy: 0.9425 - val_loss: 0.3005 - val_accuracy: 0.8900\n",
      "Epoch 1992/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.2014 - accuracy: 0.9438 - val_loss: 0.2977 - val_accuracy: 0.8900\n",
      "Epoch 1993/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.2011 - accuracy: 0.9388 - val_loss: 0.2983 - val_accuracy: 0.8950\n",
      "Epoch 1994/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.2014 - accuracy: 0.9463 - val_loss: 0.2982 - val_accuracy: 0.8950\n",
      "Epoch 1995/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.2005 - accuracy: 0.9375 - val_loss: 0.2985 - val_accuracy: 0.8950\n",
      "Epoch 1996/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.2008 - accuracy: 0.9438 - val_loss: 0.2981 - val_accuracy: 0.8900\n",
      "Epoch 1997/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.2002 - accuracy: 0.9450 - val_loss: 0.2977 - val_accuracy: 0.8900\n",
      "Epoch 1998/3000\n",
      "800/800 [==============================] - 0s 296us/step - loss: 0.2016 - accuracy: 0.9413 - val_loss: 0.2983 - val_accuracy: 0.8900\n",
      "Epoch 1999/3000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 0.2002 - accuracy: 0.9400 - val_loss: 0.2974 - val_accuracy: 0.8850\n",
      "Epoch 2000/3000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.2003 - accuracy: 0.9413 - val_loss: 0.3014 - val_accuracy: 0.8850\n",
      "Epoch 2001/3000\n",
      "800/800 [==============================] - 0s 328us/step - loss: 0.2008 - accuracy: 0.9438 - val_loss: 0.3002 - val_accuracy: 0.8900\n",
      "Epoch 2002/3000\n",
      "800/800 [==============================] - 0s 341us/step - loss: 0.2004 - accuracy: 0.9425 - val_loss: 0.3007 - val_accuracy: 0.8850\n",
      "Epoch 2003/3000\n",
      "800/800 [==============================] - 0s 336us/step - loss: 0.2002 - accuracy: 0.9450 - val_loss: 0.2983 - val_accuracy: 0.8950\n",
      "Epoch 2004/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.2004 - accuracy: 0.9413 - val_loss: 0.2993 - val_accuracy: 0.8900\n",
      "Epoch 2005/3000\n",
      "800/800 [==============================] - 0s 271us/step - loss: 0.2005 - accuracy: 0.9438 - val_loss: 0.2997 - val_accuracy: 0.8850\n",
      "Epoch 2006/3000\n",
      "800/800 [==============================] - 0s 365us/step - loss: 0.2001 - accuracy: 0.9388 - val_loss: 0.2989 - val_accuracy: 0.8950\n",
      "Epoch 2007/3000\n",
      "800/800 [==============================] - 0s 389us/step - loss: 0.2003 - accuracy: 0.9413 - val_loss: 0.2974 - val_accuracy: 0.8950\n",
      "Epoch 2008/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.2004 - accuracy: 0.9413 - val_loss: 0.2976 - val_accuracy: 0.8900\n",
      "Epoch 2009/3000\n",
      "800/800 [==============================] - 0s 128us/step - loss: 0.1998 - accuracy: 0.9425 - val_loss: 0.2978 - val_accuracy: 0.8900\n",
      "Epoch 2010/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2008 - accuracy: 0.9400 - val_loss: 0.2986 - val_accuracy: 0.8850\n",
      "Epoch 2011/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1996 - accuracy: 0.9413 - val_loss: 0.3005 - val_accuracy: 0.8850\n",
      "Epoch 2012/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.2001 - accuracy: 0.9450 - val_loss: 0.2990 - val_accuracy: 0.8850\n",
      "Epoch 2013/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.2001 - accuracy: 0.9425 - val_loss: 0.2994 - val_accuracy: 0.8850\n",
      "Epoch 2014/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2011 - accuracy: 0.9425 - val_loss: 0.2976 - val_accuracy: 0.8950\n",
      "Epoch 2015/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.1991 - accuracy: 0.9413 - val_loss: 0.2981 - val_accuracy: 0.8900\n",
      "Epoch 2016/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1989 - accuracy: 0.9400 - val_loss: 0.2983 - val_accuracy: 0.8950\n",
      "Epoch 2017/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1994 - accuracy: 0.9425 - val_loss: 0.2974 - val_accuracy: 0.8950\n",
      "Epoch 2018/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1862 - accuracy: 0.96 - 0s 99us/step - loss: 0.1993 - accuracy: 0.9400 - val_loss: 0.2974 - val_accuracy: 0.8900\n",
      "Epoch 2019/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1996 - accuracy: 0.9450 - val_loss: 0.2973 - val_accuracy: 0.8850\n",
      "Epoch 2020/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1991 - accuracy: 0.9400 - val_loss: 0.2968 - val_accuracy: 0.8950\n",
      "Epoch 2021/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1996 - accuracy: 0.9425 - val_loss: 0.2975 - val_accuracy: 0.8900\n",
      "Epoch 2022/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1985 - accuracy: 0.9425 - val_loss: 0.2979 - val_accuracy: 0.8900\n",
      "Epoch 2023/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1985 - accuracy: 0.9450 - val_loss: 0.2966 - val_accuracy: 0.8950\n",
      "Epoch 2024/3000\n",
      "800/800 [==============================] - 0s 135us/step - loss: 0.1991 - accuracy: 0.9400 - val_loss: 0.2956 - val_accuracy: 0.8900\n",
      "Epoch 2025/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2010 - accuracy: 0.92 - 0s 84us/step - loss: 0.1990 - accuracy: 0.9425 - val_loss: 0.2983 - val_accuracy: 0.8900\n",
      "Epoch 2026/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1986 - accuracy: 0.9463 - val_loss: 0.2957 - val_accuracy: 0.8950\n",
      "Epoch 2027/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1976 - accuracy: 0.9413 - val_loss: 0.2994 - val_accuracy: 0.8850\n",
      "Epoch 2028/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2544 - accuracy: 0.92 - 0s 85us/step - loss: 0.1984 - accuracy: 0.9438 - val_loss: 0.2954 - val_accuracy: 0.8950\n",
      "Epoch 2029/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.1991 - accuracy: 0.9425 - val_loss: 0.2978 - val_accuracy: 0.8900\n",
      "Epoch 2030/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.1975 - accuracy: 0.9450 - val_loss: 0.2967 - val_accuracy: 0.8900\n",
      "Epoch 2031/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.1990 - accuracy: 0.9425 - val_loss: 0.2979 - val_accuracy: 0.8900\n",
      "Epoch 2032/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1972 - accuracy: 0.9425 - val_loss: 0.2963 - val_accuracy: 0.8900\n",
      "Epoch 2033/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1984 - accuracy: 0.9425 - val_loss: 0.2951 - val_accuracy: 0.8900\n",
      "Epoch 2034/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.1983 - accuracy: 0.9425 - val_loss: 0.2958 - val_accuracy: 0.8900\n",
      "Epoch 2035/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1982 - accuracy: 0.9400 - val_loss: 0.2964 - val_accuracy: 0.8900\n",
      "Epoch 2036/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.1979 - accuracy: 0.9400 - val_loss: 0.2962 - val_accuracy: 0.8900\n",
      "Epoch 2037/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1981 - accuracy: 0.9450 - val_loss: 0.2974 - val_accuracy: 0.8900\n",
      "Epoch 2038/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1977 - accuracy: 0.9438 - val_loss: 0.2976 - val_accuracy: 0.8900\n",
      "Epoch 2039/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1976 - accuracy: 0.9425 - val_loss: 0.2985 - val_accuracy: 0.8850\n",
      "Epoch 2040/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.95 - 0s 88us/step - loss: 0.1972 - accuracy: 0.9450 - val_loss: 0.2960 - val_accuracy: 0.8950\n",
      "Epoch 2041/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1981 - accuracy: 0.9413 - val_loss: 0.2963 - val_accuracy: 0.8900\n",
      "Epoch 2042/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1967 - accuracy: 0.9413 - val_loss: 0.2980 - val_accuracy: 0.8900\n",
      "Epoch 2043/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1978 - accuracy: 0.9450 - val_loss: 0.2973 - val_accuracy: 0.8850\n",
      "Epoch 2044/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.1975 - accuracy: 0.9438 - val_loss: 0.2969 - val_accuracy: 0.8950\n",
      "Epoch 2045/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1765 - accuracy: 0.95 - 0s 121us/step - loss: 0.1968 - accuracy: 0.9450 - val_loss: 0.2965 - val_accuracy: 0.8850\n",
      "Epoch 2046/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.1965 - accuracy: 0.9425 - val_loss: 0.2980 - val_accuracy: 0.8900\n",
      "Epoch 2047/3000\n",
      "800/800 [==============================] - 0s 125us/step - loss: 0.1970 - accuracy: 0.9425 - val_loss: 0.2948 - val_accuracy: 0.8950\n",
      "Epoch 2048/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2072 - accuracy: 0.93 - 0s 96us/step - loss: 0.1965 - accuracy: 0.9425 - val_loss: 0.2956 - val_accuracy: 0.8900\n",
      "Epoch 2049/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.1962 - accuracy: 0.9438 - val_loss: 0.2962 - val_accuracy: 0.8950\n",
      "Epoch 2050/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.1964 - accuracy: 0.9425 - val_loss: 0.2943 - val_accuracy: 0.8950\n",
      "Epoch 2051/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1964 - accuracy: 0.9413 - val_loss: 0.2947 - val_accuracy: 0.8950\n",
      "Epoch 2052/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1969 - accuracy: 0.9413 - val_loss: 0.2960 - val_accuracy: 0.8950\n",
      "Epoch 2053/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1960 - accuracy: 0.94 - 0s 104us/step - loss: 0.1966 - accuracy: 0.9413 - val_loss: 0.2952 - val_accuracy: 0.8950\n",
      "Epoch 2054/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.1963 - accuracy: 0.9475 - val_loss: 0.2959 - val_accuracy: 0.8900\n",
      "Epoch 2055/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1956 - accuracy: 0.9488 - val_loss: 0.2985 - val_accuracy: 0.8850\n",
      "Epoch 2056/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2040 - accuracy: 0.94 - 0s 100us/step - loss: 0.1970 - accuracy: 0.9450 - val_loss: 0.2954 - val_accuracy: 0.8900\n",
      "Epoch 2057/3000\n",
      "800/800 [==============================] - 0s 134us/step - loss: 0.1969 - accuracy: 0.9425 - val_loss: 0.2965 - val_accuracy: 0.8850\n",
      "Epoch 2058/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1955 - accuracy: 0.9463 - val_loss: 0.2931 - val_accuracy: 0.8900\n",
      "Epoch 2059/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1961 - accuracy: 0.9438 - val_loss: 0.2962 - val_accuracy: 0.8950\n",
      "Epoch 2060/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1960 - accuracy: 0.9425 - val_loss: 0.2973 - val_accuracy: 0.8900\n",
      "Epoch 2061/3000\n",
      "800/800 [==============================] - 0s 144us/step - loss: 0.1954 - accuracy: 0.9438 - val_loss: 0.2964 - val_accuracy: 0.8850\n",
      "Epoch 2062/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1958 - accuracy: 0.9463 - val_loss: 0.2931 - val_accuracy: 0.8900\n",
      "Epoch 2063/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1951 - accuracy: 0.9425 - val_loss: 0.2958 - val_accuracy: 0.8950\n",
      "Epoch 2064/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1952 - accuracy: 0.95 - 0s 113us/step - loss: 0.1957 - accuracy: 0.9488 - val_loss: 0.2949 - val_accuracy: 0.8900\n",
      "Epoch 2065/3000\n",
      "800/800 [==============================] - 0s 131us/step - loss: 0.1956 - accuracy: 0.9425 - val_loss: 0.2964 - val_accuracy: 0.8850\n",
      "Epoch 2066/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.1958 - accuracy: 0.9463 - val_loss: 0.2939 - val_accuracy: 0.8900\n",
      "Epoch 2067/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.1951 - accuracy: 0.9438 - val_loss: 0.2968 - val_accuracy: 0.8900\n",
      "Epoch 2068/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1956 - accuracy: 0.95 - 0s 101us/step - loss: 0.1951 - accuracy: 0.9500 - val_loss: 0.2945 - val_accuracy: 0.8950\n",
      "Epoch 2069/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1955 - accuracy: 0.9413 - val_loss: 0.2936 - val_accuracy: 0.8950\n",
      "Epoch 2070/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.1956 - accuracy: 0.9425 - val_loss: 0.2961 - val_accuracy: 0.8850\n",
      "Epoch 2071/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1951 - accuracy: 0.9438 - val_loss: 0.2955 - val_accuracy: 0.8850\n",
      "Epoch 2072/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1949 - accuracy: 0.9425 - val_loss: 0.2939 - val_accuracy: 0.8950\n",
      "Epoch 2073/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1946 - accuracy: 0.9438 - val_loss: 0.2940 - val_accuracy: 0.8900\n",
      "Epoch 2074/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1950 - accuracy: 0.9438 - val_loss: 0.2936 - val_accuracy: 0.8900\n",
      "Epoch 2075/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1945 - accuracy: 0.9450 - val_loss: 0.2944 - val_accuracy: 0.8900\n",
      "Epoch 2076/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1944 - accuracy: 0.9450 - val_loss: 0.2936 - val_accuracy: 0.8800\n",
      "Epoch 2077/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1950 - accuracy: 0.9413 - val_loss: 0.2963 - val_accuracy: 0.8850\n",
      "Epoch 2078/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.1940 - accuracy: 0.9413 - val_loss: 0.2958 - val_accuracy: 0.8850\n",
      "Epoch 2079/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.1948 - accuracy: 0.9463 - val_loss: 0.2954 - val_accuracy: 0.8900\n",
      "Epoch 2080/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1946 - accuracy: 0.9450 - val_loss: 0.2931 - val_accuracy: 0.8900\n",
      "Epoch 2081/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.1945 - accuracy: 0.9425 - val_loss: 0.2948 - val_accuracy: 0.8850\n",
      "Epoch 2082/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1936 - accuracy: 0.9450 - val_loss: 0.2940 - val_accuracy: 0.8900\n",
      "Epoch 2083/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.1941 - accuracy: 0.9413 - val_loss: 0.2953 - val_accuracy: 0.8950\n",
      "Epoch 2084/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.1943 - accuracy: 0.9463 - val_loss: 0.2967 - val_accuracy: 0.8900\n",
      "Epoch 2085/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1945 - accuracy: 0.9438 - val_loss: 0.2952 - val_accuracy: 0.8900\n",
      "Epoch 2086/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1986 - accuracy: 0.94 - 0s 104us/step - loss: 0.1935 - accuracy: 0.9438 - val_loss: 0.2931 - val_accuracy: 0.8950\n",
      "Epoch 2087/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.1938 - accuracy: 0.9463 - val_loss: 0.2941 - val_accuracy: 0.8950\n",
      "Epoch 2088/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1940 - accuracy: 0.9438 - val_loss: 0.2953 - val_accuracy: 0.8900\n",
      "Epoch 2089/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.1939 - accuracy: 0.9450 - val_loss: 0.2937 - val_accuracy: 0.8900\n",
      "Epoch 2090/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.1941 - accuracy: 0.9450 - val_loss: 0.2946 - val_accuracy: 0.8900\n",
      "Epoch 2091/3000\n",
      "800/800 [==============================] - 0s 130us/step - loss: 0.1939 - accuracy: 0.9425 - val_loss: 0.2936 - val_accuracy: 0.8900\n",
      "Epoch 2092/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1454 - accuracy: 0.98 - 0s 90us/step - loss: 0.1938 - accuracy: 0.9438 - val_loss: 0.2950 - val_accuracy: 0.8900\n",
      "Epoch 2093/3000\n",
      "800/800 [==============================] - 0s 126us/step - loss: 0.1935 - accuracy: 0.9488 - val_loss: 0.2931 - val_accuracy: 0.8950\n",
      "Epoch 2094/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1935 - accuracy: 0.9450 - val_loss: 0.2927 - val_accuracy: 0.8950\n",
      "Epoch 2095/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.1929 - accuracy: 0.9425 - val_loss: 0.2931 - val_accuracy: 0.8950\n",
      "Epoch 2096/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1860 - accuracy: 0.94 - 0s 103us/step - loss: 0.1936 - accuracy: 0.9475 - val_loss: 0.2921 - val_accuracy: 0.8950\n",
      "Epoch 2097/3000\n",
      "800/800 [==============================] - 0s 126us/step - loss: 0.1930 - accuracy: 0.9413 - val_loss: 0.2929 - val_accuracy: 0.8950\n",
      "Epoch 2098/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1935 - accuracy: 0.9475 - val_loss: 0.2927 - val_accuracy: 0.8950\n",
      "Epoch 2099/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.1927 - accuracy: 0.9438 - val_loss: 0.2938 - val_accuracy: 0.8950\n",
      "Epoch 2100/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1918 - accuracy: 0.9425 - val_loss: 0.2919 - val_accuracy: 0.8950\n",
      "Epoch 2101/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1925 - accuracy: 0.9463 - val_loss: 0.2918 - val_accuracy: 0.8950\n",
      "Epoch 2102/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1929 - accuracy: 0.9463 - val_loss: 0.2924 - val_accuracy: 0.8950\n",
      "Epoch 2103/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1941 - accuracy: 0.9475 - val_loss: 0.2937 - val_accuracy: 0.8850\n",
      "Epoch 2104/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1924 - accuracy: 0.9438 - val_loss: 0.2932 - val_accuracy: 0.8900\n",
      "Epoch 2105/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1911 - accuracy: 0.94 - 0s 115us/step - loss: 0.1925 - accuracy: 0.9475 - val_loss: 0.2936 - val_accuracy: 0.8950\n",
      "Epoch 2106/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.1928 - accuracy: 0.9450 - val_loss: 0.2917 - val_accuracy: 0.8950\n",
      "Epoch 2107/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1923 - accuracy: 0.94 - 0s 113us/step - loss: 0.1928 - accuracy: 0.9463 - val_loss: 0.2911 - val_accuracy: 0.8950\n",
      "Epoch 2108/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.1919 - accuracy: 0.9475 - val_loss: 0.2936 - val_accuracy: 0.8950\n",
      "Epoch 2109/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1926 - accuracy: 0.9438 - val_loss: 0.2916 - val_accuracy: 0.8950\n",
      "Epoch 2110/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1915 - accuracy: 0.9400 - val_loss: 0.2924 - val_accuracy: 0.8950\n",
      "Epoch 2111/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1923 - accuracy: 0.94 - 0s 100us/step - loss: 0.1920 - accuracy: 0.9425 - val_loss: 0.2934 - val_accuracy: 0.8950\n",
      "Epoch 2112/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1920 - accuracy: 0.9475 - val_loss: 0.2904 - val_accuracy: 0.8950\n",
      "Epoch 2113/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.1923 - accuracy: 0.9475 - val_loss: 0.2904 - val_accuracy: 0.8950\n",
      "Epoch 2114/3000\n",
      "800/800 [==============================] - 0s 133us/step - loss: 0.1919 - accuracy: 0.9425 - val_loss: 0.2904 - val_accuracy: 0.8950\n",
      "Epoch 2115/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.1922 - accuracy: 0.9475 - val_loss: 0.2914 - val_accuracy: 0.8950\n",
      "Epoch 2116/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.1920 - accuracy: 0.9450 - val_loss: 0.2918 - val_accuracy: 0.8950\n",
      "Epoch 2117/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.1914 - accuracy: 0.9488 - val_loss: 0.2920 - val_accuracy: 0.8950\n",
      "Epoch 2118/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1918 - accuracy: 0.9450 - val_loss: 0.2949 - val_accuracy: 0.8900\n",
      "Epoch 2119/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.1913 - accuracy: 0.9475 - val_loss: 0.2949 - val_accuracy: 0.8900\n",
      "Epoch 2120/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.1909 - accuracy: 0.9450 - val_loss: 0.2942 - val_accuracy: 0.8900\n",
      "Epoch 2121/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.1921 - accuracy: 0.9425 - val_loss: 0.2910 - val_accuracy: 0.8950\n",
      "Epoch 2122/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1920 - accuracy: 0.9475 - val_loss: 0.2907 - val_accuracy: 0.8950\n",
      "Epoch 2123/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.1908 - accuracy: 0.9450 - val_loss: 0.2916 - val_accuracy: 0.8900\n",
      "Epoch 2124/3000\n",
      "800/800 [==============================] - 0s 125us/step - loss: 0.1911 - accuracy: 0.9438 - val_loss: 0.2899 - val_accuracy: 0.8950\n",
      "Epoch 2125/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.1908 - accuracy: 0.9450 - val_loss: 0.2890 - val_accuracy: 0.8950\n",
      "Epoch 2126/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.1912 - accuracy: 0.9425 - val_loss: 0.2914 - val_accuracy: 0.8950\n",
      "Epoch 2127/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1911 - accuracy: 0.9450 - val_loss: 0.2921 - val_accuracy: 0.8950\n",
      "Epoch 2128/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.1917 - accuracy: 0.9438 - val_loss: 0.2934 - val_accuracy: 0.8950\n",
      "Epoch 2129/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1843 - accuracy: 0.95 - 0s 108us/step - loss: 0.1910 - accuracy: 0.9488 - val_loss: 0.2925 - val_accuracy: 0.8950\n",
      "Epoch 2130/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1911 - accuracy: 0.9500 - val_loss: 0.2907 - val_accuracy: 0.8950\n",
      "Epoch 2131/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1909 - accuracy: 0.9438 - val_loss: 0.2907 - val_accuracy: 0.8900\n",
      "Epoch 2132/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1901 - accuracy: 0.9413 - val_loss: 0.2933 - val_accuracy: 0.8900\n",
      "Epoch 2133/3000\n",
      "800/800 [==============================] - 0s 130us/step - loss: 0.1901 - accuracy: 0.9475 - val_loss: 0.2911 - val_accuracy: 0.9000\n",
      "Epoch 2134/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.1906 - accuracy: 0.9475 - val_loss: 0.2901 - val_accuracy: 0.9000\n",
      "Epoch 2135/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1909 - accuracy: 0.94 - 0s 128us/step - loss: 0.1903 - accuracy: 0.9438 - val_loss: 0.2926 - val_accuracy: 0.8900\n",
      "Epoch 2136/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1906 - accuracy: 0.9500 - val_loss: 0.2915 - val_accuracy: 0.8950\n",
      "Epoch 2137/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.1898 - accuracy: 0.9513 - val_loss: 0.2892 - val_accuracy: 0.8950\n",
      "Epoch 2138/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1905 - accuracy: 0.9463 - val_loss: 0.2899 - val_accuracy: 0.8950\n",
      "Epoch 2139/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.1900 - accuracy: 0.9463 - val_loss: 0.2914 - val_accuracy: 0.8900\n",
      "Epoch 2140/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1901 - accuracy: 0.9463 - val_loss: 0.2913 - val_accuracy: 0.8950\n",
      "Epoch 2141/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.1905 - accuracy: 0.9450 - val_loss: 0.2914 - val_accuracy: 0.8950\n",
      "Epoch 2142/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1907 - accuracy: 0.9463 - val_loss: 0.2914 - val_accuracy: 0.8900\n",
      "Epoch 2143/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1896 - accuracy: 0.9438 - val_loss: 0.2899 - val_accuracy: 0.8950\n",
      "Epoch 2144/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.1895 - accuracy: 0.9463 - val_loss: 0.2900 - val_accuracy: 0.8950\n",
      "Epoch 2145/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1919 - accuracy: 0.94 - 0s 100us/step - loss: 0.1899 - accuracy: 0.9425 - val_loss: 0.2920 - val_accuracy: 0.8950\n",
      "Epoch 2146/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1897 - accuracy: 0.9513 - val_loss: 0.2885 - val_accuracy: 0.8950\n",
      "Epoch 2147/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2006 - accuracy: 0.94 - 0s 118us/step - loss: 0.1891 - accuracy: 0.9438 - val_loss: 0.2872 - val_accuracy: 0.8950\n",
      "Epoch 2148/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.1891 - accuracy: 0.9488 - val_loss: 0.2896 - val_accuracy: 0.8950\n",
      "Epoch 2149/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1913 - accuracy: 0.94 - 0s 104us/step - loss: 0.1894 - accuracy: 0.9475 - val_loss: 0.2901 - val_accuracy: 0.8950\n",
      "Epoch 2150/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.1897 - accuracy: 0.9438 - val_loss: 0.2895 - val_accuracy: 0.8950\n",
      "Epoch 2151/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.1893 - accuracy: 0.9488 - val_loss: 0.2876 - val_accuracy: 0.8950\n",
      "Epoch 2152/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1890 - accuracy: 0.9475 - val_loss: 0.2885 - val_accuracy: 0.8950\n",
      "Epoch 2153/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1888 - accuracy: 0.9450 - val_loss: 0.2895 - val_accuracy: 0.9000\n",
      "Epoch 2154/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.1895 - accuracy: 0.9438 - val_loss: 0.2903 - val_accuracy: 0.8950\n",
      "Epoch 2155/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.1899 - accuracy: 0.9475 - val_loss: 0.2889 - val_accuracy: 0.8950\n",
      "Epoch 2156/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1891 - accuracy: 0.9438 - val_loss: 0.2901 - val_accuracy: 0.8900\n",
      "Epoch 2157/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1891 - accuracy: 0.9450 - val_loss: 0.2910 - val_accuracy: 0.8950\n",
      "Epoch 2158/3000\n",
      "800/800 [==============================] - 0s 148us/step - loss: 0.1888 - accuracy: 0.9438 - val_loss: 0.2924 - val_accuracy: 0.8900\n",
      "Epoch 2159/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.1885 - accuracy: 0.9488 - val_loss: 0.2917 - val_accuracy: 0.8950\n",
      "Epoch 2160/3000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.1886 - accuracy: 0.9513 - val_loss: 0.2883 - val_accuracy: 0.8950\n",
      "Epoch 2161/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.1889 - accuracy: 0.9475 - val_loss: 0.2892 - val_accuracy: 0.8950\n",
      "Epoch 2162/3000\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.1887 - accuracy: 0.9450 - val_loss: 0.2901 - val_accuracy: 0.8950\n",
      "Epoch 2163/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.94 - 0s 236us/step - loss: 0.1886 - accuracy: 0.9463 - val_loss: 0.2871 - val_accuracy: 0.8950\n",
      "Epoch 2164/3000\n",
      "800/800 [==============================] - 0s 149us/step - loss: 0.1880 - accuracy: 0.9450 - val_loss: 0.2897 - val_accuracy: 0.8950\n",
      "Epoch 2165/3000\n",
      "800/800 [==============================] - 0s 338us/step - loss: 0.1878 - accuracy: 0.9438 - val_loss: 0.2931 - val_accuracy: 0.8900\n",
      "Epoch 2166/3000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.1876 - accuracy: 0.9463 - val_loss: 0.2901 - val_accuracy: 0.8900\n",
      "Epoch 2167/3000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 0.1887 - accuracy: 0.9475 - val_loss: 0.2895 - val_accuracy: 0.8950\n",
      "Epoch 2168/3000\n",
      "800/800 [==============================] - 0s 245us/step - loss: 0.1884 - accuracy: 0.9463 - val_loss: 0.2900 - val_accuracy: 0.8950\n",
      "Epoch 2169/3000\n",
      "800/800 [==============================] - 0s 129us/step - loss: 0.1885 - accuracy: 0.9425 - val_loss: 0.2872 - val_accuracy: 0.8950\n",
      "Epoch 2170/3000\n",
      "800/800 [==============================] - 0s 133us/step - loss: 0.1876 - accuracy: 0.9463 - val_loss: 0.2899 - val_accuracy: 0.8950\n",
      "Epoch 2171/3000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.1883 - accuracy: 0.9463 - val_loss: 0.2896 - val_accuracy: 0.8950\n",
      "Epoch 2172/3000\n",
      "800/800 [==============================] - 0s 158us/step - loss: 0.1875 - accuracy: 0.9475 - val_loss: 0.2890 - val_accuracy: 0.8950\n",
      "Epoch 2173/3000\n",
      "800/800 [==============================] - 0s 216us/step - loss: 0.1882 - accuracy: 0.9463 - val_loss: 0.2893 - val_accuracy: 0.8950\n",
      "Epoch 2174/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1881 - accuracy: 0.9463 - val_loss: 0.2890 - val_accuracy: 0.8950\n",
      "Epoch 2175/3000\n",
      "800/800 [==============================] - 0s 130us/step - loss: 0.1875 - accuracy: 0.9450 - val_loss: 0.2892 - val_accuracy: 0.8950\n",
      "Epoch 2176/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1874 - accuracy: 0.9488 - val_loss: 0.2887 - val_accuracy: 0.8950\n",
      "Epoch 2177/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1880 - accuracy: 0.9450 - val_loss: 0.2902 - val_accuracy: 0.8900\n",
      "Epoch 2178/3000\n",
      "800/800 [==============================] - 0s 124us/step - loss: 0.1871 - accuracy: 0.9488 - val_loss: 0.2878 - val_accuracy: 0.8950\n",
      "Epoch 2179/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1858 - accuracy: 0.93 - 0s 85us/step - loss: 0.1874 - accuracy: 0.9475 - val_loss: 0.2889 - val_accuracy: 0.8950\n",
      "Epoch 2180/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.1874 - accuracy: 0.9475 - val_loss: 0.2873 - val_accuracy: 0.8950\n",
      "Epoch 2181/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1869 - accuracy: 0.9450 - val_loss: 0.2903 - val_accuracy: 0.8900\n",
      "Epoch 2182/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1877 - accuracy: 0.9463 - val_loss: 0.2873 - val_accuracy: 0.8950\n",
      "Epoch 2183/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1870 - accuracy: 0.9475 - val_loss: 0.2881 - val_accuracy: 0.8950\n",
      "Epoch 2184/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1873 - accuracy: 0.9500 - val_loss: 0.2881 - val_accuracy: 0.8950\n",
      "Epoch 2185/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1868 - accuracy: 0.9475 - val_loss: 0.2894 - val_accuracy: 0.8950\n",
      "Epoch 2186/3000\n",
      "800/800 [==============================] - 0s 136us/step - loss: 0.1870 - accuracy: 0.9475 - val_loss: 0.2878 - val_accuracy: 0.8950\n",
      "Epoch 2187/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1871 - accuracy: 0.9475 - val_loss: 0.2864 - val_accuracy: 0.8950\n",
      "Epoch 2188/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.1866 - accuracy: 0.9475 - val_loss: 0.2891 - val_accuracy: 0.8900\n",
      "Epoch 2189/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.1868 - accuracy: 0.9475 - val_loss: 0.2901 - val_accuracy: 0.8900\n",
      "Epoch 2190/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1862 - accuracy: 0.9488 - val_loss: 0.2884 - val_accuracy: 0.8950\n",
      "Epoch 2191/3000\n",
      "800/800 [==============================] - 0s 123us/step - loss: 0.1862 - accuracy: 0.9450 - val_loss: 0.2900 - val_accuracy: 0.8950\n",
      "Epoch 2192/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.96 - ETA: 0s - loss: 0.1736 - accuracy: 0.94 - 0s 119us/step - loss: 0.1870 - accuracy: 0.9463 - val_loss: 0.2894 - val_accuracy: 0.8950\n",
      "Epoch 2193/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1863 - accuracy: 0.9500 - val_loss: 0.2868 - val_accuracy: 0.8950\n",
      "Epoch 2194/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1850 - accuracy: 0.9500 - val_loss: 0.2879 - val_accuracy: 0.9000\n",
      "Epoch 2195/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1871 - accuracy: 0.9463 - val_loss: 0.2868 - val_accuracy: 0.8950\n",
      "Epoch 2196/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1860 - accuracy: 0.9463 - val_loss: 0.2855 - val_accuracy: 0.8950\n",
      "Epoch 2197/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1860 - accuracy: 0.9488 - val_loss: 0.2856 - val_accuracy: 0.8950\n",
      "Epoch 2198/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1855 - accuracy: 0.9513 - val_loss: 0.2907 - val_accuracy: 0.8800\n",
      "Epoch 2199/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2120 - accuracy: 0.90 - 0s 83us/step - loss: 0.1866 - accuracy: 0.9475 - val_loss: 0.2894 - val_accuracy: 0.8950\n",
      "Epoch 2200/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1860 - accuracy: 0.9475 - val_loss: 0.2882 - val_accuracy: 0.8950\n",
      "Epoch 2201/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1863 - accuracy: 0.9513 - val_loss: 0.2859 - val_accuracy: 0.8950\n",
      "Epoch 2202/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.1856 - accuracy: 0.9475 - val_loss: 0.2873 - val_accuracy: 0.8950\n",
      "Epoch 2203/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1859 - accuracy: 0.9500 - val_loss: 0.2879 - val_accuracy: 0.8950\n",
      "Epoch 2204/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1807 - accuracy: 0.95 - 0s 111us/step - loss: 0.1865 - accuracy: 0.9475 - val_loss: 0.2866 - val_accuracy: 0.8950\n",
      "Epoch 2205/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1852 - accuracy: 0.9450 - val_loss: 0.2870 - val_accuracy: 0.8950\n",
      "Epoch 2206/3000\n",
      "800/800 [==============================] - 0s 124us/step - loss: 0.1856 - accuracy: 0.9500 - val_loss: 0.2870 - val_accuracy: 0.8950\n",
      "Epoch 2207/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1860 - accuracy: 0.9463 - val_loss: 0.2871 - val_accuracy: 0.8950\n",
      "Epoch 2208/3000\n",
      "800/800 [==============================] - 0s 139us/step - loss: 0.1850 - accuracy: 0.9475 - val_loss: 0.2872 - val_accuracy: 0.8950\n",
      "Epoch 2209/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1860 - accuracy: 0.9500 - val_loss: 0.2848 - val_accuracy: 0.8950\n",
      "Epoch 2210/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.1856 - accuracy: 0.9450 - val_loss: 0.2870 - val_accuracy: 0.8950\n",
      "Epoch 2211/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1848 - accuracy: 0.9500 - val_loss: 0.2875 - val_accuracy: 0.8950\n",
      "Epoch 2212/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1845 - accuracy: 0.9475 - val_loss: 0.2889 - val_accuracy: 0.8850\n",
      "Epoch 2213/3000\n",
      "800/800 [==============================] - 0s 123us/step - loss: 0.1852 - accuracy: 0.9513 - val_loss: 0.2871 - val_accuracy: 0.8950\n",
      "Epoch 2214/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1855 - accuracy: 0.9475 - val_loss: 0.2871 - val_accuracy: 0.8950\n",
      "Epoch 2215/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.1851 - accuracy: 0.9488 - val_loss: 0.2869 - val_accuracy: 0.8950\n",
      "Epoch 2216/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.1839 - accuracy: 0.9463 - val_loss: 0.2886 - val_accuracy: 0.8950\n",
      "Epoch 2217/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.1860 - accuracy: 0.9450 - val_loss: 0.2873 - val_accuracy: 0.8950\n",
      "Epoch 2218/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1851 - accuracy: 0.9488 - val_loss: 0.2849 - val_accuracy: 0.8950\n",
      "Epoch 2219/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1850 - accuracy: 0.9488 - val_loss: 0.2881 - val_accuracy: 0.8950\n",
      "Epoch 2220/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1850 - accuracy: 0.9438 - val_loss: 0.2848 - val_accuracy: 0.8950\n",
      "Epoch 2221/3000\n",
      "800/800 [==============================] - 0s 126us/step - loss: 0.1847 - accuracy: 0.9475 - val_loss: 0.2850 - val_accuracy: 0.8950\n",
      "Epoch 2222/3000\n",
      "800/800 [==============================] - 0s 126us/step - loss: 0.1844 - accuracy: 0.9500 - val_loss: 0.2835 - val_accuracy: 0.9000\n",
      "Epoch 2223/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1849 - accuracy: 0.9463 - val_loss: 0.2861 - val_accuracy: 0.8950\n",
      "Epoch 2224/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1841 - accuracy: 0.9488 - val_loss: 0.2850 - val_accuracy: 0.8950\n",
      "Epoch 2225/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1840 - accuracy: 0.9488 - val_loss: 0.2866 - val_accuracy: 0.8950\n",
      "Epoch 2226/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1849 - accuracy: 0.9475 - val_loss: 0.2875 - val_accuracy: 0.8950\n",
      "Epoch 2227/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1845 - accuracy: 0.9500 - val_loss: 0.2854 - val_accuracy: 0.8950\n",
      "Epoch 2228/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1841 - accuracy: 0.9488 - val_loss: 0.2864 - val_accuracy: 0.8950\n",
      "Epoch 2229/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1853 - accuracy: 0.95 - 0s 100us/step - loss: 0.1849 - accuracy: 0.9500 - val_loss: 0.2850 - val_accuracy: 0.8950\n",
      "Epoch 2230/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1841 - accuracy: 0.9475 - val_loss: 0.2866 - val_accuracy: 0.8950\n",
      "Epoch 2231/3000\n",
      "800/800 [==============================] - 0s 126us/step - loss: 0.1841 - accuracy: 0.9488 - val_loss: 0.2861 - val_accuracy: 0.8950\n",
      "Epoch 2232/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.1838 - accuracy: 0.9475 - val_loss: 0.2855 - val_accuracy: 0.8950\n",
      "Epoch 2233/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1840 - accuracy: 0.9475 - val_loss: 0.2872 - val_accuracy: 0.8950\n",
      "Epoch 2234/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1843 - accuracy: 0.9488 - val_loss: 0.2863 - val_accuracy: 0.8950\n",
      "Epoch 2235/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.1837 - accuracy: 0.9475 - val_loss: 0.2871 - val_accuracy: 0.8950\n",
      "Epoch 2236/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.1836 - accuracy: 0.9463 - val_loss: 0.2852 - val_accuracy: 0.8950\n",
      "Epoch 2237/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1832 - accuracy: 0.9500 - val_loss: 0.2845 - val_accuracy: 0.8950\n",
      "Epoch 2238/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1839 - accuracy: 0.9488 - val_loss: 0.2851 - val_accuracy: 0.8950\n",
      "Epoch 2239/3000\n",
      "800/800 [==============================] - 0s 124us/step - loss: 0.1832 - accuracy: 0.9475 - val_loss: 0.2854 - val_accuracy: 0.8950\n",
      "Epoch 2240/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.1831 - accuracy: 0.9488 - val_loss: 0.2843 - val_accuracy: 0.8950\n",
      "Epoch 2241/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1832 - accuracy: 0.9488 - val_loss: 0.2870 - val_accuracy: 0.8950\n",
      "Epoch 2242/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1832 - accuracy: 0.9475 - val_loss: 0.2864 - val_accuracy: 0.8950\n",
      "Epoch 2243/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1830 - accuracy: 0.9463 - val_loss: 0.2852 - val_accuracy: 0.8950\n",
      "Epoch 2244/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1925 - accuracy: 0.94 - 0s 121us/step - loss: 0.1831 - accuracy: 0.9475 - val_loss: 0.2848 - val_accuracy: 0.8950\n",
      "Epoch 2245/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1836 - accuracy: 0.9463 - val_loss: 0.2837 - val_accuracy: 0.8950\n",
      "Epoch 2246/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1830 - accuracy: 0.9513 - val_loss: 0.2845 - val_accuracy: 0.8950\n",
      "Epoch 2247/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1831 - accuracy: 0.9500 - val_loss: 0.2852 - val_accuracy: 0.8950\n",
      "Epoch 2248/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1830 - accuracy: 0.9525 - val_loss: 0.2870 - val_accuracy: 0.8950\n",
      "Epoch 2249/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1826 - accuracy: 0.9513 - val_loss: 0.2860 - val_accuracy: 0.8950\n",
      "Epoch 2250/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.1820 - accuracy: 0.9500 - val_loss: 0.2854 - val_accuracy: 0.9000\n",
      "Epoch 2251/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1832 - accuracy: 0.9500 - val_loss: 0.2863 - val_accuracy: 0.8950\n",
      "Epoch 2252/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1826 - accuracy: 0.9500 - val_loss: 0.2858 - val_accuracy: 0.8950\n",
      "Epoch 2253/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1824 - accuracy: 0.9500 - val_loss: 0.2846 - val_accuracy: 0.8950\n",
      "Epoch 2254/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.1828 - accuracy: 0.9463 - val_loss: 0.2847 - val_accuracy: 0.8950\n",
      "Epoch 2255/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1819 - accuracy: 0.9500 - val_loss: 0.2855 - val_accuracy: 0.8950\n",
      "Epoch 2256/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.1825 - accuracy: 0.9475 - val_loss: 0.2843 - val_accuracy: 0.8950\n",
      "Epoch 2257/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.1826 - accuracy: 0.9500 - val_loss: 0.2840 - val_accuracy: 0.8950\n",
      "Epoch 2258/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1814 - accuracy: 0.9500 - val_loss: 0.2868 - val_accuracy: 0.8950\n",
      "Epoch 2259/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1829 - accuracy: 0.9500 - val_loss: 0.2845 - val_accuracy: 0.8950\n",
      "Epoch 2260/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1818 - accuracy: 0.9513 - val_loss: 0.2854 - val_accuracy: 0.8950\n",
      "Epoch 2261/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1821 - accuracy: 0.9513 - val_loss: 0.2863 - val_accuracy: 0.8900\n",
      "Epoch 2262/3000\n",
      "800/800 [==============================] - 0s 126us/step - loss: 0.1815 - accuracy: 0.9525 - val_loss: 0.2838 - val_accuracy: 0.8950\n",
      "Epoch 2263/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1858 - accuracy: 0.94 - 0s 104us/step - loss: 0.1814 - accuracy: 0.9488 - val_loss: 0.2851 - val_accuracy: 0.8950\n",
      "Epoch 2264/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.1820 - accuracy: 0.9513 - val_loss: 0.2864 - val_accuracy: 0.9000\n",
      "Epoch 2265/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1851 - accuracy: 0.94 - 0s 101us/step - loss: 0.1822 - accuracy: 0.9463 - val_loss: 0.2862 - val_accuracy: 0.8950\n",
      "Epoch 2266/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.1816 - accuracy: 0.9500 - val_loss: 0.2856 - val_accuracy: 0.8950\n",
      "Epoch 2267/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.1818 - accuracy: 0.9525 - val_loss: 0.2842 - val_accuracy: 0.8950\n",
      "Epoch 2268/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1819 - accuracy: 0.9513 - val_loss: 0.2857 - val_accuracy: 0.8900\n",
      "Epoch 2269/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1816 - accuracy: 0.9488 - val_loss: 0.2840 - val_accuracy: 0.8950\n",
      "Epoch 2270/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1242 - accuracy: 0.98 - 0s 88us/step - loss: 0.1821 - accuracy: 0.9475 - val_loss: 0.2851 - val_accuracy: 0.8950\n",
      "Epoch 2271/3000\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.1810 - accuracy: 0.9500 - val_loss: 0.2862 - val_accuracy: 0.8900\n",
      "Epoch 2272/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1819 - accuracy: 0.9488 - val_loss: 0.2855 - val_accuracy: 0.8950\n",
      "Epoch 2273/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1815 - accuracy: 0.9463 - val_loss: 0.2838 - val_accuracy: 0.8950\n",
      "Epoch 2274/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.1806 - accuracy: 0.9475 - val_loss: 0.2849 - val_accuracy: 0.8950\n",
      "Epoch 2275/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1843 - accuracy: 0.94 - 0s 106us/step - loss: 0.1812 - accuracy: 0.9513 - val_loss: 0.2828 - val_accuracy: 0.8950\n",
      "Epoch 2276/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.1810 - accuracy: 0.9488 - val_loss: 0.2828 - val_accuracy: 0.8950\n",
      "Epoch 2277/3000\n",
      "800/800 [==============================] - 0s 126us/step - loss: 0.1811 - accuracy: 0.9488 - val_loss: 0.2829 - val_accuracy: 0.8950\n",
      "Epoch 2278/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1802 - accuracy: 0.9513 - val_loss: 0.2844 - val_accuracy: 0.8950\n",
      "Epoch 2279/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1799 - accuracy: 0.9500 - val_loss: 0.2835 - val_accuracy: 0.8950\n",
      "Epoch 2280/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1811 - accuracy: 0.9525 - val_loss: 0.2828 - val_accuracy: 0.8950\n",
      "Epoch 2281/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1626 - accuracy: 0.96 - 0s 81us/step - loss: 0.1804 - accuracy: 0.9513 - val_loss: 0.2836 - val_accuracy: 0.8950\n",
      "Epoch 2282/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.1809 - accuracy: 0.9525 - val_loss: 0.2855 - val_accuracy: 0.8950\n",
      "Epoch 2283/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1801 - accuracy: 0.9513 - val_loss: 0.2827 - val_accuracy: 0.8950\n",
      "Epoch 2284/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1806 - accuracy: 0.9500 - val_loss: 0.2827 - val_accuracy: 0.8950\n",
      "Epoch 2285/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1800 - accuracy: 0.9488 - val_loss: 0.2855 - val_accuracy: 0.9000\n",
      "Epoch 2286/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.1809 - accuracy: 0.9488 - val_loss: 0.2839 - val_accuracy: 0.8950\n",
      "Epoch 2287/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1802 - accuracy: 0.9463 - val_loss: 0.2850 - val_accuracy: 0.8950\n",
      "Epoch 2288/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.1799 - accuracy: 0.9513 - val_loss: 0.2833 - val_accuracy: 0.8950\n",
      "Epoch 2289/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1804 - accuracy: 0.9488 - val_loss: 0.2842 - val_accuracy: 0.8950\n",
      "Epoch 2290/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1797 - accuracy: 0.9488 - val_loss: 0.2841 - val_accuracy: 0.9000\n",
      "Epoch 2291/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1801 - accuracy: 0.9500 - val_loss: 0.2833 - val_accuracy: 0.8950\n",
      "Epoch 2292/3000\n",
      "800/800 [==============================] - 0s 134us/step - loss: 0.1805 - accuracy: 0.9513 - val_loss: 0.2814 - val_accuracy: 0.8950\n",
      "Epoch 2293/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1851 - accuracy: 0.94 - 0s 109us/step - loss: 0.1797 - accuracy: 0.9513 - val_loss: 0.2835 - val_accuracy: 0.8950\n",
      "Epoch 2294/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1795 - accuracy: 0.9513 - val_loss: 0.2821 - val_accuracy: 0.8950\n",
      "Epoch 2295/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.1795 - accuracy: 0.9488 - val_loss: 0.2847 - val_accuracy: 0.8950\n",
      "Epoch 2296/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1799 - accuracy: 0.9488 - val_loss: 0.2830 - val_accuracy: 0.8950\n",
      "Epoch 2297/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1798 - accuracy: 0.9450 - val_loss: 0.2834 - val_accuracy: 0.8950\n",
      "Epoch 2298/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.1796 - accuracy: 0.9488 - val_loss: 0.2835 - val_accuracy: 0.8950\n",
      "Epoch 2299/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1797 - accuracy: 0.9525 - val_loss: 0.2820 - val_accuracy: 0.8950\n",
      "Epoch 2300/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.1795 - accuracy: 0.9488 - val_loss: 0.2815 - val_accuracy: 0.8950\n",
      "Epoch 2301/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1791 - accuracy: 0.9500 - val_loss: 0.2838 - val_accuracy: 0.8950\n",
      "Epoch 2302/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1791 - accuracy: 0.9513 - val_loss: 0.2819 - val_accuracy: 0.8950\n",
      "Epoch 2303/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1795 - accuracy: 0.9500 - val_loss: 0.2820 - val_accuracy: 0.8950\n",
      "Epoch 2304/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1791 - accuracy: 0.9513 - val_loss: 0.2837 - val_accuracy: 0.8950\n",
      "Epoch 2305/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1818 - accuracy: 0.94 - 0s 109us/step - loss: 0.1789 - accuracy: 0.9500 - val_loss: 0.2816 - val_accuracy: 0.8950\n",
      "Epoch 2306/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1796 - accuracy: 0.9513 - val_loss: 0.2826 - val_accuracy: 0.8950\n",
      "Epoch 2307/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.1788 - accuracy: 0.9500 - val_loss: 0.2855 - val_accuracy: 0.8900\n",
      "Epoch 2308/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1797 - accuracy: 0.9513 - val_loss: 0.2814 - val_accuracy: 0.8950\n",
      "Epoch 2309/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1787 - accuracy: 0.9525 - val_loss: 0.2804 - val_accuracy: 0.8950\n",
      "Epoch 2310/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.1793 - accuracy: 0.9500 - val_loss: 0.2804 - val_accuracy: 0.8950\n",
      "Epoch 2311/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.1787 - accuracy: 0.9525 - val_loss: 0.2834 - val_accuracy: 0.8950\n",
      "Epoch 2312/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1840 - accuracy: 0.95 - 0s 116us/step - loss: 0.1787 - accuracy: 0.9538 - val_loss: 0.2829 - val_accuracy: 0.8900\n",
      "Epoch 2313/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.1790 - accuracy: 0.9475 - val_loss: 0.2831 - val_accuracy: 0.8950\n",
      "Epoch 2314/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1785 - accuracy: 0.9525 - val_loss: 0.2829 - val_accuracy: 0.8950\n",
      "Epoch 2315/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.1790 - accuracy: 0.9525 - val_loss: 0.2817 - val_accuracy: 0.8950\n",
      "Epoch 2316/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1782 - accuracy: 0.9488 - val_loss: 0.2838 - val_accuracy: 0.8950\n",
      "Epoch 2317/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1769 - accuracy: 0.95 - 0s 103us/step - loss: 0.1792 - accuracy: 0.9525 - val_loss: 0.2844 - val_accuracy: 0.8900\n",
      "Epoch 2318/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1781 - accuracy: 0.9513 - val_loss: 0.2828 - val_accuracy: 0.8950\n",
      "Epoch 2319/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.1785 - accuracy: 0.9500 - val_loss: 0.2842 - val_accuracy: 0.8950\n",
      "Epoch 2320/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1783 - accuracy: 0.95 - 0s 106us/step - loss: 0.1789 - accuracy: 0.9475 - val_loss: 0.2808 - val_accuracy: 0.8950\n",
      "Epoch 2321/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1705 - accuracy: 0.95 - 0s 124us/step - loss: 0.1785 - accuracy: 0.9463 - val_loss: 0.2825 - val_accuracy: 0.8900\n",
      "Epoch 2322/3000\n",
      "800/800 [==============================] - 0s 149us/step - loss: 0.1781 - accuracy: 0.9513 - val_loss: 0.2835 - val_accuracy: 0.8950\n",
      "Epoch 2323/3000\n",
      "800/800 [==============================] - 0s 286us/step - loss: 0.1783 - accuracy: 0.9538 - val_loss: 0.2799 - val_accuracy: 0.8950\n",
      "Epoch 2324/3000\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.1785 - accuracy: 0.9513 - val_loss: 0.2824 - val_accuracy: 0.8950\n",
      "Epoch 2325/3000\n",
      "800/800 [==============================] - 0s 265us/step - loss: 0.1775 - accuracy: 0.9513 - val_loss: 0.2827 - val_accuracy: 0.8950\n",
      "Epoch 2326/3000\n",
      "800/800 [==============================] - 0s 481us/step - loss: 0.1783 - accuracy: 0.9488 - val_loss: 0.2831 - val_accuracy: 0.8950\n",
      "Epoch 2327/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.95 - 0s 213us/step - loss: 0.1776 - accuracy: 0.9500 - val_loss: 0.2809 - val_accuracy: 0.8950\n",
      "Epoch 2328/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1772 - accuracy: 0.95 - 0s 164us/step - loss: 0.1773 - accuracy: 0.9513 - val_loss: 0.2810 - val_accuracy: 0.8950\n",
      "Epoch 2329/3000\n",
      "800/800 [==============================] - 0s 150us/step - loss: 0.1776 - accuracy: 0.9525 - val_loss: 0.2800 - val_accuracy: 0.8950\n",
      "Epoch 2330/3000\n",
      "800/800 [==============================] - 0s 134us/step - loss: 0.1782 - accuracy: 0.9513 - val_loss: 0.2816 - val_accuracy: 0.8950\n",
      "Epoch 2331/3000\n",
      "800/800 [==============================] - 0s 170us/step - loss: 0.1774 - accuracy: 0.9488 - val_loss: 0.2806 - val_accuracy: 0.8950\n",
      "Epoch 2332/3000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 0.1773 - accuracy: 0.9500 - val_loss: 0.2791 - val_accuracy: 0.9000\n",
      "Epoch 2333/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1777 - accuracy: 0.94 - 0s 230us/step - loss: 0.1774 - accuracy: 0.9500 - val_loss: 0.2822 - val_accuracy: 0.8950\n",
      "Epoch 2334/3000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.1773 - accuracy: 0.9500 - val_loss: 0.2834 - val_accuracy: 0.8900\n",
      "Epoch 2335/3000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.1772 - accuracy: 0.9500 - val_loss: 0.2784 - val_accuracy: 0.9000\n",
      "Epoch 2336/3000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 0.1773 - accuracy: 0.9513 - val_loss: 0.2811 - val_accuracy: 0.8950\n",
      "Epoch 2337/3000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 0.1767 - accuracy: 0.9500 - val_loss: 0.2815 - val_accuracy: 0.8950\n",
      "Epoch 2338/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1771 - accuracy: 0.9538 - val_loss: 0.2787 - val_accuracy: 0.9000\n",
      "Epoch 2339/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1705 - accuracy: 0.95 - 0s 129us/step - loss: 0.1777 - accuracy: 0.9488 - val_loss: 0.2789 - val_accuracy: 0.8950\n",
      "Epoch 2340/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1762 - accuracy: 0.9488 - val_loss: 0.2796 - val_accuracy: 0.8950\n",
      "Epoch 2341/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1740 - accuracy: 0.94 - 0s 105us/step - loss: 0.1776 - accuracy: 0.9488 - val_loss: 0.2797 - val_accuracy: 0.8950\n",
      "Epoch 2342/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1772 - accuracy: 0.9500 - val_loss: 0.2798 - val_accuracy: 0.8950\n",
      "Epoch 2343/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.1771 - accuracy: 0.9513 - val_loss: 0.2829 - val_accuracy: 0.8950\n",
      "Epoch 2344/3000\n",
      "800/800 [==============================] - 0s 133us/step - loss: 0.1767 - accuracy: 0.9525 - val_loss: 0.2826 - val_accuracy: 0.9000\n",
      "Epoch 2345/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1783 - accuracy: 0.95 - 0s 100us/step - loss: 0.1770 - accuracy: 0.9513 - val_loss: 0.2827 - val_accuracy: 0.8950\n",
      "Epoch 2346/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1738 - accuracy: 0.95 - 0s 104us/step - loss: 0.1770 - accuracy: 0.9513 - val_loss: 0.2796 - val_accuracy: 0.8950\n",
      "Epoch 2347/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.1765 - accuracy: 0.9513 - val_loss: 0.2825 - val_accuracy: 0.8950\n",
      "Epoch 2348/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1765 - accuracy: 0.9513 - val_loss: 0.2818 - val_accuracy: 0.8950\n",
      "Epoch 2349/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1763 - accuracy: 0.9488 - val_loss: 0.2817 - val_accuracy: 0.8950\n",
      "Epoch 2350/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1764 - accuracy: 0.9513 - val_loss: 0.2824 - val_accuracy: 0.9000\n",
      "Epoch 2351/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1744 - accuracy: 0.95 - 0s 120us/step - loss: 0.1760 - accuracy: 0.9513 - val_loss: 0.2810 - val_accuracy: 0.8950\n",
      "Epoch 2352/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.1765 - accuracy: 0.9513 - val_loss: 0.2824 - val_accuracy: 0.8950\n",
      "Epoch 2353/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.1760 - accuracy: 0.9538 - val_loss: 0.2796 - val_accuracy: 0.8950\n",
      "Epoch 2354/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.1767 - accuracy: 0.9513 - val_loss: 0.2805 - val_accuracy: 0.8950\n",
      "Epoch 2355/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1764 - accuracy: 0.9500 - val_loss: 0.2802 - val_accuracy: 0.8950\n",
      "Epoch 2356/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1760 - accuracy: 0.9550 - val_loss: 0.2799 - val_accuracy: 0.8950\n",
      "Epoch 2357/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1759 - accuracy: 0.9525 - val_loss: 0.2824 - val_accuracy: 0.8900\n",
      "Epoch 2358/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1759 - accuracy: 0.9550 - val_loss: 0.2799 - val_accuracy: 0.8950\n",
      "Epoch 2359/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1764 - accuracy: 0.9475 - val_loss: 0.2840 - val_accuracy: 0.8950\n",
      "Epoch 2360/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1760 - accuracy: 0.9550 - val_loss: 0.2819 - val_accuracy: 0.9000\n",
      "Epoch 2361/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1763 - accuracy: 0.9488 - val_loss: 0.2833 - val_accuracy: 0.9000\n",
      "Epoch 2362/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1689 - accuracy: 0.95 - 0s 106us/step - loss: 0.1757 - accuracy: 0.9525 - val_loss: 0.2799 - val_accuracy: 0.8950\n",
      "Epoch 2363/3000\n",
      "800/800 [==============================] - 0s 128us/step - loss: 0.1758 - accuracy: 0.9525 - val_loss: 0.2790 - val_accuracy: 0.9000\n",
      "Epoch 2364/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1762 - accuracy: 0.9488 - val_loss: 0.2799 - val_accuracy: 0.8950\n",
      "Epoch 2365/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1750 - accuracy: 0.9513 - val_loss: 0.2799 - val_accuracy: 0.8950\n",
      "Epoch 2366/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1754 - accuracy: 0.9538 - val_loss: 0.2789 - val_accuracy: 0.8950\n",
      "Epoch 2367/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1756 - accuracy: 0.9525 - val_loss: 0.2786 - val_accuracy: 0.8950\n",
      "Epoch 2368/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1761 - accuracy: 0.9475 - val_loss: 0.2788 - val_accuracy: 0.8950\n",
      "Epoch 2369/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.1756 - accuracy: 0.9525 - val_loss: 0.2788 - val_accuracy: 0.8950\n",
      "Epoch 2370/3000\n",
      "800/800 [==============================] - 0s 126us/step - loss: 0.1748 - accuracy: 0.9525 - val_loss: 0.2780 - val_accuracy: 0.8950\n",
      "Epoch 2371/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1750 - accuracy: 0.9538 - val_loss: 0.2796 - val_accuracy: 0.8950\n",
      "Epoch 2372/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1754 - accuracy: 0.9538 - val_loss: 0.2792 - val_accuracy: 0.8950\n",
      "Epoch 2373/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1751 - accuracy: 0.9513 - val_loss: 0.2787 - val_accuracy: 0.8950\n",
      "Epoch 2374/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1807 - accuracy: 0.94 - 0s 116us/step - loss: 0.1751 - accuracy: 0.9513 - val_loss: 0.2822 - val_accuracy: 0.9000\n",
      "Epoch 2375/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.1749 - accuracy: 0.9525 - val_loss: 0.2812 - val_accuracy: 0.9000\n",
      "Epoch 2376/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1749 - accuracy: 0.95 - 0s 119us/step - loss: 0.1759 - accuracy: 0.9538 - val_loss: 0.2814 - val_accuracy: 0.9000\n",
      "Epoch 2377/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1748 - accuracy: 0.9525 - val_loss: 0.2796 - val_accuracy: 0.8950\n",
      "Epoch 2378/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1741 - accuracy: 0.9538 - val_loss: 0.2816 - val_accuracy: 0.9000\n",
      "Epoch 2379/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 1.00 - 0s 99us/step - loss: 0.1751 - accuracy: 0.9513 - val_loss: 0.2803 - val_accuracy: 0.8950\n",
      "Epoch 2380/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.1753 - accuracy: 0.9513 - val_loss: 0.2800 - val_accuracy: 0.8950\n",
      "Epoch 2381/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1746 - accuracy: 0.9538 - val_loss: 0.2774 - val_accuracy: 0.8950\n",
      "Epoch 2382/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.1745 - accuracy: 0.9538 - val_loss: 0.2784 - val_accuracy: 0.8950\n",
      "Epoch 2383/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1749 - accuracy: 0.9513 - val_loss: 0.2776 - val_accuracy: 0.8950\n",
      "Epoch 2384/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1740 - accuracy: 0.9525 - val_loss: 0.2780 - val_accuracy: 0.8950\n",
      "Epoch 2385/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1748 - accuracy: 0.9525 - val_loss: 0.2777 - val_accuracy: 0.8950\n",
      "Epoch 2386/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1741 - accuracy: 0.9500 - val_loss: 0.2783 - val_accuracy: 0.8950\n",
      "Epoch 2387/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1740 - accuracy: 0.9500 - val_loss: 0.2805 - val_accuracy: 0.8950\n",
      "Epoch 2388/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.1740 - accuracy: 0.9513 - val_loss: 0.2784 - val_accuracy: 0.8950\n",
      "Epoch 2389/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.1740 - accuracy: 0.9538 - val_loss: 0.2786 - val_accuracy: 0.8950\n",
      "Epoch 2390/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1742 - accuracy: 0.9538 - val_loss: 0.2800 - val_accuracy: 0.8950\n",
      "Epoch 2391/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.1742 - accuracy: 0.9525 - val_loss: 0.2778 - val_accuracy: 0.8950\n",
      "Epoch 2392/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1735 - accuracy: 0.9525 - val_loss: 0.2795 - val_accuracy: 0.8950\n",
      "Epoch 2393/3000\n",
      "800/800 [==============================] - 0s 144us/step - loss: 0.1735 - accuracy: 0.9538 - val_loss: 0.2767 - val_accuracy: 0.8950\n",
      "Epoch 2394/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1741 - accuracy: 0.9538 - val_loss: 0.2785 - val_accuracy: 0.8950\n",
      "Epoch 2395/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1743 - accuracy: 0.9513 - val_loss: 0.2788 - val_accuracy: 0.8950\n",
      "Epoch 2396/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1738 - accuracy: 0.9525 - val_loss: 0.2777 - val_accuracy: 0.8950\n",
      "Epoch 2397/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2024 - accuracy: 0.95 - ETA: 0s - loss: 0.1747 - accuracy: 0.95 - 0s 106us/step - loss: 0.1736 - accuracy: 0.9525 - val_loss: 0.2785 - val_accuracy: 0.8950\n",
      "Epoch 2398/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.1745 - accuracy: 0.9513 - val_loss: 0.2795 - val_accuracy: 0.8950\n",
      "Epoch 2399/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1736 - accuracy: 0.9525 - val_loss: 0.2771 - val_accuracy: 0.8950\n",
      "Epoch 2400/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1936 - accuracy: 0.94 - 0s 126us/step - loss: 0.1733 - accuracy: 0.9513 - val_loss: 0.2782 - val_accuracy: 0.8950\n",
      "Epoch 2401/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.1735 - accuracy: 0.9513 - val_loss: 0.2799 - val_accuracy: 0.8950\n",
      "Epoch 2402/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1731 - accuracy: 0.9588 - val_loss: 0.2773 - val_accuracy: 0.9000\n",
      "Epoch 2403/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.1741 - accuracy: 0.9525 - val_loss: 0.2776 - val_accuracy: 0.8950\n",
      "Epoch 2404/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1731 - accuracy: 0.9513 - val_loss: 0.2774 - val_accuracy: 0.8950\n",
      "Epoch 2405/3000\n",
      "800/800 [==============================] - 0s 123us/step - loss: 0.1731 - accuracy: 0.9500 - val_loss: 0.2789 - val_accuracy: 0.8950\n",
      "Epoch 2406/3000\n",
      "800/800 [==============================] - 0s 124us/step - loss: 0.1729 - accuracy: 0.9513 - val_loss: 0.2800 - val_accuracy: 0.8950\n",
      "Epoch 2407/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1732 - accuracy: 0.9500 - val_loss: 0.2785 - val_accuracy: 0.8950\n",
      "Epoch 2408/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.1728 - accuracy: 0.9538 - val_loss: 0.2796 - val_accuracy: 0.9000\n",
      "Epoch 2409/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.1736 - accuracy: 0.9538 - val_loss: 0.2790 - val_accuracy: 0.8950\n",
      "Epoch 2410/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1731 - accuracy: 0.9538 - val_loss: 0.2793 - val_accuracy: 0.8950\n",
      "Epoch 2411/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1731 - accuracy: 0.9513 - val_loss: 0.2768 - val_accuracy: 0.8950\n",
      "Epoch 2412/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1725 - accuracy: 0.9538 - val_loss: 0.2771 - val_accuracy: 0.8950\n",
      "Epoch 2413/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1728 - accuracy: 0.9550 - val_loss: 0.2759 - val_accuracy: 0.8950\n",
      "Epoch 2414/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1725 - accuracy: 0.9500 - val_loss: 0.2771 - val_accuracy: 0.8950\n",
      "Epoch 2415/3000\n",
      "800/800 [==============================] - 0s 123us/step - loss: 0.1731 - accuracy: 0.9525 - val_loss: 0.2772 - val_accuracy: 0.8950\n",
      "Epoch 2416/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.94 - 0s 110us/step - loss: 0.1720 - accuracy: 0.9488 - val_loss: 0.2785 - val_accuracy: 0.8950\n",
      "Epoch 2417/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1728 - accuracy: 0.9538 - val_loss: 0.2786 - val_accuracy: 0.8950\n",
      "Epoch 2418/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.1718 - accuracy: 0.9563 - val_loss: 0.2772 - val_accuracy: 0.8950\n",
      "Epoch 2419/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1724 - accuracy: 0.9513 - val_loss: 0.2789 - val_accuracy: 0.9000\n",
      "Epoch 2420/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1715 - accuracy: 0.9488 - val_loss: 0.2826 - val_accuracy: 0.8900\n",
      "Epoch 2421/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1723 - accuracy: 0.9538 - val_loss: 0.2802 - val_accuracy: 0.8950\n",
      "Epoch 2422/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1730 - accuracy: 0.9538 - val_loss: 0.2785 - val_accuracy: 0.8950\n",
      "Epoch 2423/3000\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.1718 - accuracy: 0.9538 - val_loss: 0.2806 - val_accuracy: 0.9000\n",
      "Epoch 2424/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1726 - accuracy: 0.9525 - val_loss: 0.2784 - val_accuracy: 0.8950\n",
      "Epoch 2425/3000\n",
      "800/800 [==============================] - 0s 125us/step - loss: 0.1724 - accuracy: 0.9538 - val_loss: 0.2776 - val_accuracy: 0.8950\n",
      "Epoch 2426/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.1723 - accuracy: 0.9538 - val_loss: 0.2750 - val_accuracy: 0.8950\n",
      "Epoch 2427/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1716 - accuracy: 0.9550 - val_loss: 0.2769 - val_accuracy: 0.8950\n",
      "Epoch 2428/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.1722 - accuracy: 0.9538 - val_loss: 0.2746 - val_accuracy: 0.8950\n",
      "Epoch 2429/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1716 - accuracy: 0.9538 - val_loss: 0.2780 - val_accuracy: 0.8950\n",
      "Epoch 2430/3000\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.1718 - accuracy: 0.9538 - val_loss: 0.2757 - val_accuracy: 0.8950\n",
      "Epoch 2431/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1725 - accuracy: 0.9538 - val_loss: 0.2748 - val_accuracy: 0.8950\n",
      "Epoch 2432/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.1713 - accuracy: 0.9513 - val_loss: 0.2760 - val_accuracy: 0.8950\n",
      "Epoch 2433/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1710 - accuracy: 0.9525 - val_loss: 0.2786 - val_accuracy: 0.9000\n",
      "Epoch 2434/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1708 - accuracy: 0.9550 - val_loss: 0.2751 - val_accuracy: 0.8950\n",
      "Epoch 2435/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1724 - accuracy: 0.9513 - val_loss: 0.2763 - val_accuracy: 0.8950\n",
      "Epoch 2436/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1709 - accuracy: 0.9525 - val_loss: 0.2743 - val_accuracy: 0.8950\n",
      "Epoch 2437/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1712 - accuracy: 0.9538 - val_loss: 0.2749 - val_accuracy: 0.8950\n",
      "Epoch 2438/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1712 - accuracy: 0.9525 - val_loss: 0.2783 - val_accuracy: 0.8950\n",
      "Epoch 2439/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.1712 - accuracy: 0.9513 - val_loss: 0.2772 - val_accuracy: 0.8950\n",
      "Epoch 2440/3000\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.1707 - accuracy: 0.9550 - val_loss: 0.2790 - val_accuracy: 0.8950\n",
      "Epoch 2441/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1715 - accuracy: 0.9538 - val_loss: 0.2770 - val_accuracy: 0.8950\n",
      "Epoch 2442/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1724 - accuracy: 0.95 - 0s 115us/step - loss: 0.1710 - accuracy: 0.9538 - val_loss: 0.2793 - val_accuracy: 0.8950\n",
      "Epoch 2443/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1720 - accuracy: 0.9550 - val_loss: 0.2767 - val_accuracy: 0.8950\n",
      "Epoch 2444/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1707 - accuracy: 0.9525 - val_loss: 0.2774 - val_accuracy: 0.8950\n",
      "Epoch 2445/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1712 - accuracy: 0.9513 - val_loss: 0.2775 - val_accuracy: 0.8950\n",
      "Epoch 2446/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1713 - accuracy: 0.9513 - val_loss: 0.2755 - val_accuracy: 0.8950\n",
      "Epoch 2447/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1705 - accuracy: 0.9513 - val_loss: 0.2771 - val_accuracy: 0.8950\n",
      "Epoch 2448/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.1709 - accuracy: 0.9563 - val_loss: 0.2760 - val_accuracy: 0.8950\n",
      "Epoch 2449/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1703 - accuracy: 0.9538 - val_loss: 0.2774 - val_accuracy: 0.8950\n",
      "Epoch 2450/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.1707 - accuracy: 0.9550 - val_loss: 0.2743 - val_accuracy: 0.8950\n",
      "Epoch 2451/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.1702 - accuracy: 0.9538 - val_loss: 0.2760 - val_accuracy: 0.8950\n",
      "Epoch 2452/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1702 - accuracy: 0.9550 - val_loss: 0.2780 - val_accuracy: 0.8950\n",
      "Epoch 2453/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.1709 - accuracy: 0.9538 - val_loss: 0.2753 - val_accuracy: 0.8950\n",
      "Epoch 2454/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1706 - accuracy: 0.9538 - val_loss: 0.2764 - val_accuracy: 0.8950\n",
      "Epoch 2455/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1731 - accuracy: 0.95 - 0s 120us/step - loss: 0.1704 - accuracy: 0.9525 - val_loss: 0.2756 - val_accuracy: 0.8950\n",
      "Epoch 2456/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.1706 - accuracy: 0.9525 - val_loss: 0.2759 - val_accuracy: 0.8950\n",
      "Epoch 2457/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1701 - accuracy: 0.9538 - val_loss: 0.2751 - val_accuracy: 0.8950\n",
      "Epoch 2458/3000\n",
      "800/800 [==============================] - 0s 128us/step - loss: 0.1705 - accuracy: 0.9513 - val_loss: 0.2752 - val_accuracy: 0.8950\n",
      "Epoch 2459/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1700 - accuracy: 0.9538 - val_loss: 0.2765 - val_accuracy: 0.8950\n",
      "Epoch 2460/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1701 - accuracy: 0.9525 - val_loss: 0.2763 - val_accuracy: 0.8950\n",
      "Epoch 2461/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.1708 - accuracy: 0.9563 - val_loss: 0.2760 - val_accuracy: 0.8950\n",
      "Epoch 2462/3000\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.1698 - accuracy: 0.9538 - val_loss: 0.2745 - val_accuracy: 0.8950\n",
      "Epoch 2463/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1699 - accuracy: 0.9538 - val_loss: 0.2746 - val_accuracy: 0.8950\n",
      "Epoch 2464/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1695 - accuracy: 0.9550 - val_loss: 0.2736 - val_accuracy: 0.9000\n",
      "Epoch 2465/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1554 - accuracy: 0.98 - ETA: 0s - loss: 0.1638 - accuracy: 0.95 - 0s 114us/step - loss: 0.1693 - accuracy: 0.9525 - val_loss: 0.2761 - val_accuracy: 0.8950\n",
      "Epoch 2466/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1766 - accuracy: 0.95 - 0s 109us/step - loss: 0.1701 - accuracy: 0.9538 - val_loss: 0.2753 - val_accuracy: 0.8950\n",
      "Epoch 2467/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.95 - 0s 104us/step - loss: 0.1697 - accuracy: 0.9525 - val_loss: 0.2770 - val_accuracy: 0.9000\n",
      "Epoch 2468/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.1697 - accuracy: 0.9563 - val_loss: 0.2762 - val_accuracy: 0.8950\n",
      "Epoch 2469/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1697 - accuracy: 0.9513 - val_loss: 0.2775 - val_accuracy: 0.8950\n",
      "Epoch 2470/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1695 - accuracy: 0.9538 - val_loss: 0.2764 - val_accuracy: 0.8950\n",
      "Epoch 2471/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1691 - accuracy: 0.9538 - val_loss: 0.2760 - val_accuracy: 0.8950\n",
      "Epoch 2472/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1695 - accuracy: 0.9513 - val_loss: 0.2755 - val_accuracy: 0.8950\n",
      "Epoch 2473/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1693 - accuracy: 0.9538 - val_loss: 0.2755 - val_accuracy: 0.8950\n",
      "Epoch 2474/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1697 - accuracy: 0.9563 - val_loss: 0.2760 - val_accuracy: 0.8950\n",
      "Epoch 2475/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.1698 - accuracy: 0.9513 - val_loss: 0.2760 - val_accuracy: 0.8950\n",
      "Epoch 2476/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1695 - accuracy: 0.9538 - val_loss: 0.2754 - val_accuracy: 0.8950\n",
      "Epoch 2477/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1688 - accuracy: 0.95 - 0s 109us/step - loss: 0.1695 - accuracy: 0.9538 - val_loss: 0.2756 - val_accuracy: 0.8950\n",
      "Epoch 2478/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1688 - accuracy: 0.9563 - val_loss: 0.2781 - val_accuracy: 0.9000\n",
      "Epoch 2479/3000\n",
      "800/800 [==============================] - 0s 123us/step - loss: 0.1693 - accuracy: 0.9550 - val_loss: 0.2757 - val_accuracy: 0.8950\n",
      "Epoch 2480/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1698 - accuracy: 0.9538 - val_loss: 0.2754 - val_accuracy: 0.8950\n",
      "Epoch 2481/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1696 - accuracy: 0.95 - 0s 105us/step - loss: 0.1685 - accuracy: 0.9525 - val_loss: 0.2745 - val_accuracy: 0.8950\n",
      "Epoch 2482/3000\n",
      "800/800 [==============================] - 0s 359us/step - loss: 0.1688 - accuracy: 0.9563 - val_loss: 0.2748 - val_accuracy: 0.8950\n",
      "Epoch 2483/3000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.1696 - accuracy: 0.9550 - val_loss: 0.2757 - val_accuracy: 0.8950\n",
      "Epoch 2484/3000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 0.1684 - accuracy: 0.9525 - val_loss: 0.2771 - val_accuracy: 0.9000\n",
      "Epoch 2485/3000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.1690 - accuracy: 0.9563 - val_loss: 0.2751 - val_accuracy: 0.8950\n",
      "Epoch 2486/3000\n",
      "800/800 [==============================] - 0s 218us/step - loss: 0.1692 - accuracy: 0.9563 - val_loss: 0.2751 - val_accuracy: 0.8950\n",
      "Epoch 2487/3000\n",
      "800/800 [==============================] - 0s 219us/step - loss: 0.1685 - accuracy: 0.9538 - val_loss: 0.2767 - val_accuracy: 0.9000\n",
      "Epoch 2488/3000\n",
      "800/800 [==============================] - 0s 175us/step - loss: 0.1688 - accuracy: 0.9550 - val_loss: 0.2751 - val_accuracy: 0.9000\n",
      "Epoch 2489/3000\n",
      "800/800 [==============================] - 0s 220us/step - loss: 0.1680 - accuracy: 0.9525 - val_loss: 0.2762 - val_accuracy: 0.8900\n",
      "Epoch 2490/3000\n",
      "800/800 [==============================] - 0s 156us/step - loss: 0.1683 - accuracy: 0.9525 - val_loss: 0.2744 - val_accuracy: 0.8950\n",
      "Epoch 2491/3000\n",
      "800/800 [==============================] - 0s 219us/step - loss: 0.1684 - accuracy: 0.9525 - val_loss: 0.2756 - val_accuracy: 0.8950\n",
      "Epoch 2492/3000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.1687 - accuracy: 0.9538 - val_loss: 0.2744 - val_accuracy: 0.8950\n",
      "Epoch 2493/3000\n",
      "800/800 [==============================] - 0s 214us/step - loss: 0.1680 - accuracy: 0.9563 - val_loss: 0.2726 - val_accuracy: 0.9000\n",
      "Epoch 2494/3000\n",
      "800/800 [==============================] - 0s 151us/step - loss: 0.1681 - accuracy: 0.9550 - val_loss: 0.2742 - val_accuracy: 0.8950\n",
      "Epoch 2495/3000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.1686 - accuracy: 0.9575 - val_loss: 0.2744 - val_accuracy: 0.8950\n",
      "Epoch 2496/3000\n",
      "800/800 [==============================] - 0s 131us/step - loss: 0.1681 - accuracy: 0.9513 - val_loss: 0.2727 - val_accuracy: 0.8950\n",
      "Epoch 2497/3000\n",
      "800/800 [==============================] - 0s 141us/step - loss: 0.1678 - accuracy: 0.9538 - val_loss: 0.2722 - val_accuracy: 0.8950\n",
      "Epoch 2498/3000\n",
      "800/800 [==============================] - 0s 154us/step - loss: 0.1683 - accuracy: 0.9525 - val_loss: 0.2726 - val_accuracy: 0.8950\n",
      "Epoch 2499/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1691 - accuracy: 0.9513 - val_loss: 0.2743 - val_accuracy: 0.8950\n",
      "Epoch 2500/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1674 - accuracy: 0.9525 - val_loss: 0.2751 - val_accuracy: 0.9000\n",
      "Epoch 2501/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1677 - accuracy: 0.9525 - val_loss: 0.2758 - val_accuracy: 0.8950\n",
      "Epoch 2502/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.95 - 0s 119us/step - loss: 0.1685 - accuracy: 0.9550 - val_loss: 0.2761 - val_accuracy: 0.9000\n",
      "Epoch 2503/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.1679 - accuracy: 0.9550 - val_loss: 0.2761 - val_accuracy: 0.9000\n",
      "Epoch 2504/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1725 - accuracy: 0.95 - 0s 116us/step - loss: 0.1689 - accuracy: 0.9513 - val_loss: 0.2734 - val_accuracy: 0.8950\n",
      "Epoch 2505/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1674 - accuracy: 0.9525 - val_loss: 0.2755 - val_accuracy: 0.8950\n",
      "Epoch 2506/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.1682 - accuracy: 0.9513 - val_loss: 0.2743 - val_accuracy: 0.8950\n",
      "Epoch 2507/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1670 - accuracy: 0.9563 - val_loss: 0.2755 - val_accuracy: 0.8950\n",
      "Epoch 2508/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1676 - accuracy: 0.9538 - val_loss: 0.2734 - val_accuracy: 0.8950\n",
      "Epoch 2509/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1671 - accuracy: 0.9538 - val_loss: 0.2725 - val_accuracy: 0.8950\n",
      "Epoch 2510/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1676 - accuracy: 0.9525 - val_loss: 0.2733 - val_accuracy: 0.8950\n",
      "Epoch 2511/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1681 - accuracy: 0.9538 - val_loss: 0.2720 - val_accuracy: 0.8950\n",
      "Epoch 2512/3000\n",
      "800/800 [==============================] - 0s 125us/step - loss: 0.1674 - accuracy: 0.9538 - val_loss: 0.2751 - val_accuracy: 0.8950\n",
      "Epoch 2513/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1670 - accuracy: 0.9563 - val_loss: 0.2761 - val_accuracy: 0.8950\n",
      "Epoch 2514/3000\n",
      "800/800 [==============================] - 0s 128us/step - loss: 0.1668 - accuracy: 0.9563 - val_loss: 0.2758 - val_accuracy: 0.8950\n",
      "Epoch 2515/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1670 - accuracy: 0.9550 - val_loss: 0.2751 - val_accuracy: 0.8950\n",
      "Epoch 2516/3000\n",
      "800/800 [==============================] - 0s 123us/step - loss: 0.1678 - accuracy: 0.9538 - val_loss: 0.2724 - val_accuracy: 0.8950\n",
      "Epoch 2517/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1668 - accuracy: 0.9538 - val_loss: 0.2739 - val_accuracy: 0.8950\n",
      "Epoch 2518/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1543 - accuracy: 0.93 - 0s 100us/step - loss: 0.1672 - accuracy: 0.9525 - val_loss: 0.2743 - val_accuracy: 0.8950\n",
      "Epoch 2519/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.1668 - accuracy: 0.9525 - val_loss: 0.2766 - val_accuracy: 0.8950\n",
      "Epoch 2520/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1675 - accuracy: 0.9550 - val_loss: 0.2768 - val_accuracy: 0.8950\n",
      "Epoch 2521/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1670 - accuracy: 0.9563 - val_loss: 0.2737 - val_accuracy: 0.9000\n",
      "Epoch 2522/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1671 - accuracy: 0.9538 - val_loss: 0.2730 - val_accuracy: 0.8950\n",
      "Epoch 2523/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1671 - accuracy: 0.9538 - val_loss: 0.2722 - val_accuracy: 0.8950\n",
      "Epoch 2524/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1669 - accuracy: 0.9538 - val_loss: 0.2717 - val_accuracy: 0.9000\n",
      "Epoch 2525/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1602 - accuracy: 0.95 - 0s 109us/step - loss: 0.1665 - accuracy: 0.9538 - val_loss: 0.2743 - val_accuracy: 0.9000\n",
      "Epoch 2526/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1666 - accuracy: 0.9550 - val_loss: 0.2743 - val_accuracy: 0.9000\n",
      "Epoch 2527/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1672 - accuracy: 0.9538 - val_loss: 0.2754 - val_accuracy: 0.8950\n",
      "Epoch 2528/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.1661 - accuracy: 0.9550 - val_loss: 0.2722 - val_accuracy: 0.8950\n",
      "Epoch 2529/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1661 - accuracy: 0.95 - 0s 108us/step - loss: 0.1663 - accuracy: 0.9575 - val_loss: 0.2723 - val_accuracy: 0.8950\n",
      "Epoch 2530/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1668 - accuracy: 0.9538 - val_loss: 0.2734 - val_accuracy: 0.8950\n",
      "Epoch 2531/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1660 - accuracy: 0.9550 - val_loss: 0.2745 - val_accuracy: 0.9000\n",
      "Epoch 2532/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1667 - accuracy: 0.9550 - val_loss: 0.2755 - val_accuracy: 0.9000\n",
      "Epoch 2533/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1660 - accuracy: 0.9563 - val_loss: 0.2732 - val_accuracy: 0.9000\n",
      "Epoch 2534/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1663 - accuracy: 0.9513 - val_loss: 0.2719 - val_accuracy: 0.8950\n",
      "Epoch 2535/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1664 - accuracy: 0.9538 - val_loss: 0.2717 - val_accuracy: 0.8950\n",
      "Epoch 2536/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1656 - accuracy: 0.9575 - val_loss: 0.2735 - val_accuracy: 0.8950\n",
      "Epoch 2537/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1666 - accuracy: 0.9513 - val_loss: 0.2738 - val_accuracy: 0.8950\n",
      "Epoch 2538/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1656 - accuracy: 0.9538 - val_loss: 0.2735 - val_accuracy: 0.9000\n",
      "Epoch 2539/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1660 - accuracy: 0.9525 - val_loss: 0.2743 - val_accuracy: 0.9000\n",
      "Epoch 2540/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.1657 - accuracy: 0.9538 - val_loss: 0.2758 - val_accuracy: 0.9000\n",
      "Epoch 2541/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.1668 - accuracy: 0.9550 - val_loss: 0.2735 - val_accuracy: 0.9000\n",
      "Epoch 2542/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.1656 - accuracy: 0.9538 - val_loss: 0.2740 - val_accuracy: 0.9000\n",
      "Epoch 2543/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.1663 - accuracy: 0.9563 - val_loss: 0.2705 - val_accuracy: 0.8950\n",
      "Epoch 2544/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1665 - accuracy: 0.9538 - val_loss: 0.2708 - val_accuracy: 0.9000\n",
      "Epoch 2545/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1639 - accuracy: 0.95 - 0s 109us/step - loss: 0.1654 - accuracy: 0.9513 - val_loss: 0.2718 - val_accuracy: 0.8950\n",
      "Epoch 2546/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1652 - accuracy: 0.9525 - val_loss: 0.2716 - val_accuracy: 0.8950\n",
      "Epoch 2547/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1655 - accuracy: 0.9513 - val_loss: 0.2743 - val_accuracy: 0.8950\n",
      "Epoch 2548/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1645 - accuracy: 0.9563 - val_loss: 0.2707 - val_accuracy: 0.8950\n",
      "Epoch 2549/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1661 - accuracy: 0.9513 - val_loss: 0.2725 - val_accuracy: 0.8950\n",
      "Epoch 2550/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1657 - accuracy: 0.9525 - val_loss: 0.2723 - val_accuracy: 0.9000\n",
      "Epoch 2551/3000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.1660 - accuracy: 0.9525 - val_loss: 0.2729 - val_accuracy: 0.8950\n",
      "Epoch 2552/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1643 - accuracy: 0.95 - 0s 134us/step - loss: 0.1655 - accuracy: 0.9538 - val_loss: 0.2737 - val_accuracy: 0.8950\n",
      "Epoch 2553/3000\n",
      "800/800 [==============================] - 0s 148us/step - loss: 0.1648 - accuracy: 0.9550 - val_loss: 0.2738 - val_accuracy: 0.8950\n",
      "Epoch 2554/3000\n",
      "800/800 [==============================] - 0s 221us/step - loss: 0.1650 - accuracy: 0.9538 - val_loss: 0.2735 - val_accuracy: 0.9000\n",
      "Epoch 2555/3000\n",
      "800/800 [==============================] - 0s 175us/step - loss: 0.1651 - accuracy: 0.9550 - val_loss: 0.2741 - val_accuracy: 0.8950\n",
      "Epoch 2556/3000\n",
      "800/800 [==============================] - 0s 126us/step - loss: 0.1649 - accuracy: 0.9588 - val_loss: 0.2714 - val_accuracy: 0.8950\n",
      "Epoch 2557/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1659 - accuracy: 0.9525 - val_loss: 0.2725 - val_accuracy: 0.8950\n",
      "Epoch 2558/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1738 - accuracy: 0.95 - 0s 114us/step - loss: 0.1646 - accuracy: 0.9563 - val_loss: 0.2735 - val_accuracy: 0.8950\n",
      "Epoch 2559/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.1645 - accuracy: 0.9575 - val_loss: 0.2783 - val_accuracy: 0.8950\n",
      "Epoch 2560/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1656 - accuracy: 0.9563 - val_loss: 0.2738 - val_accuracy: 0.9000\n",
      "Epoch 2561/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1649 - accuracy: 0.9563 - val_loss: 0.2747 - val_accuracy: 0.9000\n",
      "Epoch 2562/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1650 - accuracy: 0.9513 - val_loss: 0.2737 - val_accuracy: 0.8950\n",
      "Epoch 2563/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1643 - accuracy: 0.9550 - val_loss: 0.2716 - val_accuracy: 0.8950\n",
      "Epoch 2564/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1652 - accuracy: 0.9525 - val_loss: 0.2704 - val_accuracy: 0.8950\n",
      "Epoch 2565/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1643 - accuracy: 0.9550 - val_loss: 0.2702 - val_accuracy: 0.9000\n",
      "Epoch 2566/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1666 - accuracy: 0.95 - 0s 100us/step - loss: 0.1646 - accuracy: 0.9538 - val_loss: 0.2721 - val_accuracy: 0.8950\n",
      "Epoch 2567/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1647 - accuracy: 0.9538 - val_loss: 0.2708 - val_accuracy: 0.8950\n",
      "Epoch 2568/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1651 - accuracy: 0.95 - 0s 106us/step - loss: 0.1643 - accuracy: 0.9550 - val_loss: 0.2701 - val_accuracy: 0.8950\n",
      "Epoch 2569/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1647 - accuracy: 0.9563 - val_loss: 0.2692 - val_accuracy: 0.9000\n",
      "Epoch 2570/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1640 - accuracy: 0.9538 - val_loss: 0.2703 - val_accuracy: 0.8950\n",
      "Epoch 2571/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1644 - accuracy: 0.9563 - val_loss: 0.2715 - val_accuracy: 0.8950\n",
      "Epoch 2572/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.1644 - accuracy: 0.9563 - val_loss: 0.2710 - val_accuracy: 0.8950\n",
      "Epoch 2573/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.1638 - accuracy: 0.9538 - val_loss: 0.2737 - val_accuracy: 0.9000\n",
      "Epoch 2574/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.1643 - accuracy: 0.9563 - val_loss: 0.2716 - val_accuracy: 0.8950\n",
      "Epoch 2575/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.1637 - accuracy: 0.9563 - val_loss: 0.2723 - val_accuracy: 0.8950\n",
      "Epoch 2576/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1637 - accuracy: 0.9538 - val_loss: 0.2714 - val_accuracy: 0.8950\n",
      "Epoch 2577/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1641 - accuracy: 0.9538 - val_loss: 0.2714 - val_accuracy: 0.8950\n",
      "Epoch 2578/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1636 - accuracy: 0.9550 - val_loss: 0.2760 - val_accuracy: 0.8950\n",
      "Epoch 2579/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1640 - accuracy: 0.9563 - val_loss: 0.2723 - val_accuracy: 0.8950\n",
      "Epoch 2580/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.1640 - accuracy: 0.9513 - val_loss: 0.2731 - val_accuracy: 0.9000\n",
      "Epoch 2581/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1638 - accuracy: 0.9538 - val_loss: 0.2738 - val_accuracy: 0.9000\n",
      "Epoch 2582/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1633 - accuracy: 0.9538 - val_loss: 0.2715 - val_accuracy: 0.9000\n",
      "Epoch 2583/3000\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.1635 - accuracy: 0.9525 - val_loss: 0.2744 - val_accuracy: 0.8950\n",
      "Epoch 2584/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1649 - accuracy: 0.9538 - val_loss: 0.2739 - val_accuracy: 0.9000\n",
      "Epoch 2585/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1635 - accuracy: 0.9550 - val_loss: 0.2716 - val_accuracy: 0.9000\n",
      "Epoch 2586/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1630 - accuracy: 0.9563 - val_loss: 0.2713 - val_accuracy: 0.8950\n",
      "Epoch 2587/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1638 - accuracy: 0.9550 - val_loss: 0.2727 - val_accuracy: 0.9000\n",
      "Epoch 2588/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1639 - accuracy: 0.9525 - val_loss: 0.2718 - val_accuracy: 0.8950\n",
      "Epoch 2589/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1498 - accuracy: 0.98 - 0s 85us/step - loss: 0.1637 - accuracy: 0.9550 - val_loss: 0.2705 - val_accuracy: 0.8950\n",
      "Epoch 2590/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1631 - accuracy: 0.9563 - val_loss: 0.2706 - val_accuracy: 0.8950\n",
      "Epoch 2591/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1630 - accuracy: 0.9575 - val_loss: 0.2736 - val_accuracy: 0.8950\n",
      "Epoch 2592/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1630 - accuracy: 0.9563 - val_loss: 0.2713 - val_accuracy: 0.9000\n",
      "Epoch 2593/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1635 - accuracy: 0.9538 - val_loss: 0.2708 - val_accuracy: 0.8950\n",
      "Epoch 2594/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1628 - accuracy: 0.9513 - val_loss: 0.2716 - val_accuracy: 0.9000\n",
      "Epoch 2595/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1633 - accuracy: 0.9563 - val_loss: 0.2698 - val_accuracy: 0.8950\n",
      "Epoch 2596/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1631 - accuracy: 0.9550 - val_loss: 0.2697 - val_accuracy: 0.9000\n",
      "Epoch 2597/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1637 - accuracy: 0.9513 - val_loss: 0.2691 - val_accuracy: 0.8950\n",
      "Epoch 2598/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1622 - accuracy: 0.9563 - val_loss: 0.2737 - val_accuracy: 0.9000\n",
      "Epoch 2599/3000\n",
      "800/800 [==============================] - 0s 124us/step - loss: 0.1631 - accuracy: 0.9575 - val_loss: 0.2701 - val_accuracy: 0.9000\n",
      "Epoch 2600/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.1631 - accuracy: 0.9538 - val_loss: 0.2699 - val_accuracy: 0.8950\n",
      "Epoch 2601/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1632 - accuracy: 0.9563 - val_loss: 0.2704 - val_accuracy: 0.8950\n",
      "Epoch 2602/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1626 - accuracy: 0.9538 - val_loss: 0.2715 - val_accuracy: 0.9000\n",
      "Epoch 2603/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1633 - accuracy: 0.9563 - val_loss: 0.2693 - val_accuracy: 0.8950\n",
      "Epoch 2604/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1620 - accuracy: 0.9575 - val_loss: 0.2694 - val_accuracy: 0.9000\n",
      "Epoch 2605/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1634 - accuracy: 0.9525 - val_loss: 0.2709 - val_accuracy: 0.9000\n",
      "Epoch 2606/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1639 - accuracy: 0.95 - 0s 128us/step - loss: 0.1627 - accuracy: 0.9538 - val_loss: 0.2705 - val_accuracy: 0.8950\n",
      "Epoch 2607/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.1630 - accuracy: 0.9550 - val_loss: 0.2698 - val_accuracy: 0.8950\n",
      "Epoch 2608/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1627 - accuracy: 0.9525 - val_loss: 0.2690 - val_accuracy: 0.8950\n",
      "Epoch 2609/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1623 - accuracy: 0.95 - 0s 104us/step - loss: 0.1631 - accuracy: 0.9538 - val_loss: 0.2702 - val_accuracy: 0.8950\n",
      "Epoch 2610/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1622 - accuracy: 0.9538 - val_loss: 0.2694 - val_accuracy: 0.8950\n",
      "Epoch 2611/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1585 - accuracy: 0.95 - 0s 106us/step - loss: 0.1632 - accuracy: 0.9513 - val_loss: 0.2693 - val_accuracy: 0.8950\n",
      "Epoch 2612/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1693 - accuracy: 0.96 - 0s 88us/step - loss: 0.1616 - accuracy: 0.9550 - val_loss: 0.2715 - val_accuracy: 0.8950\n",
      "Epoch 2613/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1622 - accuracy: 0.9575 - val_loss: 0.2689 - val_accuracy: 0.8950\n",
      "Epoch 2614/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.1617 - accuracy: 0.9538 - val_loss: 0.2706 - val_accuracy: 0.8950\n",
      "Epoch 2615/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1630 - accuracy: 0.95 - 0s 101us/step - loss: 0.1613 - accuracy: 0.9538 - val_loss: 0.2747 - val_accuracy: 0.9000\n",
      "Epoch 2616/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1624 - accuracy: 0.9575 - val_loss: 0.2697 - val_accuracy: 0.8950\n",
      "Epoch 2617/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1617 - accuracy: 0.9550 - val_loss: 0.2696 - val_accuracy: 0.8950\n",
      "Epoch 2618/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.1629 - accuracy: 0.9550 - val_loss: 0.2690 - val_accuracy: 0.8950\n",
      "Epoch 2619/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1616 - accuracy: 0.9550 - val_loss: 0.2690 - val_accuracy: 0.8950\n",
      "Epoch 2620/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1626 - accuracy: 0.95 - 0s 105us/step - loss: 0.1631 - accuracy: 0.9538 - val_loss: 0.2715 - val_accuracy: 0.9000\n",
      "Epoch 2621/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1663 - accuracy: 0.95 - 0s 114us/step - loss: 0.1621 - accuracy: 0.9563 - val_loss: 0.2708 - val_accuracy: 0.9000\n",
      "Epoch 2622/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1686 - accuracy: 0.95 - 0s 115us/step - loss: 0.1613 - accuracy: 0.9563 - val_loss: 0.2724 - val_accuracy: 0.9000\n",
      "Epoch 2623/3000\n",
      "800/800 [==============================] - 0s 128us/step - loss: 0.1616 - accuracy: 0.9550 - val_loss: 0.2695 - val_accuracy: 0.8950\n",
      "Epoch 2624/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1621 - accuracy: 0.9513 - val_loss: 0.2707 - val_accuracy: 0.9000\n",
      "Epoch 2625/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 1.00 - ETA: 0s - loss: 0.1498 - accuracy: 0.95 - 0s 113us/step - loss: 0.1615 - accuracy: 0.9550 - val_loss: 0.2689 - val_accuracy: 0.8950\n",
      "Epoch 2626/3000\n",
      "800/800 [==============================] - 0s 149us/step - loss: 0.1613 - accuracy: 0.9550 - val_loss: 0.2716 - val_accuracy: 0.9000\n",
      "Epoch 2627/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.1619 - accuracy: 0.9550 - val_loss: 0.2710 - val_accuracy: 0.9000\n",
      "Epoch 2628/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1615 - accuracy: 0.9550 - val_loss: 0.2709 - val_accuracy: 0.9000\n",
      "Epoch 2629/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.1617 - accuracy: 0.9550 - val_loss: 0.2697 - val_accuracy: 0.9000\n",
      "Epoch 2630/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1650 - accuracy: 0.95 - 0s 115us/step - loss: 0.1616 - accuracy: 0.9538 - val_loss: 0.2693 - val_accuracy: 0.8950\n",
      "Epoch 2631/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.1607 - accuracy: 0.9550 - val_loss: 0.2687 - val_accuracy: 0.8950\n",
      "Epoch 2632/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.1614 - accuracy: 0.9588 - val_loss: 0.2709 - val_accuracy: 0.8950\n",
      "Epoch 2633/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1858 - accuracy: 0.95 - 0s 99us/step - loss: 0.1616 - accuracy: 0.9588 - val_loss: 0.2700 - val_accuracy: 0.9000\n",
      "Epoch 2634/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1609 - accuracy: 0.9575 - val_loss: 0.2709 - val_accuracy: 0.9000\n",
      "Epoch 2635/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1595 - accuracy: 0.95 - 0s 110us/step - loss: 0.1619 - accuracy: 0.9550 - val_loss: 0.2687 - val_accuracy: 0.8950\n",
      "Epoch 2636/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.95 - 0s 105us/step - loss: 0.1608 - accuracy: 0.9575 - val_loss: 0.2708 - val_accuracy: 0.8950\n",
      "Epoch 2637/3000\n",
      "800/800 [==============================] - 0s 123us/step - loss: 0.1610 - accuracy: 0.9575 - val_loss: 0.2725 - val_accuracy: 0.9050\n",
      "Epoch 2638/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1615 - accuracy: 0.9550 - val_loss: 0.2722 - val_accuracy: 0.8950\n",
      "Epoch 2639/3000\n",
      "800/800 [==============================] - 0s 453us/step - loss: 0.1617 - accuracy: 0.9538 - val_loss: 0.2707 - val_accuracy: 0.9000\n",
      "Epoch 2640/3000\n",
      "800/800 [==============================] - 0s 235us/step - loss: 0.1613 - accuracy: 0.9538 - val_loss: 0.2690 - val_accuracy: 0.9000\n",
      "Epoch 2641/3000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 0.1609 - accuracy: 0.9563 - val_loss: 0.2707 - val_accuracy: 0.9000\n",
      "Epoch 2642/3000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 0.1618 - accuracy: 0.9550 - val_loss: 0.2687 - val_accuracy: 0.8950\n",
      "Epoch 2643/3000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.1610 - accuracy: 0.9563 - val_loss: 0.2674 - val_accuracy: 0.9050\n",
      "Epoch 2644/3000\n",
      "800/800 [==============================] - 0s 263us/step - loss: 0.1614 - accuracy: 0.9550 - val_loss: 0.2681 - val_accuracy: 0.9000\n",
      "Epoch 2645/3000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 0.1601 - accuracy: 0.9525 - val_loss: 0.2706 - val_accuracy: 0.8950\n",
      "Epoch 2646/3000\n",
      "800/800 [==============================] - 0s 214us/step - loss: 0.1606 - accuracy: 0.9550 - val_loss: 0.2686 - val_accuracy: 0.8950\n",
      "Epoch 2647/3000\n",
      "800/800 [==============================] - 0s 218us/step - loss: 0.1608 - accuracy: 0.9538 - val_loss: 0.2677 - val_accuracy: 0.8950\n",
      "Epoch 2648/3000\n",
      "800/800 [==============================] - 0s 159us/step - loss: 0.1603 - accuracy: 0.9563 - val_loss: 0.2708 - val_accuracy: 0.9000\n",
      "Epoch 2649/3000\n",
      "800/800 [==============================] - 0s 149us/step - loss: 0.1608 - accuracy: 0.9563 - val_loss: 0.2691 - val_accuracy: 0.9000\n",
      "Epoch 2650/3000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 0.1606 - accuracy: 0.9550 - val_loss: 0.2709 - val_accuracy: 0.9000\n",
      "Epoch 2651/3000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.1608 - accuracy: 0.9538 - val_loss: 0.2693 - val_accuracy: 0.9000\n",
      "Epoch 2652/3000\n",
      "800/800 [==============================] - 0s 245us/step - loss: 0.1609 - accuracy: 0.9538 - val_loss: 0.2703 - val_accuracy: 0.9000\n",
      "Epoch 2653/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1609 - accuracy: 0.9550 - val_loss: 0.2692 - val_accuracy: 0.9000\n",
      "Epoch 2654/3000\n",
      "800/800 [==============================] - 0s 169us/step - loss: 0.1605 - accuracy: 0.9550 - val_loss: 0.2691 - val_accuracy: 0.8950\n",
      "Epoch 2655/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.95 - 0s 243us/step - loss: 0.1601 - accuracy: 0.9538 - val_loss: 0.2676 - val_accuracy: 0.8950\n",
      "Epoch 2656/3000\n",
      "800/800 [==============================] - 0s 141us/step - loss: 0.1597 - accuracy: 0.9563 - val_loss: 0.2702 - val_accuracy: 0.9000\n",
      "Epoch 2657/3000\n",
      "800/800 [==============================] - 0s 176us/step - loss: 0.1602 - accuracy: 0.9563 - val_loss: 0.2691 - val_accuracy: 0.8950\n",
      "Epoch 2658/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.1597 - accuracy: 0.9563 - val_loss: 0.2706 - val_accuracy: 0.9000\n",
      "Epoch 2659/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.1600 - accuracy: 0.9575 - val_loss: 0.2691 - val_accuracy: 0.8950\n",
      "Epoch 2660/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1597 - accuracy: 0.9575 - val_loss: 0.2723 - val_accuracy: 0.9000\n",
      "Epoch 2661/3000\n",
      "800/800 [==============================] - 0s 123us/step - loss: 0.1599 - accuracy: 0.9575 - val_loss: 0.2709 - val_accuracy: 0.9000\n",
      "Epoch 2662/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1594 - accuracy: 0.9513 - val_loss: 0.2686 - val_accuracy: 0.8950\n",
      "Epoch 2663/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1602 - accuracy: 0.9550 - val_loss: 0.2697 - val_accuracy: 0.9000\n",
      "Epoch 2664/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1597 - accuracy: 0.9550 - val_loss: 0.2696 - val_accuracy: 0.9000\n",
      "Epoch 2665/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.1594 - accuracy: 0.9575 - val_loss: 0.2670 - val_accuracy: 0.8950\n",
      "Epoch 2666/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1581 - accuracy: 0.95 - 0s 105us/step - loss: 0.1600 - accuracy: 0.9575 - val_loss: 0.2698 - val_accuracy: 0.9000\n",
      "Epoch 2667/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1594 - accuracy: 0.9538 - val_loss: 0.2670 - val_accuracy: 0.8950\n",
      "Epoch 2668/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1508 - accuracy: 0.95 - 0s 115us/step - loss: 0.1591 - accuracy: 0.9563 - val_loss: 0.2737 - val_accuracy: 0.9050\n",
      "Epoch 2669/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.1597 - accuracy: 0.9550 - val_loss: 0.2674 - val_accuracy: 0.8950\n",
      "Epoch 2670/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1590 - accuracy: 0.9550 - val_loss: 0.2666 - val_accuracy: 0.9050\n",
      "Epoch 2671/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.1599 - accuracy: 0.9550 - val_loss: 0.2674 - val_accuracy: 0.9000\n",
      "Epoch 2672/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1592 - accuracy: 0.9575 - val_loss: 0.2680 - val_accuracy: 0.9000\n",
      "Epoch 2673/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1591 - accuracy: 0.9575 - val_loss: 0.2697 - val_accuracy: 0.9000\n",
      "Epoch 2674/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1601 - accuracy: 0.9563 - val_loss: 0.2681 - val_accuracy: 0.9000\n",
      "Epoch 2675/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1589 - accuracy: 0.9563 - val_loss: 0.2691 - val_accuracy: 0.9000\n",
      "Epoch 2676/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1598 - accuracy: 0.9563 - val_loss: 0.2683 - val_accuracy: 0.9000\n",
      "Epoch 2677/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.1580 - accuracy: 0.9550 - val_loss: 0.2707 - val_accuracy: 0.9000\n",
      "Epoch 2678/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1595 - accuracy: 0.9563 - val_loss: 0.2673 - val_accuracy: 0.8950\n",
      "Epoch 2679/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1592 - accuracy: 0.9563 - val_loss: 0.2669 - val_accuracy: 0.8950\n",
      "Epoch 2680/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1594 - accuracy: 0.9538 - val_loss: 0.2673 - val_accuracy: 0.9000\n",
      "Epoch 2681/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1589 - accuracy: 0.9550 - val_loss: 0.2678 - val_accuracy: 0.8950\n",
      "Epoch 2682/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1592 - accuracy: 0.95 - 0s 114us/step - loss: 0.1588 - accuracy: 0.9563 - val_loss: 0.2679 - val_accuracy: 0.9000\n",
      "Epoch 2683/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1592 - accuracy: 0.9550 - val_loss: 0.2665 - val_accuracy: 0.8950\n",
      "Epoch 2684/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1598 - accuracy: 0.9550 - val_loss: 0.2685 - val_accuracy: 0.9000\n",
      "Epoch 2685/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1589 - accuracy: 0.9550 - val_loss: 0.2687 - val_accuracy: 0.8950\n",
      "Epoch 2686/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.1585 - accuracy: 0.9550 - val_loss: 0.2685 - val_accuracy: 0.9000\n",
      "Epoch 2687/3000\n",
      "800/800 [==============================] - 0s 126us/step - loss: 0.1596 - accuracy: 0.9563 - val_loss: 0.2673 - val_accuracy: 0.8950\n",
      "Epoch 2688/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1590 - accuracy: 0.9575 - val_loss: 0.2684 - val_accuracy: 0.9000\n",
      "Epoch 2689/3000\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.1588 - accuracy: 0.9563 - val_loss: 0.2724 - val_accuracy: 0.8950\n",
      "Epoch 2690/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1601 - accuracy: 0.95 - 0s 96us/step - loss: 0.1588 - accuracy: 0.9575 - val_loss: 0.2681 - val_accuracy: 0.8950\n",
      "Epoch 2691/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1583 - accuracy: 0.9575 - val_loss: 0.2684 - val_accuracy: 0.8950\n",
      "Epoch 2692/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1586 - accuracy: 0.9575 - val_loss: 0.2698 - val_accuracy: 0.9000\n",
      "Epoch 2693/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1589 - accuracy: 0.9538 - val_loss: 0.2701 - val_accuracy: 0.9000\n",
      "Epoch 2694/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1484 - accuracy: 0.96 - 0s 100us/step - loss: 0.1583 - accuracy: 0.9550 - val_loss: 0.2700 - val_accuracy: 0.9000\n",
      "Epoch 2695/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1533 - accuracy: 0.95 - 0s 113us/step - loss: 0.1592 - accuracy: 0.9525 - val_loss: 0.2683 - val_accuracy: 0.9000\n",
      "Epoch 2696/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1585 - accuracy: 0.9550 - val_loss: 0.2686 - val_accuracy: 0.9050\n",
      "Epoch 2697/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1583 - accuracy: 0.9563 - val_loss: 0.2685 - val_accuracy: 0.9000\n",
      "Epoch 2698/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1587 - accuracy: 0.9550 - val_loss: 0.2672 - val_accuracy: 0.8950\n",
      "Epoch 2699/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1583 - accuracy: 0.96 - 0s 101us/step - loss: 0.1588 - accuracy: 0.9575 - val_loss: 0.2698 - val_accuracy: 0.9050\n",
      "Epoch 2700/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1637 - accuracy: 0.95 - 0s 114us/step - loss: 0.1579 - accuracy: 0.9575 - val_loss: 0.2683 - val_accuracy: 0.9000\n",
      "Epoch 2701/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1580 - accuracy: 0.9575 - val_loss: 0.2682 - val_accuracy: 0.9000\n",
      "Epoch 2702/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1574 - accuracy: 0.9588 - val_loss: 0.2688 - val_accuracy: 0.9000\n",
      "Epoch 2703/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1581 - accuracy: 0.9550 - val_loss: 0.2684 - val_accuracy: 0.9000\n",
      "Epoch 2704/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1576 - accuracy: 0.9575 - val_loss: 0.2683 - val_accuracy: 0.9000\n",
      "Epoch 2705/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1583 - accuracy: 0.9575 - val_loss: 0.2697 - val_accuracy: 0.9000\n",
      "Epoch 2706/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1588 - accuracy: 0.95 - 0s 103us/step - loss: 0.1575 - accuracy: 0.9563 - val_loss: 0.2672 - val_accuracy: 0.9000\n",
      "Epoch 2707/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1598 - accuracy: 0.96 - 0s 116us/step - loss: 0.1574 - accuracy: 0.9588 - val_loss: 0.2683 - val_accuracy: 0.9000\n",
      "Epoch 2708/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1578 - accuracy: 0.9563 - val_loss: 0.2676 - val_accuracy: 0.8950\n",
      "Epoch 2709/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1583 - accuracy: 0.9575 - val_loss: 0.2698 - val_accuracy: 0.9000\n",
      "Epoch 2710/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.1580 - accuracy: 0.9550 - val_loss: 0.2673 - val_accuracy: 0.9000\n",
      "Epoch 2711/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1479 - accuracy: 0.95 - 0s 120us/step - loss: 0.1575 - accuracy: 0.9563 - val_loss: 0.2665 - val_accuracy: 0.9000\n",
      "Epoch 2712/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.1579 - accuracy: 0.9563 - val_loss: 0.2663 - val_accuracy: 0.8950\n",
      "Epoch 2713/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1578 - accuracy: 0.95 - 0s 106us/step - loss: 0.1586 - accuracy: 0.9550 - val_loss: 0.2679 - val_accuracy: 0.9000\n",
      "Epoch 2714/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.1573 - accuracy: 0.9575 - val_loss: 0.2679 - val_accuracy: 0.9000\n",
      "Epoch 2715/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1580 - accuracy: 0.9550 - val_loss: 0.2668 - val_accuracy: 0.9000\n",
      "Epoch 2716/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1573 - accuracy: 0.9550 - val_loss: 0.2685 - val_accuracy: 0.9000\n",
      "Epoch 2717/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1625 - accuracy: 0.95 - 0s 111us/step - loss: 0.1573 - accuracy: 0.9575 - val_loss: 0.2665 - val_accuracy: 0.8950\n",
      "Epoch 2718/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1569 - accuracy: 0.9588 - val_loss: 0.2675 - val_accuracy: 0.9000\n",
      "Epoch 2719/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.1573 - accuracy: 0.9563 - val_loss: 0.2655 - val_accuracy: 0.9000\n",
      "Epoch 2720/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1576 - accuracy: 0.9550 - val_loss: 0.2664 - val_accuracy: 0.9000\n",
      "Epoch 2721/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1571 - accuracy: 0.9563 - val_loss: 0.2662 - val_accuracy: 0.8950\n",
      "Epoch 2722/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1577 - accuracy: 0.9575 - val_loss: 0.2669 - val_accuracy: 0.9000\n",
      "Epoch 2723/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1569 - accuracy: 0.9575 - val_loss: 0.2669 - val_accuracy: 0.9050\n",
      "Epoch 2724/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1602 - accuracy: 0.95 - 0s 111us/step - loss: 0.1576 - accuracy: 0.9563 - val_loss: 0.2646 - val_accuracy: 0.8950\n",
      "Epoch 2725/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1570 - accuracy: 0.9550 - val_loss: 0.2658 - val_accuracy: 0.8950\n",
      "Epoch 2726/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1546 - accuracy: 0.95 - 0s 106us/step - loss: 0.1571 - accuracy: 0.9575 - val_loss: 0.2654 - val_accuracy: 0.8950\n",
      "Epoch 2727/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.1570 - accuracy: 0.9588 - val_loss: 0.2639 - val_accuracy: 0.8950\n",
      "Epoch 2728/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1569 - accuracy: 0.9563 - val_loss: 0.2660 - val_accuracy: 0.8950\n",
      "Epoch 2729/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1568 - accuracy: 0.9575 - val_loss: 0.2668 - val_accuracy: 0.9000\n",
      "Epoch 2730/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1467 - accuracy: 0.95 - 0s 121us/step - loss: 0.1567 - accuracy: 0.9550 - val_loss: 0.2647 - val_accuracy: 0.8950\n",
      "Epoch 2731/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2191 - accuracy: 0.92 - 0s 84us/step - loss: 0.1571 - accuracy: 0.9575 - val_loss: 0.2679 - val_accuracy: 0.9000\n",
      "Epoch 2732/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1568 - accuracy: 0.9600 - val_loss: 0.2678 - val_accuracy: 0.9000\n",
      "Epoch 2733/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.1569 - accuracy: 0.9538 - val_loss: 0.2661 - val_accuracy: 0.8950\n",
      "Epoch 2734/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1623 - accuracy: 0.95 - 0s 109us/step - loss: 0.1565 - accuracy: 0.9575 - val_loss: 0.2663 - val_accuracy: 0.9000\n",
      "Epoch 2735/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1563 - accuracy: 0.9538 - val_loss: 0.2669 - val_accuracy: 0.9000\n",
      "Epoch 2736/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1563 - accuracy: 0.9575 - val_loss: 0.2672 - val_accuracy: 0.9000\n",
      "Epoch 2737/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1323 - accuracy: 0.92 - 0s 84us/step - loss: 0.1570 - accuracy: 0.9563 - val_loss: 0.2670 - val_accuracy: 0.8950\n",
      "Epoch 2738/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1567 - accuracy: 0.9575 - val_loss: 0.2648 - val_accuracy: 0.9000\n",
      "Epoch 2739/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1567 - accuracy: 0.9538 - val_loss: 0.2651 - val_accuracy: 0.8950\n",
      "Epoch 2740/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1567 - accuracy: 0.9575 - val_loss: 0.2646 - val_accuracy: 0.8950\n",
      "Epoch 2741/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.1561 - accuracy: 0.9563 - val_loss: 0.2652 - val_accuracy: 0.9000\n",
      "Epoch 2742/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1561 - accuracy: 0.9575 - val_loss: 0.2660 - val_accuracy: 0.9000\n",
      "Epoch 2743/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1567 - accuracy: 0.9563 - val_loss: 0.2664 - val_accuracy: 0.9000\n",
      "Epoch 2744/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.95 - 0s 115us/step - loss: 0.1558 - accuracy: 0.9575 - val_loss: 0.2656 - val_accuracy: 0.9000\n",
      "Epoch 2745/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1571 - accuracy: 0.9600 - val_loss: 0.2663 - val_accuracy: 0.9000\n",
      "Epoch 2746/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1560 - accuracy: 0.9588 - val_loss: 0.2661 - val_accuracy: 0.9000\n",
      "Epoch 2747/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1564 - accuracy: 0.9588 - val_loss: 0.2672 - val_accuracy: 0.9000\n",
      "Epoch 2748/3000\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.1557 - accuracy: 0.9588 - val_loss: 0.2644 - val_accuracy: 0.9000\n",
      "Epoch 2749/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.1566 - accuracy: 0.9575 - val_loss: 0.2669 - val_accuracy: 0.9000\n",
      "Epoch 2750/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1556 - accuracy: 0.9588 - val_loss: 0.2693 - val_accuracy: 0.9050\n",
      "Epoch 2751/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1565 - accuracy: 0.9600 - val_loss: 0.2654 - val_accuracy: 0.9000\n",
      "Epoch 2752/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1554 - accuracy: 0.9588 - val_loss: 0.2663 - val_accuracy: 0.8950\n",
      "Epoch 2753/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.1561 - accuracy: 0.9550 - val_loss: 0.2665 - val_accuracy: 0.9000\n",
      "Epoch 2754/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.1557 - accuracy: 0.9563 - val_loss: 0.2674 - val_accuracy: 0.9000\n",
      "Epoch 2755/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1551 - accuracy: 0.9588 - val_loss: 0.2676 - val_accuracy: 0.9000\n",
      "Epoch 2756/3000\n",
      "800/800 [==============================] - 0s 129us/step - loss: 0.1553 - accuracy: 0.9563 - val_loss: 0.2673 - val_accuracy: 0.9000\n",
      "Epoch 2757/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.95 - 0s 110us/step - loss: 0.1556 - accuracy: 0.9538 - val_loss: 0.2650 - val_accuracy: 0.9000\n",
      "Epoch 2758/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1542 - accuracy: 0.95 - 0s 105us/step - loss: 0.1550 - accuracy: 0.9563 - val_loss: 0.2680 - val_accuracy: 0.9000\n",
      "Epoch 2759/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1604 - accuracy: 0.95 - 0s 110us/step - loss: 0.1552 - accuracy: 0.9575 - val_loss: 0.2672 - val_accuracy: 0.9000\n",
      "Epoch 2760/3000\n",
      "800/800 [==============================] - 0s 133us/step - loss: 0.1556 - accuracy: 0.9600 - val_loss: 0.2656 - val_accuracy: 0.8950\n",
      "Epoch 2761/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1551 - accuracy: 0.9600 - val_loss: 0.2653 - val_accuracy: 0.8950\n",
      "Epoch 2762/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1554 - accuracy: 0.9575 - val_loss: 0.2665 - val_accuracy: 0.9050\n",
      "Epoch 2763/3000\n",
      "800/800 [==============================] - 0s 129us/step - loss: 0.1556 - accuracy: 0.9588 - val_loss: 0.2669 - val_accuracy: 0.9000\n",
      "Epoch 2764/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1538 - accuracy: 0.95 - 0s 105us/step - loss: 0.1555 - accuracy: 0.9575 - val_loss: 0.2671 - val_accuracy: 0.9000\n",
      "Epoch 2765/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1554 - accuracy: 0.9563 - val_loss: 0.2644 - val_accuracy: 0.8950\n",
      "Epoch 2766/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.1555 - accuracy: 0.9563 - val_loss: 0.2649 - val_accuracy: 0.8950\n",
      "Epoch 2767/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1550 - accuracy: 0.9575 - val_loss: 0.2673 - val_accuracy: 0.9000\n",
      "Epoch 2768/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1549 - accuracy: 0.9575 - val_loss: 0.2652 - val_accuracy: 0.9000\n",
      "Epoch 2769/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.1554 - accuracy: 0.9575 - val_loss: 0.2663 - val_accuracy: 0.9050\n",
      "Epoch 2770/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1549 - accuracy: 0.9575 - val_loss: 0.2668 - val_accuracy: 0.9000\n",
      "Epoch 2771/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1554 - accuracy: 0.9588 - val_loss: 0.2647 - val_accuracy: 0.9000\n",
      "Epoch 2772/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1555 - accuracy: 0.9588 - val_loss: 0.2643 - val_accuracy: 0.9000\n",
      "Epoch 2773/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.1550 - accuracy: 0.9600 - val_loss: 0.2641 - val_accuracy: 0.9050\n",
      "Epoch 2774/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.1549 - accuracy: 0.9575 - val_loss: 0.2675 - val_accuracy: 0.9050\n",
      "Epoch 2775/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1548 - accuracy: 0.9563 - val_loss: 0.2656 - val_accuracy: 0.9000\n",
      "Epoch 2776/3000\n",
      "800/800 [==============================] - 0s 124us/step - loss: 0.1552 - accuracy: 0.9575 - val_loss: 0.2652 - val_accuracy: 0.8950\n",
      "Epoch 2777/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1555 - accuracy: 0.95 - 0s 113us/step - loss: 0.1547 - accuracy: 0.9575 - val_loss: 0.2647 - val_accuracy: 0.8950\n",
      "Epoch 2778/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1550 - accuracy: 0.9563 - val_loss: 0.2657 - val_accuracy: 0.9000\n",
      "Epoch 2779/3000\n",
      "800/800 [==============================] - 0s 134us/step - loss: 0.1550 - accuracy: 0.9575 - val_loss: 0.2645 - val_accuracy: 0.9050\n",
      "Epoch 2780/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.1543 - accuracy: 0.9563 - val_loss: 0.2649 - val_accuracy: 0.9000\n",
      "Epoch 2781/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.1542 - accuracy: 0.9600 - val_loss: 0.2645 - val_accuracy: 0.9000\n",
      "Epoch 2782/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.1549 - accuracy: 0.9563 - val_loss: 0.2666 - val_accuracy: 0.9000\n",
      "Epoch 2783/3000\n",
      "800/800 [==============================] - 0s 236us/step - loss: 0.1544 - accuracy: 0.9563 - val_loss: 0.2648 - val_accuracy: 0.8950\n",
      "Epoch 2784/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1542 - accuracy: 0.9588 - val_loss: 0.2633 - val_accuracy: 0.9000\n",
      "Epoch 2785/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1572 - accuracy: 0.95 - 0s 100us/step - loss: 0.1541 - accuracy: 0.9588 - val_loss: 0.2644 - val_accuracy: 0.9050\n",
      "Epoch 2786/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1546 - accuracy: 0.9600 - val_loss: 0.2669 - val_accuracy: 0.9050\n",
      "Epoch 2787/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1543 - accuracy: 0.9550 - val_loss: 0.2653 - val_accuracy: 0.9000\n",
      "Epoch 2788/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1542 - accuracy: 0.9575 - val_loss: 0.2656 - val_accuracy: 0.9000\n",
      "Epoch 2789/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1543 - accuracy: 0.9563 - val_loss: 0.2692 - val_accuracy: 0.9050\n",
      "Epoch 2790/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1545 - accuracy: 0.9588 - val_loss: 0.2647 - val_accuracy: 0.9000\n",
      "Epoch 2791/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1540 - accuracy: 0.9575 - val_loss: 0.2646 - val_accuracy: 0.9000\n",
      "Epoch 2792/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1541 - accuracy: 0.9600 - val_loss: 0.2647 - val_accuracy: 0.9000\n",
      "Epoch 2793/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1535 - accuracy: 0.9563 - val_loss: 0.2676 - val_accuracy: 0.9000\n",
      "Epoch 2794/3000\n",
      "800/800 [==============================] - 0s 430us/step - loss: 0.1544 - accuracy: 0.9588 - val_loss: 0.2670 - val_accuracy: 0.9050\n",
      "Epoch 2795/3000\n",
      "800/800 [==============================] - 0s 330us/step - loss: 0.1537 - accuracy: 0.9588 - val_loss: 0.2678 - val_accuracy: 0.9000\n",
      "Epoch 2796/3000\n",
      "800/800 [==============================] - 0s 504us/step - loss: 0.1543 - accuracy: 0.9575 - val_loss: 0.2663 - val_accuracy: 0.9000\n",
      "Epoch 2797/3000\n",
      "800/800 [==============================] - 0s 400us/step - loss: 0.1539 - accuracy: 0.9563 - val_loss: 0.2647 - val_accuracy: 0.9000\n",
      "Epoch 2798/3000\n",
      "800/800 [==============================] - 0s 375us/step - loss: 0.1537 - accuracy: 0.9575 - val_loss: 0.2681 - val_accuracy: 0.9000\n",
      "Epoch 2799/3000\n",
      "800/800 [==============================] - 0s 306us/step - loss: 0.1539 - accuracy: 0.9538 - val_loss: 0.2655 - val_accuracy: 0.9000\n",
      "Epoch 2800/3000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.1535 - accuracy: 0.9575 - val_loss: 0.2636 - val_accuracy: 0.8950\n",
      "Epoch 2801/3000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 0.1537 - accuracy: 0.9575 - val_loss: 0.2672 - val_accuracy: 0.9050\n",
      "Epoch 2802/3000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 0.1539 - accuracy: 0.9575 - val_loss: 0.2649 - val_accuracy: 0.9000\n",
      "Epoch 2803/3000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.1534 - accuracy: 0.9563 - val_loss: 0.2633 - val_accuracy: 0.9000\n",
      "Epoch 2804/3000\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.1537 - accuracy: 0.9588 - val_loss: 0.2640 - val_accuracy: 0.8950\n",
      "Epoch 2805/3000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 0.1529 - accuracy: 0.9563 - val_loss: 0.2686 - val_accuracy: 0.9000\n",
      "Epoch 2806/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1546 - accuracy: 0.95 - 0s 110us/step - loss: 0.1539 - accuracy: 0.9575 - val_loss: 0.2672 - val_accuracy: 0.9000\n",
      "Epoch 2807/3000\n",
      "800/800 [==============================] - 0s 124us/step - loss: 0.1537 - accuracy: 0.9588 - val_loss: 0.2633 - val_accuracy: 0.8950\n",
      "Epoch 2808/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1534 - accuracy: 0.9613 - val_loss: 0.2618 - val_accuracy: 0.9000\n",
      "Epoch 2809/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.1532 - accuracy: 0.9575 - val_loss: 0.2659 - val_accuracy: 0.9050\n",
      "Epoch 2810/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1537 - accuracy: 0.9600 - val_loss: 0.2652 - val_accuracy: 0.9050\n",
      "Epoch 2811/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.1532 - accuracy: 0.9600 - val_loss: 0.2629 - val_accuracy: 0.9000\n",
      "Epoch 2812/3000\n",
      "800/800 [==============================] - 0s 178us/step - loss: 0.1534 - accuracy: 0.9600 - val_loss: 0.2634 - val_accuracy: 0.9000\n",
      "Epoch 2813/3000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 0.1532 - accuracy: 0.9563 - val_loss: 0.2623 - val_accuracy: 0.9000\n",
      "Epoch 2814/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.1535 - accuracy: 0.9550 - val_loss: 0.2641 - val_accuracy: 0.9000\n",
      "Epoch 2815/3000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.1530 - accuracy: 0.9600 - val_loss: 0.2623 - val_accuracy: 0.8950\n",
      "Epoch 2816/3000\n",
      "800/800 [==============================] - 0s 136us/step - loss: 0.1532 - accuracy: 0.9575 - val_loss: 0.2657 - val_accuracy: 0.9000\n",
      "Epoch 2817/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1530 - accuracy: 0.9563 - val_loss: 0.2644 - val_accuracy: 0.8950\n",
      "Epoch 2818/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1531 - accuracy: 0.9575 - val_loss: 0.2628 - val_accuracy: 0.8950\n",
      "Epoch 2819/3000\n",
      "800/800 [==============================] - 0s 124us/step - loss: 0.1535 - accuracy: 0.9588 - val_loss: 0.2618 - val_accuracy: 0.8950\n",
      "Epoch 2820/3000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 0.1537 - accuracy: 0.9588 - val_loss: 0.2646 - val_accuracy: 0.9000\n",
      "Epoch 2821/3000\n",
      "800/800 [==============================] - 0s 166us/step - loss: 0.1533 - accuracy: 0.9575 - val_loss: 0.2650 - val_accuracy: 0.9000\n",
      "Epoch 2822/3000\n",
      "800/800 [==============================] - 0s 145us/step - loss: 0.1523 - accuracy: 0.9588 - val_loss: 0.2634 - val_accuracy: 0.8950\n",
      "Epoch 2823/3000\n",
      "800/800 [==============================] - 0s 128us/step - loss: 0.1536 - accuracy: 0.9600 - val_loss: 0.2641 - val_accuracy: 0.9000\n",
      "Epoch 2824/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1428 - accuracy: 0.95 - 0s 168us/step - loss: 0.1527 - accuracy: 0.9563 - val_loss: 0.2619 - val_accuracy: 0.8950\n",
      "Epoch 2825/3000\n",
      "800/800 [==============================] - 0s 151us/step - loss: 0.1525 - accuracy: 0.9588 - val_loss: 0.2613 - val_accuracy: 0.9050\n",
      "Epoch 2826/3000\n",
      "800/800 [==============================] - 0s 138us/step - loss: 0.1536 - accuracy: 0.9588 - val_loss: 0.2646 - val_accuracy: 0.9000\n",
      "Epoch 2827/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1535 - accuracy: 0.9575 - val_loss: 0.2648 - val_accuracy: 0.9050\n",
      "Epoch 2828/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1522 - accuracy: 0.9563 - val_loss: 0.2625 - val_accuracy: 0.9000\n",
      "Epoch 2829/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1525 - accuracy: 0.9575 - val_loss: 0.2626 - val_accuracy: 0.9000\n",
      "Epoch 2830/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1526 - accuracy: 0.9563 - val_loss: 0.2642 - val_accuracy: 0.9000\n",
      "Epoch 2831/3000\n",
      "800/800 [==============================] - 0s 130us/step - loss: 0.1532 - accuracy: 0.9575 - val_loss: 0.2648 - val_accuracy: 0.9000\n",
      "Epoch 2832/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1525 - accuracy: 0.9563 - val_loss: 0.2626 - val_accuracy: 0.9000\n",
      "Epoch 2833/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1523 - accuracy: 0.9563 - val_loss: 0.2626 - val_accuracy: 0.8950\n",
      "Epoch 2834/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1547 - accuracy: 0.95 - 0s 109us/step - loss: 0.1522 - accuracy: 0.9588 - val_loss: 0.2669 - val_accuracy: 0.9000\n",
      "Epoch 2835/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1525 - accuracy: 0.9588 - val_loss: 0.2638 - val_accuracy: 0.9050\n",
      "Epoch 2836/3000\n",
      "800/800 [==============================] - 0s 133us/step - loss: 0.1518 - accuracy: 0.9563 - val_loss: 0.2648 - val_accuracy: 0.9000\n",
      "Epoch 2837/3000\n",
      "800/800 [==============================] - 0s 126us/step - loss: 0.1519 - accuracy: 0.9588 - val_loss: 0.2641 - val_accuracy: 0.9000\n",
      "Epoch 2838/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1549 - accuracy: 0.95 - 0s 99us/step - loss: 0.1526 - accuracy: 0.9563 - val_loss: 0.2641 - val_accuracy: 0.9000\n",
      "Epoch 2839/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1528 - accuracy: 0.9563 - val_loss: 0.2663 - val_accuracy: 0.9050\n",
      "Epoch 2840/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1521 - accuracy: 0.9588 - val_loss: 0.2633 - val_accuracy: 0.9000\n",
      "Epoch 2841/3000\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.1517 - accuracy: 0.9575 - val_loss: 0.2627 - val_accuracy: 0.9000\n",
      "Epoch 2842/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1517 - accuracy: 0.9600 - val_loss: 0.2647 - val_accuracy: 0.9000\n",
      "Epoch 2843/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1528 - accuracy: 0.9600 - val_loss: 0.2629 - val_accuracy: 0.9000\n",
      "Epoch 2844/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1883 - accuracy: 0.95 - ETA: 0s - loss: 0.1469 - accuracy: 0.95 - 0s 116us/step - loss: 0.1517 - accuracy: 0.9588 - val_loss: 0.2629 - val_accuracy: 0.9000\n",
      "Epoch 2845/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1514 - accuracy: 0.9588 - val_loss: 0.2642 - val_accuracy: 0.9000\n",
      "Epoch 2846/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.1516 - accuracy: 0.9588 - val_loss: 0.2627 - val_accuracy: 0.9050\n",
      "Epoch 2847/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.1517 - accuracy: 0.9588 - val_loss: 0.2646 - val_accuracy: 0.9000\n",
      "Epoch 2848/3000\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.1512 - accuracy: 0.9600 - val_loss: 0.2625 - val_accuracy: 0.9000\n",
      "Epoch 2849/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1517 - accuracy: 0.9600 - val_loss: 0.2628 - val_accuracy: 0.9000\n",
      "Epoch 2850/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1518 - accuracy: 0.9588 - val_loss: 0.2613 - val_accuracy: 0.9000\n",
      "Epoch 2851/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1513 - accuracy: 0.9600 - val_loss: 0.2615 - val_accuracy: 0.9050\n",
      "Epoch 2852/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1508 - accuracy: 0.96 - 0s 106us/step - loss: 0.1515 - accuracy: 0.9600 - val_loss: 0.2649 - val_accuracy: 0.9050\n",
      "Epoch 2853/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2257 - accuracy: 0.92 - ETA: 0s - loss: 0.1569 - accuracy: 0.95 - 0s 108us/step - loss: 0.1518 - accuracy: 0.9588 - val_loss: 0.2651 - val_accuracy: 0.9000\n",
      "Epoch 2854/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.1512 - accuracy: 0.9575 - val_loss: 0.2623 - val_accuracy: 0.9050\n",
      "Epoch 2855/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.1512 - accuracy: 0.9613 - val_loss: 0.2643 - val_accuracy: 0.9050\n",
      "Epoch 2856/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.1523 - accuracy: 0.9575 - val_loss: 0.2640 - val_accuracy: 0.9000\n",
      "Epoch 2857/3000\n",
      "800/800 [==============================] - 0s 144us/step - loss: 0.1508 - accuracy: 0.9575 - val_loss: 0.2645 - val_accuracy: 0.9000\n",
      "Epoch 2858/3000\n",
      "800/800 [==============================] - 0s 126us/step - loss: 0.1516 - accuracy: 0.9575 - val_loss: 0.2639 - val_accuracy: 0.9000\n",
      "Epoch 2859/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1492 - accuracy: 0.96 - 0s 115us/step - loss: 0.1518 - accuracy: 0.9613 - val_loss: 0.2640 - val_accuracy: 0.9000\n",
      "Epoch 2860/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1513 - accuracy: 0.96 - 0s 103us/step - loss: 0.1507 - accuracy: 0.9588 - val_loss: 0.2617 - val_accuracy: 0.8950\n",
      "Epoch 2861/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1509 - accuracy: 0.9588 - val_loss: 0.2633 - val_accuracy: 0.9050\n",
      "Epoch 2862/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1511 - accuracy: 0.9613 - val_loss: 0.2619 - val_accuracy: 0.9100\n",
      "Epoch 2863/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.95 - 0s 123us/step - loss: 0.1517 - accuracy: 0.9588 - val_loss: 0.2641 - val_accuracy: 0.9000\n",
      "Epoch 2864/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1509 - accuracy: 0.9563 - val_loss: 0.2616 - val_accuracy: 0.9050\n",
      "Epoch 2865/3000\n",
      "800/800 [==============================] - 0s 135us/step - loss: 0.1509 - accuracy: 0.9588 - val_loss: 0.2632 - val_accuracy: 0.9000\n",
      "Epoch 2866/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1514 - accuracy: 0.9588 - val_loss: 0.2631 - val_accuracy: 0.9000\n",
      "Epoch 2867/3000\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.1503 - accuracy: 0.9588 - val_loss: 0.2607 - val_accuracy: 0.9050\n",
      "Epoch 2868/3000\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.1503 - accuracy: 0.9588 - val_loss: 0.2654 - val_accuracy: 0.9000\n",
      "Epoch 2869/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1513 - accuracy: 0.9550 - val_loss: 0.2644 - val_accuracy: 0.9000\n",
      "Epoch 2870/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1505 - accuracy: 0.9575 - val_loss: 0.2625 - val_accuracy: 0.9000\n",
      "Epoch 2871/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1501 - accuracy: 0.9575 - val_loss: 0.2643 - val_accuracy: 0.9000\n",
      "Epoch 2872/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1459 - accuracy: 0.96 - 0s 114us/step - loss: 0.1515 - accuracy: 0.9550 - val_loss: 0.2647 - val_accuracy: 0.9050\n",
      "Epoch 2873/3000\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1501 - accuracy: 0.9563 - val_loss: 0.2638 - val_accuracy: 0.9050\n",
      "Epoch 2874/3000\n",
      "800/800 [==============================] - 0s 129us/step - loss: 0.1508 - accuracy: 0.9613 - val_loss: 0.2640 - val_accuracy: 0.9000\n",
      "Epoch 2875/3000\n",
      "800/800 [==============================] - 0s 125us/step - loss: 0.1509 - accuracy: 0.9613 - val_loss: 0.2643 - val_accuracy: 0.9000\n",
      "Epoch 2876/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1504 - accuracy: 0.9613 - val_loss: 0.2631 - val_accuracy: 0.9050\n",
      "Epoch 2877/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1500 - accuracy: 0.9613 - val_loss: 0.2660 - val_accuracy: 0.9050\n",
      "Epoch 2878/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.1512 - accuracy: 0.9588 - val_loss: 0.2623 - val_accuracy: 0.9050\n",
      "Epoch 2879/3000\n",
      "800/800 [==============================] - 0s 148us/step - loss: 0.1506 - accuracy: 0.9588 - val_loss: 0.2607 - val_accuracy: 0.9000\n",
      "Epoch 2880/3000\n",
      "800/800 [==============================] - 0s 134us/step - loss: 0.1504 - accuracy: 0.9575 - val_loss: 0.2610 - val_accuracy: 0.9000\n",
      "Epoch 2881/3000\n",
      "800/800 [==============================] - 0s 288us/step - loss: 0.1503 - accuracy: 0.9588 - val_loss: 0.2615 - val_accuracy: 0.9050\n",
      "Epoch 2882/3000\n",
      "800/800 [==============================] - 0s 229us/step - loss: 0.1503 - accuracy: 0.9575 - val_loss: 0.2613 - val_accuracy: 0.9100\n",
      "Epoch 2883/3000\n",
      "800/800 [==============================] - 0s 294us/step - loss: 0.1507 - accuracy: 0.9563 - val_loss: 0.2640 - val_accuracy: 0.9000\n",
      "Epoch 2884/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1501 - accuracy: 0.9613 - val_loss: 0.2669 - val_accuracy: 0.9100\n",
      "Epoch 2885/3000\n",
      "800/800 [==============================] - 0s 365us/step - loss: 0.1502 - accuracy: 0.9588 - val_loss: 0.2612 - val_accuracy: 0.9050\n",
      "Epoch 2886/3000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.1495 - accuracy: 0.9575 - val_loss: 0.2646 - val_accuracy: 0.9000\n",
      "Epoch 2887/3000\n",
      "800/800 [==============================] - 0s 319us/step - loss: 0.1509 - accuracy: 0.9563 - val_loss: 0.2638 - val_accuracy: 0.9000\n",
      "Epoch 2888/3000\n",
      "800/800 [==============================] - 0s 254us/step - loss: 0.1504 - accuracy: 0.9538 - val_loss: 0.2624 - val_accuracy: 0.9000\n",
      "Epoch 2889/3000\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.1495 - accuracy: 0.9588 - val_loss: 0.2609 - val_accuracy: 0.8950\n",
      "Epoch 2890/3000\n",
      "800/800 [==============================] - 0s 173us/step - loss: 0.1504 - accuracy: 0.9563 - val_loss: 0.2615 - val_accuracy: 0.9050\n",
      "Epoch 2891/3000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 0.1500 - accuracy: 0.9588 - val_loss: 0.2609 - val_accuracy: 0.9000\n",
      "Epoch 2892/3000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.1498 - accuracy: 0.9613 - val_loss: 0.2613 - val_accuracy: 0.9050\n",
      "Epoch 2893/3000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 0.1499 - accuracy: 0.9588 - val_loss: 0.2631 - val_accuracy: 0.9050\n",
      "Epoch 2894/3000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 0.1497 - accuracy: 0.9600 - val_loss: 0.2607 - val_accuracy: 0.8950\n",
      "Epoch 2895/3000\n",
      "800/800 [==============================] - 0s 301us/step - loss: 0.1496 - accuracy: 0.9600 - val_loss: 0.2632 - val_accuracy: 0.9050\n",
      "Epoch 2896/3000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 0.1497 - accuracy: 0.9600 - val_loss: 0.2632 - val_accuracy: 0.9050\n",
      "Epoch 2897/3000\n",
      "800/800 [==============================] - 0s 373us/step - loss: 0.1502 - accuracy: 0.9575 - val_loss: 0.2604 - val_accuracy: 0.8950\n",
      "Epoch 2898/3000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 0.1497 - accuracy: 0.9588 - val_loss: 0.2619 - val_accuracy: 0.9000\n",
      "Epoch 2899/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1326 - accuracy: 0.97 - 0s 166us/step - loss: 0.1496 - accuracy: 0.9613 - val_loss: 0.2636 - val_accuracy: 0.9050\n",
      "Epoch 2900/3000\n",
      "800/800 [==============================] - 0s 231us/step - loss: 0.1506 - accuracy: 0.9600 - val_loss: 0.2617 - val_accuracy: 0.9100\n",
      "Epoch 2901/3000\n",
      "800/800 [==============================] - 0s 128us/step - loss: 0.1505 - accuracy: 0.9600 - val_loss: 0.2609 - val_accuracy: 0.8950\n",
      "Epoch 2902/3000\n",
      "800/800 [==============================] - 0s 153us/step - loss: 0.1503 - accuracy: 0.9600 - val_loss: 0.2596 - val_accuracy: 0.9000\n",
      "Epoch 2903/3000\n",
      "800/800 [==============================] - 0s 129us/step - loss: 0.1496 - accuracy: 0.9588 - val_loss: 0.2617 - val_accuracy: 0.9050\n",
      "Epoch 2904/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1496 - accuracy: 0.9600 - val_loss: 0.2610 - val_accuracy: 0.9000\n",
      "Epoch 2905/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1494 - accuracy: 0.9600 - val_loss: 0.2622 - val_accuracy: 0.9000\n",
      "Epoch 2906/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1496 - accuracy: 0.9613 - val_loss: 0.2592 - val_accuracy: 0.9000\n",
      "Epoch 2907/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1494 - accuracy: 0.9588 - val_loss: 0.2602 - val_accuracy: 0.9050\n",
      "Epoch 2908/3000\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.1494 - accuracy: 0.9588 - val_loss: 0.2633 - val_accuracy: 0.9000\n",
      "Epoch 2909/3000\n",
      "800/800 [==============================] - 0s 133us/step - loss: 0.1495 - accuracy: 0.9588 - val_loss: 0.2620 - val_accuracy: 0.9000\n",
      "Epoch 2910/3000\n",
      "800/800 [==============================] - 0s 159us/step - loss: 0.1496 - accuracy: 0.9575 - val_loss: 0.2622 - val_accuracy: 0.9000\n",
      "Epoch 2911/3000\n",
      "800/800 [==============================] - 0s 129us/step - loss: 0.1487 - accuracy: 0.9588 - val_loss: 0.2626 - val_accuracy: 0.9000\n",
      "Epoch 2912/3000\n",
      "800/800 [==============================] - 0s 149us/step - loss: 0.1491 - accuracy: 0.9588 - val_loss: 0.2617 - val_accuracy: 0.9000\n",
      "Epoch 2913/3000\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.1488 - accuracy: 0.9613 - val_loss: 0.2615 - val_accuracy: 0.9050\n",
      "Epoch 2914/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1497 - accuracy: 0.9588 - val_loss: 0.2619 - val_accuracy: 0.9050\n",
      "Epoch 2915/3000\n",
      "800/800 [==============================] - 0s 140us/step - loss: 0.1487 - accuracy: 0.9600 - val_loss: 0.2603 - val_accuracy: 0.9000\n",
      "Epoch 2916/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1499 - accuracy: 0.9588 - val_loss: 0.2611 - val_accuracy: 0.9000\n",
      "Epoch 2917/3000\n",
      "800/800 [==============================] - 0s 236us/step - loss: 0.1491 - accuracy: 0.9588 - val_loss: 0.2622 - val_accuracy: 0.9000\n",
      "Epoch 2918/3000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 0.1488 - accuracy: 0.9600 - val_loss: 0.2617 - val_accuracy: 0.9050\n",
      "Epoch 2919/3000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.1493 - accuracy: 0.9613 - val_loss: 0.2637 - val_accuracy: 0.8950\n",
      "Epoch 2920/3000\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.1483 - accuracy: 0.9588 - val_loss: 0.2665 - val_accuracy: 0.9000\n",
      "Epoch 2921/3000\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.1483 - accuracy: 0.9600 - val_loss: 0.2643 - val_accuracy: 0.9050\n",
      "Epoch 2922/3000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.1487 - accuracy: 0.9575 - val_loss: 0.2633 - val_accuracy: 0.9000\n",
      "Epoch 2923/3000\n",
      "800/800 [==============================] - 0s 143us/step - loss: 0.1490 - accuracy: 0.9625 - val_loss: 0.2630 - val_accuracy: 0.9050\n",
      "Epoch 2924/3000\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.1485 - accuracy: 0.9588 - val_loss: 0.2623 - val_accuracy: 0.9050\n",
      "Epoch 2925/3000\n",
      "800/800 [==============================] - 0s 223us/step - loss: 0.1490 - accuracy: 0.9613 - val_loss: 0.2647 - val_accuracy: 0.9000\n",
      "Epoch 2926/3000\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.1493 - accuracy: 0.9575 - val_loss: 0.2604 - val_accuracy: 0.9000\n",
      "Epoch 2927/3000\n",
      "800/800 [==============================] - 0s 236us/step - loss: 0.1484 - accuracy: 0.9600 - val_loss: 0.2606 - val_accuracy: 0.9050\n",
      "Epoch 2928/3000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.1483 - accuracy: 0.9613 - val_loss: 0.2637 - val_accuracy: 0.9050\n",
      "Epoch 2929/3000\n",
      "800/800 [==============================] - 0s 145us/step - loss: 0.1483 - accuracy: 0.9600 - val_loss: 0.2618 - val_accuracy: 0.9050\n",
      "Epoch 2930/3000\n",
      "800/800 [==============================] - 0s 358us/step - loss: 0.1486 - accuracy: 0.9613 - val_loss: 0.2632 - val_accuracy: 0.9050\n",
      "Epoch 2931/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1485 - accuracy: 0.9588 - val_loss: 0.2630 - val_accuracy: 0.9050\n",
      "Epoch 2932/3000\n",
      "800/800 [==============================] - 0s 220us/step - loss: 0.1492 - accuracy: 0.9588 - val_loss: 0.2632 - val_accuracy: 0.9050\n",
      "Epoch 2933/3000\n",
      "800/800 [==============================] - 0s 124us/step - loss: 0.1486 - accuracy: 0.9600 - val_loss: 0.2623 - val_accuracy: 0.9050\n",
      "Epoch 2934/3000\n",
      "800/800 [==============================] - 0s 136us/step - loss: 0.1480 - accuracy: 0.9588 - val_loss: 0.2607 - val_accuracy: 0.9050\n",
      "Epoch 2935/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1483 - accuracy: 0.9563 - val_loss: 0.2611 - val_accuracy: 0.9000\n",
      "Epoch 2936/3000\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.1475 - accuracy: 0.9575 - val_loss: 0.2600 - val_accuracy: 0.9100\n",
      "Epoch 2937/3000\n",
      "800/800 [==============================] - 0s 120us/step - loss: 0.1489 - accuracy: 0.9600 - val_loss: 0.2615 - val_accuracy: 0.9000\n",
      "Epoch 2938/3000\n",
      "800/800 [==============================] - 0s 126us/step - loss: 0.1480 - accuracy: 0.9600 - val_loss: 0.2612 - val_accuracy: 0.9000\n",
      "Epoch 2939/3000\n",
      "800/800 [==============================] - 0s 173us/step - loss: 0.1478 - accuracy: 0.9613 - val_loss: 0.2634 - val_accuracy: 0.9000\n",
      "Epoch 2940/3000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 0.1477 - accuracy: 0.9575 - val_loss: 0.2607 - val_accuracy: 0.9050\n",
      "Epoch 2941/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1480 - accuracy: 0.9588 - val_loss: 0.2608 - val_accuracy: 0.9000\n",
      "Epoch 2942/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1571 - accuracy: 0.95 - 0s 179us/step - loss: 0.1485 - accuracy: 0.9600 - val_loss: 0.2596 - val_accuracy: 0.9000\n",
      "Epoch 2943/3000\n",
      "800/800 [==============================] - 0s 123us/step - loss: 0.1483 - accuracy: 0.9625 - val_loss: 0.2619 - val_accuracy: 0.9050\n",
      "Epoch 2944/3000\n",
      "800/800 [==============================] - 0s 155us/step - loss: 0.1478 - accuracy: 0.9588 - val_loss: 0.2606 - val_accuracy: 0.9050\n",
      "Epoch 2945/3000\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.1478 - accuracy: 0.9625 - val_loss: 0.2614 - val_accuracy: 0.9050\n",
      "Epoch 2946/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1492 - accuracy: 0.96 - 0s 108us/step - loss: 0.1477 - accuracy: 0.9625 - val_loss: 0.2627 - val_accuracy: 0.9050\n",
      "Epoch 2947/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1479 - accuracy: 0.9600 - val_loss: 0.2621 - val_accuracy: 0.9050\n",
      "Epoch 2948/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1476 - accuracy: 0.9550 - val_loss: 0.2632 - val_accuracy: 0.9000\n",
      "Epoch 2949/3000\n",
      "800/800 [==============================] - 0s 124us/step - loss: 0.1480 - accuracy: 0.9613 - val_loss: 0.2629 - val_accuracy: 0.9050\n",
      "Epoch 2950/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1476 - accuracy: 0.9613 - val_loss: 0.2609 - val_accuracy: 0.9000\n",
      "Epoch 2951/3000\n",
      "800/800 [==============================] - 0s 124us/step - loss: 0.1474 - accuracy: 0.9588 - val_loss: 0.2598 - val_accuracy: 0.9000\n",
      "Epoch 2952/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1475 - accuracy: 0.9588 - val_loss: 0.2612 - val_accuracy: 0.9050\n",
      "Epoch 2953/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1472 - accuracy: 0.9613 - val_loss: 0.2611 - val_accuracy: 0.9050\n",
      "Epoch 2954/3000\n",
      "800/800 [==============================] - 0s 169us/step - loss: 0.1475 - accuracy: 0.9600 - val_loss: 0.2607 - val_accuracy: 0.9000\n",
      "Epoch 2955/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1479 - accuracy: 0.9588 - val_loss: 0.2602 - val_accuracy: 0.9050\n",
      "Epoch 2956/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1476 - accuracy: 0.9600 - val_loss: 0.2590 - val_accuracy: 0.9050\n",
      "Epoch 2957/3000\n",
      "800/800 [==============================] - 0s 163us/step - loss: 0.1474 - accuracy: 0.9625 - val_loss: 0.2604 - val_accuracy: 0.9050\n",
      "Epoch 2958/3000\n",
      "800/800 [==============================] - 0s 129us/step - loss: 0.1479 - accuracy: 0.9600 - val_loss: 0.2598 - val_accuracy: 0.9100\n",
      "Epoch 2959/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1467 - accuracy: 0.9638 - val_loss: 0.2615 - val_accuracy: 0.9000\n",
      "Epoch 2960/3000\n",
      "800/800 [==============================] - 0s 135us/step - loss: 0.1468 - accuracy: 0.9600 - val_loss: 0.2583 - val_accuracy: 0.9050\n",
      "Epoch 2961/3000\n",
      "800/800 [==============================] - 0s 148us/step - loss: 0.1483 - accuracy: 0.9613 - val_loss: 0.2623 - val_accuracy: 0.9050\n",
      "Epoch 2962/3000\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.1469 - accuracy: 0.9600 - val_loss: 0.2619 - val_accuracy: 0.9050\n",
      "Epoch 2963/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1469 - accuracy: 0.9638 - val_loss: 0.2625 - val_accuracy: 0.9000\n",
      "Epoch 2964/3000\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.1468 - accuracy: 0.9613 - val_loss: 0.2616 - val_accuracy: 0.9000\n",
      "Epoch 2965/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1543 - accuracy: 0.95 - 0s 113us/step - loss: 0.1469 - accuracy: 0.9600 - val_loss: 0.2608 - val_accuracy: 0.9000\n",
      "Epoch 2966/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.1469 - accuracy: 0.9613 - val_loss: 0.2614 - val_accuracy: 0.9000\n",
      "Epoch 2967/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1480 - accuracy: 0.9600 - val_loss: 0.2602 - val_accuracy: 0.9050\n",
      "Epoch 2968/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1467 - accuracy: 0.9613 - val_loss: 0.2610 - val_accuracy: 0.9050\n",
      "Epoch 2969/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1474 - accuracy: 0.9575 - val_loss: 0.2598 - val_accuracy: 0.9100\n",
      "Epoch 2970/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1473 - accuracy: 0.9600 - val_loss: 0.2613 - val_accuracy: 0.9000\n",
      "Epoch 2971/3000\n",
      "800/800 [==============================] - 0s 123us/step - loss: 0.1468 - accuracy: 0.9600 - val_loss: 0.2631 - val_accuracy: 0.9050\n",
      "Epoch 2972/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1593 - accuracy: 0.95 - ETA: 0s - loss: 0.1458 - accuracy: 0.95 - 0s 104us/step - loss: 0.1464 - accuracy: 0.9600 - val_loss: 0.2581 - val_accuracy: 0.9050\n",
      "Epoch 2973/3000\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.1474 - accuracy: 0.9600 - val_loss: 0.2605 - val_accuracy: 0.9000\n",
      "Epoch 2974/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1466 - accuracy: 0.9625 - val_loss: 0.2635 - val_accuracy: 0.9050\n",
      "Epoch 2975/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1466 - accuracy: 0.9613 - val_loss: 0.2583 - val_accuracy: 0.9150\n",
      "Epoch 2976/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1466 - accuracy: 0.9650 - val_loss: 0.2609 - val_accuracy: 0.9050\n",
      "Epoch 2977/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1467 - accuracy: 0.9625 - val_loss: 0.2621 - val_accuracy: 0.9050\n",
      "Epoch 2978/3000\n",
      "800/800 [==============================] - 0s 125us/step - loss: 0.1463 - accuracy: 0.9625 - val_loss: 0.2601 - val_accuracy: 0.9050\n",
      "Epoch 2979/3000\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.1468 - accuracy: 0.9625 - val_loss: 0.2628 - val_accuracy: 0.9050\n",
      "Epoch 2980/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1466 - accuracy: 0.9600 - val_loss: 0.2602 - val_accuracy: 0.9100\n",
      "Epoch 2981/3000\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.1460 - accuracy: 0.9588 - val_loss: 0.2578 - val_accuracy: 0.9050\n",
      "Epoch 2982/3000\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.1463 - accuracy: 0.9588 - val_loss: 0.2649 - val_accuracy: 0.9100\n",
      "Epoch 2983/3000\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.1469 - accuracy: 0.9600 - val_loss: 0.2585 - val_accuracy: 0.9050\n",
      "Epoch 2984/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.1463 - accuracy: 0.9600 - val_loss: 0.2600 - val_accuracy: 0.9000\n",
      "Epoch 2985/3000\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.1467 - accuracy: 0.9613 - val_loss: 0.2583 - val_accuracy: 0.8950\n",
      "Epoch 2986/3000\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.1467 - accuracy: 0.9613 - val_loss: 0.2582 - val_accuracy: 0.9050\n",
      "Epoch 2987/3000\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.1468 - accuracy: 0.9625 - val_loss: 0.2589 - val_accuracy: 0.9050\n",
      "Epoch 2988/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1501 - accuracy: 0.96 - 0s 101us/step - loss: 0.1464 - accuracy: 0.9613 - val_loss: 0.2602 - val_accuracy: 0.9050\n",
      "Epoch 2989/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1493 - accuracy: 0.95 - 0s 128us/step - loss: 0.1458 - accuracy: 0.9588 - val_loss: 0.2617 - val_accuracy: 0.9000\n",
      "Epoch 2990/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1401 - accuracy: 0.96 - 0s 116us/step - loss: 0.1462 - accuracy: 0.9613 - val_loss: 0.2623 - val_accuracy: 0.9050\n",
      "Epoch 2991/3000\n",
      "800/800 [==============================] - 0s 131us/step - loss: 0.1469 - accuracy: 0.9600 - val_loss: 0.2606 - val_accuracy: 0.9050\n",
      "Epoch 2992/3000\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.1448 - accuracy: 0.9600 - val_loss: 0.2592 - val_accuracy: 0.9100\n",
      "Epoch 2993/3000\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.1468 - accuracy: 0.9613 - val_loss: 0.2601 - val_accuracy: 0.9050\n",
      "Epoch 2994/3000\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.1458 - accuracy: 0.9575 - val_loss: 0.2619 - val_accuracy: 0.9000\n",
      "Epoch 2995/3000\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1460 - accuracy: 0.9600 - val_loss: 0.2630 - val_accuracy: 0.9100\n",
      "Epoch 2996/3000\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.1462 - accuracy: 0.9600 - val_loss: 0.2603 - val_accuracy: 0.9000\n",
      "Epoch 2997/3000\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.1458 - accuracy: 0.9600 - val_loss: 0.2595 - val_accuracy: 0.9050\n",
      "Epoch 2998/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1481 - accuracy: 0.95 - 0s 104us/step - loss: 0.1460 - accuracy: 0.9600 - val_loss: 0.2610 - val_accuracy: 0.9050\n",
      "Epoch 2999/3000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1910 - accuracy: 0.95 - ETA: 0s - loss: 0.1483 - accuracy: 0.96 - 0s 128us/step - loss: 0.1459 - accuracy: 0.9625 - val_loss: 0.2594 - val_accuracy: 0.9000\n",
      "Epoch 3000/3000\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.1457 - accuracy: 0.9625 - val_loss: 0.2632 - val_accuracy: 0.9050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2527b308>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          epochs=3000,\n",
    "          batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 35us/step\n",
      "\n",
      "Testing loss: 0.22, acc: 0.92%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print('\\nTesting loss: %.2f, acc: %.2f%%'%(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
